{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flask-sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install html5lib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#from unidecode import unidecode\n",
    "import re\n",
    "import os\n",
    "import yfinance as yf\n",
    "from time import sleep\n",
    "import glob\n",
    "import regex as re\n",
    "import datetime\n",
    "import sqlalchemy as db\n",
    "from dotenv import load_dotenv\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename=f'{logging_path}{today}.log',\n",
    "                    format='%(asctime)s.%(msecs)03d %(levelname)s - %(funcName)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "logger = logging.getLogger('Logging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining file's path\n",
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\Ironhack_Final_Project\\data/'\n",
    "# Historical dataset is to big to upload to GitHub\n",
    "stock_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets/'\n",
    "# Logging path\n",
    "logging_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets\\Logging/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - Brazilian Companies\n",
    "\n",
    "### List of brazilian companies and composition of indexes - Ibovespa, IBrX100, IBrX50, IBrA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium\n",
    "\n",
    "Used to get list of companies in brazilian's index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurating WebDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurating download file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromeOptions = webdriver.ChromeOptions()\n",
    "download_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project\\data'\n",
    "prefs = {\"download.default_directory\" : download_path}\n",
    "chromeOptions.add_experimental_option(\"prefs\",prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the webdriver\n",
    "driver = webdriver.Chrome(options=chromeOptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Index File (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_stocks(index, wait=6):\n",
    "    '''\n",
    "        Receives the Index name, download a file that contains the index tickers, and return the name of the downloaded file\n",
    "    '''\n",
    "\n",
    "    # Chrome WebDriver opens the index webside\n",
    "    url = f'https://sistemaswebb3-listados.b3.com.br/indexPage/day/{index.upper()}?language=pt-br'\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(wait)\n",
    "\n",
    "    driver.find_element(By.ID, 'segment').send_keys(\"Setor de Atuação\")\n",
    "    driver.implicitly_wait(wait)\n",
    "    driver.find_element(By.LINK_TEXT, 'Download').click()\n",
    "    driver.implicitly_wait(wait)\n",
    "\n",
    "    # Set the directory\n",
    "    os.chdir(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project\\data')\n",
    "    sleep(wait)\n",
    "\n",
    "    # Get the .csv files from the selectec directory and sort them ascending by modification date \n",
    "    files = list(glob.glob('*csv'))\n",
    "    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "\n",
    "    # Returns the name of the most recent file\n",
    "    return files[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Index DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(file):\n",
    "    '''\n",
    "        This function receives the name of the Stock Exchange index and returns a DataFrame with all companies and their respective sectors\n",
    "    '''\n",
    "\n",
    "    # Creating DataFrame\n",
    "    DataFrame = pd.read_csv(file, \n",
    "                                encoding='ISO-8859-1',\n",
    "                                header=1,                   # Uses line 1 as header\n",
    "                                sep=';',                    \n",
    "                                decimal=',',\n",
    "                                thousands='.',\n",
    "                                skipfooter=2,               # Removes last 2 lines\n",
    "                                engine='python',\n",
    "                                index_col=False)            # Does not make first column as index\n",
    "    \n",
    "    # Normalizing columns\n",
    "    DataFrame.columns = [re.sub('[\\.()]', '', re.sub(' ', '_', unidecode(columns.lower()))) for columns in DataFrame.columns]\n",
    "\n",
    "    return DataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Index's DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining file's path\n",
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project\\data/'\n",
    "# Historical dataset is to big to upload to GitHub\n",
    "stock_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining DataFrames' columns names\n",
    "col_names = [\n",
    "    'sector',\n",
    "    'ticker',\n",
    "    'name',\n",
    "    'type',\n",
    "    'amount',\n",
    "    'percentage',\n",
    "    'percentage_acum'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ibovespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov = create_df(get_index_stocks('ibov'))\n",
    "len(ibov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibov.to_csv(f'{path}IBOV.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov = pd.read_csv(f'{path}IBOV.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBrX100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx = create_df(get_index_stocks('ibxx'))\n",
    "len(ibrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibrx.to_csv(f'{path}IBRX100.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBrX50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx50 = create_df(get_index_stocks('ibxl'))\n",
    "len(ibrx50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx50.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibrx50.to_csv(f'{path}IBRX50.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBrA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = create_df(get_index_stocks('ibra'))\n",
    "len(ibra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibra.to_csv(f'{path}IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking companies that differ in the two indexes - Obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ibrx = ibrx['codigo']\n",
    "set_ibrx = set(emp_ibrx)\n",
    "len(set_ibrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ibov = ibov['codigo']\n",
    "set_ibov = set(emp_ibov)\n",
    "len(set_ibov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ibra = ibra['codigo']\n",
    "set_ibra = set(emp_ibra)\n",
    "len(set_ibra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set_ibra.difference(set_ibrx)))\n",
    "print(set_ibra.difference(set_ibrx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set_ibov.difference(set_ibrx)))\n",
    "print(set_ibov.difference(set_ibrx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set_ibrx.difference(set_ibov)))\n",
    "print(set_ibrx.difference(set_ibov))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - Brazilian Companies Historical Dataset - Obsolete (All data gathered from Yfinance)\n",
    "\n",
    "### Create dataset concatenating historical datasets downloaded from B3 website with data from the companies listed in IBRA Index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list with main companies ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using companies in IBRA Index\n",
    "codigo = list(set_ibra)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\data_visualization\\data/'\n",
    "\n",
    "i = 1986\n",
    "\n",
    "while i < 2000:\n",
    "    with zipfile.ZipFile(f'{path}COTAHIST_A{i}.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "    i +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2000\n",
    "\n",
    "while i < 2022:\n",
    "    os.rename(f'COTAHIST_A{i}.TXT', f'COTAHIST_A{i}.txt')\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting configurations to read B3 historical files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.max_columns=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\B3\\txt/'\n",
    "\n",
    "year = 2022\n",
    "\n",
    "widths = [2,8,2,12,3,12,10,3,4,13,13,13,13,13,13,13,5,18,18,13,1,8,7,13,12,3]\n",
    "\n",
    "col_names = [\n",
    "\"tipo_registro\",\n",
    "\"data_pregao\",\n",
    "\"cod_bdi\",\n",
    "\"cod_negociacao\",\n",
    "\"tipo_mercado\",\n",
    "\"nome_empresa\",\n",
    "\"especificacao_papel\",\n",
    "\"prazo_dias_merc_termo\",\n",
    "\"moeda_referencia\",\n",
    "\"preco_abertura\",\n",
    "\"preco_maximo\",\n",
    "\"preco_minimo\",\n",
    "\"preco_medio\",\n",
    "\"preco_ultimo_negocio\",\n",
    "\"preco_melhor_oferta_compra\",\n",
    "\"preco_melhor_oferta_venda\",\n",
    "\"numero_negocios\",\n",
    "\"quantidade_papeis_negociados\",\n",
    "\"volume_total_negociado\",\n",
    "\"preco_exercicio\",\n",
    "\"ìndicador_correcao_precos\",\n",
    "\"data_vencimento\" ,\n",
    "\"fator_cotacao\",\n",
    "\"preco_exercicio_pontos\",\n",
    "\"codigo_isin\",\n",
    "\"num_distribuicao_papel\"]\n",
    "\n",
    "decimal_config=[\n",
    "\"preco_abertura\",\n",
    "\"preco_maximo\",\n",
    "\"preco_minimo\",\n",
    "\"preco_medio\",\n",
    "\"preco_ultimo_negocio\",\n",
    "\"preco_melhor_oferta_compra\",\n",
    "\"preco_melhor_oferta_venda\",\n",
    "\"volume_total_negociado\",\n",
    "\"preco_exercicio\",\n",
    "\"preco_exercicio_pontos\"\n",
    "]\n",
    "\n",
    "\n",
    "remains = [\n",
    "\"data_pregao\",\n",
    "\"cod_negociacao\",\n",
    "\"tipo_mercado\",\n",
    "\"nome_empresa\",\n",
    "\"preco_abertura\",\n",
    "\"preco_maximo\",\n",
    "\"preco_minimo\",\n",
    "\"preco_medio\",\n",
    "\"preco_ultimo_negocio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     Concatenate DataFrames\n",
    "year = 2022\n",
    "while year > 1985:\n",
    "    df = pd.read_fwf(f'{path}COTAHIST_A{year}.TXT',\n",
    "                                    encoding='ISO-8859-1',\n",
    "                                    header=0,\n",
    "                                    widths=widths,\n",
    "                                    skipfooter=1,\n",
    "                                    engine='python',\n",
    "                                    parse_dates=[1],\n",
    "                                    infer_datetime_format=True,\n",
    "                                    index_col=False)\n",
    "    year -= 1\n",
    "\n",
    "    #Definindo nomes das colunas\n",
    "    df.columns = col_names\n",
    "\n",
    "    #Corrigindo casas decimais\n",
    "    for col in decimal_config:\n",
    "        df[col]=df[col]/100\n",
    "\n",
    "    #Selecionando colunas\n",
    "    df = df[remains]\n",
    "    \n",
    "    #Mascara de empresas desejadas\n",
    "    mask_empresas = df.cod_negociacao.isin(codigo)\n",
    "\n",
    "    df = df[mask_empresas]\n",
    "\n",
    "    dataset = pd.concat([dataset, df], ignore_index=True)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export DF - Historical Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(f'{path}dataset_IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f'{path}dataset_IBRA.csv',\n",
    "                encoding='ISO-8859-1',\n",
    "                sep=';',\n",
    "                decimal='.',\n",
    "                index_col=False\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data From Yahoo Finance\n",
    "\n",
    "### Get historical series of brazilian and american indexes\n",
    "### Get historical series of Gold, Bitcoin and Ethererum\n",
    "### Get historical series of american companies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set YFinance setting\n",
    "\n",
    "symbol_list_br = ['^BVSP','^IBX50']\n",
    "symbol_list_eua = ['^DJI','^IXIC','^GSPC','GC=F']\n",
    "symbol_list_crypto = ['BTC-USD', 'ETH-USD']\n",
    "\n",
    "name_dict={\n",
    "    '^BVSP':'Ibovespa',\n",
    "    '^IBX50':'IBrX50',\n",
    "    '^DJI':'Dow Jones',\n",
    "    '^IXIC':'NASDAQ',\n",
    "    '^GSPC':'S&P 500',\n",
    "    'GC=F':'Ouro ($)',\n",
    "    'BTC-USD':'Bitcoin ($)',\n",
    "    'ETH-USD':'Ethereum ($)'\n",
    "}\n",
    "\n",
    "col_names = ['date',\n",
    "\"open\",\n",
    "\"high\",\n",
    "\"low\",\n",
    "\"close\",\n",
    "'cod_yfinance']\n",
    "\n",
    "drop_col = ['Volume','Dividends','Stock Splits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty indexes DataFrames\n",
    "'''\n",
    "df_br = pd.DataFrame()\n",
    "df_eua = pd.DataFrame()\n",
    "df_crypto = pd.DataFrame()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill brazilian indexes historical series dataset\n",
    "'''\n",
    "for ativo in symbol_list_br:\n",
    "        chamada_api = yf.Ticker(ativo).history(period='max')\n",
    "        chamada_api['cod_yfinace'] = ativo\n",
    "        df_br = pd.concat([df_br, chamada_api])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform data from index to column 0\n",
    "'''\n",
    "df_br = df_br.drop(drop_col, axis = 1)\n",
    "df_br.reset_index(inplace=True)\n",
    "df_br['Date'] = df_br['Date'].dt.date\n",
    "df_br.columns = col_names\n",
    "df_br\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put indexes names in the DF\n",
    "df_br['name'] = df_br['cod_yfinance'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reroder columns\n",
    "df_br = df_br[['date','name','open','high','low','close','cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "df_br.to_csv(f'{path}index_br.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame\n",
    "index_br = pd.read_csv(f'{path}index_br.csv',\n",
    "                    sep = ';',\n",
    "                    decimal = '.',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill american indexes and gold historical series dataset\n",
    "'''\n",
    "for ativo in symbol_list_eua:\n",
    "        chamada_api = yf.Ticker(ativo).history(period='max')\n",
    "        chamada_api['cod_yfinance'] = ativo\n",
    "        df_eua = pd.concat([df_eua, chamada_api])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform data from index to column 0\n",
    "'''\n",
    "df_eua = df_eua.drop(drop_col, axis = 1)\n",
    "df_eua.reset_index(inplace=True)\n",
    "df_eua['Date'] = df_eua['Date'].dt.date\n",
    "df_eua.columns = col_names\n",
    "df_eua\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put indexes names in the DF\n",
    "df_eua['name'] = df_eua['cod_yfinance'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_eua = df_eua[['date','name','open','high','low','close','cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "df_eua.to_csv(f'{path}index_eua.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame\n",
    "index_eua = pd.read_csv(f'{path}index_eua.csv',\n",
    "                    sep = ';',\n",
    "                    decimal = '.',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill cripto historical series dataset\n",
    "'''\n",
    "for ativo in symbol_list_crypto:\n",
    "        chamada_api = yf.Ticker(ativo).history(period='max')\n",
    "        chamada_api['cod_yfinace'] = ativo\n",
    "        df_crypto = pd.concat([df_crypto, chamada_api])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform data from index to column 0\n",
    "'''\n",
    "df_crypto = df_crypto.drop(drop_col, axis = 1)\n",
    "df_crypto.reset_index(inplace=True)\n",
    "df_crypto['Date'] = df_crypto['Date'].dt.date\n",
    "df_crypto.columns = col_names\n",
    "df_crypto\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put indexes names in the DF\n",
    "df_crypto['name'] = df_crypto['cod_yfinance'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_crypto = df_crypto[['date','name','open','high','low','close','cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crypto.to_csv(f'{path}crypto.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = pd.read_csv(f'{path}crypto.csv',\n",
    "                    sep = ';',\n",
    "                    decimal = '.',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - American Companies\n",
    "\n",
    "### List of american companies and composition of indexes - S&P500, Dow Jones, Nasdaq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = data[0].iloc[:,[0,1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.columns = ['ticker', 'name', 'sector', 'sub_industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.to_csv(f'{path}SP500.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv(f'{path}SP500.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Nasdaq-100'\n",
    "\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[4]\n",
    "nasdaq = data[4]\n",
    "nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq.columns = ['name','ticker', 'sector', 'sub_industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq.to_csv(f'{path}NASDAQ.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = pd.read_csv(f'{path}NASDAQ.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dow Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average'\n",
    "\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]\n",
    "dow_jones = data[1].iloc[:,[0,2,3]]\n",
    "dow_jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones.columns = ['name','ticker', 'sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones.to_csv(f'{path}DOW_JONES.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones = pd.read_csv(f'{path}DOW_JONES.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame with all companies in american indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_sp500 = sp500['ticker']\n",
    "set_sp500 = set(emp_sp500)\n",
    "len(set_sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_nasdaq = nasdaq['ticker']\n",
    "set_nasdaq = set(emp_nasdaq)\n",
    "len(set_nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Companies in Nasdaq that aren't in sp500\n",
    "print(len(set_nasdaq.difference(set_sp500)))\n",
    "print(set_nasdaq.difference(set_sp500))\n",
    "list_nasdaq = list(set_nasdaq.difference(set_sp500))\n",
    "list_nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF with all companies in both indexes\n",
    "sp500_concat = pd.concat([sp500,nasdaq.loc[nasdaq['ticker'].isin(list_nasdaq)]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF\n",
    "sp500_concat.to_csv(f'{path}eua_all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - Company's Sector and Industry\n",
    "\n",
    "### Get sector and sub-sector of all companies using WebScrapping on Yahoo Finance website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = pd.read_csv(f'{path}IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.')\n",
    "\n",
    "ibra = ibra[['ticker','name','sector']]\n",
    "ibra[['sector','sub_industry']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua = pd.read_csv(f'{path}eua_all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua[eua['ticker'].str.contains(r'[^a-zA-Z0-9]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '.' in S&P500 ticker to '-', in order to get the right ticker for yfinance webscrapping\n",
    "eua['ticker'].replace(r'[^a-zA-Z0-9]', r'-', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the webdriver\n",
    "driver = webdriver.Chrome(options=chromeOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "wait = 8\n",
    "\n",
    "for i in eua['ticker']:\n",
    "    # Get the Yfinance company's url\n",
    "    url = f'https://finance.yahoo.com/quote/{i}/profile?p={i}'\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(wait)\n",
    "\n",
    "    # Get company's sector\n",
    "    try:\n",
    "        sector = driver.find_element(By.XPATH, '//*[@id=\"Col1-0-Profile-Proxy\"]/section/div[1]/div/div/p[2]/span[2]')\n",
    "        driver.implicitly_wait(wait)\n",
    "        eua.loc[index, 'sector'] = sector.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Get company's industry\n",
    "    try:\n",
    "        industry = driver.find_element(By.XPATH, '//*[@id=\"Col1-0-Profile-Proxy\"]/section/div[1]/div/div/p[2]/span[4]')\n",
    "        driver.implicitly_wait(wait)\n",
    "        eua.loc[index, 'sub_industry'] = industry.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Update index\n",
    "    index +=1    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if all companies in IBRA index have sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra[ibra['sector'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra[ibra['sector'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.loc[[149,151,200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.loc[149,('sector','sub_industry')] = ['Healthcare', 'Drug Manufacturers—Specialty & Generic']\n",
    "ibra.loc[151,('sector','sub_industry')] = ['Healthcare', 'Drug Manufacturers—Specialty & Generic']\n",
    "ibra.loc[200,('sector','sub_industry')] = ['Utilities', 'Utilities—Independent Power Producers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.to_csv(f'{path}IBRA_sector.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = ibra.rename({'sub_industry':'industry'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_yfinance = [f'{i}.SA' for i in ibra['ticker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['cod_yfinance'] = cod_yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['country'] = 'Brazil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if all companies in eua DataFrame have sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua['sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataframe\n",
    "eua.to_csv(f'{path}eua_all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua = eua.rename({'sub_industry':'industry'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua['cod_yfinance'] = eua['ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua['country'] = 'USA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating IBRA dataset - Obsoleto - criar novo dataframe com series históricas retiradas do yfinace para todas as empresas\n",
    "\n",
    "### (dataset that contains brazilian companies's historical data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets\n",
    "\n",
    "### Dataset that contains brazilian and american companies's characteristics\n",
    "### Dataset that contains brazilian and american companies's historical data\n",
    "### Dataset that contains brazilian and american indexes, gold, dolar (R$), bitcoin and ethereum  characteristics\n",
    "### Dataset that contains brazilian and american indexes, gold, dolar (R$), bitcoin and ethereum  historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical dataset is to big to upload to GitHub\n",
    "stock_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with all companies's characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.concat([ibra, eua], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.to_csv(f'{stock_path}all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_rev4.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with indexes, gold, dolar (R$), bitcoin and ethereum  characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ticker = [\n",
    "    'IBOV'\n",
    "    ,'IBRX50'\n",
    "    ,'NASDAQ'\n",
    "    ,'DOW JONES'\n",
    "    ,'SP500'\n",
    "    ,'GOLD'\n",
    "    ,'BTC'\n",
    "    ,'ETH'\n",
    "    ,'USD-BRL'\n",
    "]\n",
    "\n",
    "index_name = [\n",
    "    'Ibovespa'\n",
    "    ,'IBrX50'\n",
    "    ,'Nasdaq 100'\n",
    "    ,'Dow Jones Industrial Average'\n",
    "    ,'S&P 500'\n",
    "    ,'Gold (US$)'\n",
    "    ,'Bitcoin (US$)'\n",
    "    ,'Ethereum (US$)'\n",
    "    ,'Dolar (R$)'\n",
    "]\n",
    "\n",
    "index_sector = [\n",
    "    'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Gold'\n",
    "    ,'Crypto'\n",
    "    ,'Crypto'\n",
    "    ,'Currency'\n",
    "]\n",
    "\n",
    "index_industry = [\n",
    "    'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Gold'\n",
    "    ,'Crypto'\n",
    "    ,'Crypto'\n",
    "    ,'Currency'\n",
    "]\n",
    "\n",
    "index_cod = [\n",
    "    '^BVSP'\n",
    "    ,'^IBX50'\n",
    "    ,'NQ=F'\n",
    "    ,'^DJI'\n",
    "    ,'^GSPC'\n",
    "    ,'GC=F'\n",
    "    ,'BTC-USD'\n",
    "    ,'ETH-USD'\n",
    "    ,'BRL=X'\n",
    "]\n",
    "\n",
    "index_country = [\n",
    "    'Brazil'\n",
    "    ,'Brazil'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'Brazil'\n",
    "]\n",
    "\n",
    "index_type = [\n",
    "    'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Gold'\n",
    "    ,'Crypto'\n",
    "    ,'Crypto'\n",
    "    ,'Currency'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = pd.DataFrame()\n",
    "df_index['ticker'] = index_ticker\n",
    "df_index['name'] = index_name\n",
    "df_index['sector'] = index_sector\n",
    "df_index['industry'] = index_industry\n",
    "df_index['cod_yfinance'] = index_cod\n",
    "df_index['country'] = index_country\n",
    "df_index['type'] = index_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index.to_csv(f'{stock_path}all_indexes.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unificating characteristic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_and_index = pd.concat([all_companies, df_index], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_and_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_and_index.to_csv(f'{stock_path}all_companies_and_indexes.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with all companies and indexes historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty DataFrame\n",
    "historical_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with historical data of all companies\n",
    "for ticker in all_companies_and_index['cod_yfinance']:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(period='max')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    historical_data = pd.concat([historical_data, aux_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if got all companies historical data\n",
    "len(historical_data['cod_yfinance'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 2022-12-12\n",
    "historical_data = historical_data.drop(historical_data[historical_data['Date'] == datetime.date(2022,12,12)].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data[historical_data['Date'] == datetime.date(2022,12,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "historical_data.to_csv(f'{stock_path}historical_data_complete_rev5.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete5.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform index to column Date\n",
    "historical_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date to datetime\n",
    "historical_data['Date'] = pd.to_datetime(historical_data['Date'], utc=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform datetime to YYYY-MM-DD\n",
    "historical_data['Date'] = historical_data['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historical_data['cod_yfinance'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data['Open'] = historical_data['Open'].round(3)\n",
    "historical_data['High'] = historical_data['High'].round(3)\n",
    "historical_data['Low'] = historical_data['Low'].round(3)\n",
    "historical_data['Close'] = historical_data['Close'].round(3)\n",
    "historical_data['Dividends'] = historical_data['Dividends'].round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with indexes, gold, dolar (R$), bitcoin and ethereum historical data - Obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty DataFrame\n",
    "indexes_historical_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with historical data of all companies\n",
    "for ticker in df_index['cod_yfinance']:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(start='1927-12-30', end='2022-12-10')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    indexes_historical_data = pd.concat([indexes_historical_data, aux_df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_historical_data.to_csv(f'{stock_path}indexes_historical_data.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on companies sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_and_indexes.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['sector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['industry'] = all_companies['industry'].str.replace(\"—\",\" - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[all_companies['industry'].str.contains('-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agf = ['QUAL3'\n",
    ",'VVBR3'\n",
    ",'AESB3'\n",
    ",'WIZS3'\n",
    ",'BRAP3'\n",
    ",'BRSR6'\n",
    ",'BRKM5'\n",
    ",'BRAP4'\n",
    ",'BRKM3'\n",
    ",'BRSR3'\n",
    ",'CGAS5'\n",
    ",'TRPL4'\n",
    ",'VIVT3'\n",
    ",'TAEE11'\n",
    ",'TAEE4'\n",
    ",'TAEE3'\n",
    ",'CGAS3'\n",
    ",'ITSA4'\n",
    ",'CSMG3'\n",
    ",'ENAT3'\n",
    ",'ITSA3'\n",
    ",'SANB11'\n",
    ",'SANB3'\n",
    ",'SANB4'\n",
    ",'GRND3'\n",
    ",'BRSR5'\n",
    ",'TRPL3'\n",
    ",'SAPR4'\n",
    ",'SAPR3'\n",
    ",'BBSE3'\n",
    ",'CMIG4'\n",
    ",'ALUP11'\n",
    ",'CLSC3'\n",
    ",'CMIG4'\n",
    ",'ELET3'\n",
    ",'BBAS3'\n",
    ",'BBDC4'\n",
    ",'ITUB4'\n",
    ",'AMBP3'\n",
    ",'CSAN3'\n",
    ",'CSAN4'\n",
    ",'OPCT3'\n",
    ",'SBSP3'\n",
    ",'SAPR11'\n",
    ",'VERZ34'\n",
    ",'OIBR4'\n",
    ",'TIMS3'\n",
    ",'VIVT4'\n",
    ",'TELB4'\n",
    ",'TELB3'\n",
    ",'ATTB34'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[all_companies['ticker'].isin(agf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[all_companies['name'].isin(companies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[(all_companies['name'].isin(companies)) | all_companies['ticker'].isin(agf)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perennial Industry\n",
    "perennial=[\n",
    "'Utilities - Diversified'\n",
    ",'Utilities - Independent Power Producers'\n",
    ",'Utilities - Regulated Electric'\n",
    ",'Utilities - Regulated Gas'\n",
    ",'Utilities - Regulated Water'\n",
    ",'Utilities - Renewable'\n",
    ",'Banks - Diversified'\n",
    ",'Banks - Regional'\n",
    ",'Insurance - Diversified'\n",
    ",'Insurance - Life'\n",
    ",'Insurance - Property & Casualty'\n",
    ",'Insurance - Reinsurance'\n",
    ",'Insurance - Specialty'\n",
    ",'Insurance Brokers'\n",
    ",'Healthcare Plans'\n",
    ",'Telecom Services'\n",
    ",'Waste Management'\n",
    ",'Oil & Gas E&P'\n",
    ",'Oil & Gas Equipment & Services'\n",
    ",'Oil & Gas Integrated'\n",
    ",'Oil & Gas Midstream'\n",
    ",'Oil & Gas Refining & Marketing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perennial subsector\n",
    "dict_subsector = {\n",
    "'Utilities - Diversified' : 'Utilities - Electricity'\n",
    ",'Utilities - Independent Power Producers' : 'Utilities - Electricity'\n",
    ",'Utilities - Regulated Electric' : 'Utilities - Electricity'\n",
    ",'Utilities - Regulated Gas' :\t'Utilities - Gas'\n",
    ",'Utilities - Regulated Water' : 'Sanitation'\n",
    ",'Utilities - Renewable' : 'Utilities - Electricity'\n",
    ",'Banks - Diversified' : 'Banks'\n",
    ",'Banks - Regional' : 'Banks'\n",
    ",'Insurance - Diversified': 'Insurance'\n",
    ",'Insurance - Life' : 'Insurance'\n",
    ",'Insurance - Property & Casualty' : 'Insurance'\n",
    ",'Insurance - Reinsurance' : 'Insurance'\n",
    ",'Insurance - Specialty' : 'Insurance'\n",
    ",'Insurance Brokers' : 'Insurance'\n",
    ",'Healthcare Plans' : 'Health Insurance'\n",
    ",'Telecom Services' : 'Telecom'\n",
    ",'Waste Management' : 'Sanitation'\n",
    ",'Oil & Gas E&P' : 'Oil & Gas'\n",
    ",'Oil & Gas Equipment & Services' : 'Oil & Gas'\n",
    ",'Oil & Gas Integrated' : 'Oil & Gas'\n",
    ",'Oil & Gas Midstream' : 'Oil & Gas'\n",
    ",'Oil & Gas Refining & Marketing' : 'Oil & Gas'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_perennial = all_companies['industry'].isin(perennial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indetify if the company is in a perennial sector\n",
    "all_companies.loc[mask_perennial, 'perennial'] = 'Yes'\n",
    "all_companies.loc[~mask_perennial, 'perennial'] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subsector for perennial companies\n",
    "all_companies.loc[mask_perennial, 'perennial_subsector'] =  all_companies.loc[mask_perennial, 'industry'].map(dict_subsector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the company is not perennial, subsector = industry\n",
    "all_companies.loc[~mask_perennial, 'perennial_subsector'] = all_companies.loc[~mask_perennial, 'industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified DataFrame\n",
    "all_companies_rev1.to_csv(f'{stock_path}all_companies_and_indexes_rev2.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_rev2 = pd.read_csv(f'{stock_path}all_companies_and_indexes_rev1.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\05.Ironhack_Final_Project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(mysql+pymysql://root:***@localhost/stocks_project)\n"
     ]
    }
   ],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create companies Dataset in SQL\n",
    "all_companies.to_sql(name='companies', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create historical data dataset in SQL\n",
    "historical_data.to_sql(name='historical_data', con=engine, if_exists='replace', index=False) ##if_exists=append\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate historical data dataset update process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing yfinance historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_engine():\n",
    "    \"\"\"Create engine to connect to MySQL server\n",
    "\n",
    "    Returns: \n",
    "        engine (sqlalchemy.engine): engine that connects to the stocks_project dataset on MySQL Server \n",
    "    \"\"\"\n",
    "    \n",
    "    # Import sql_password\n",
    "    load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\05.Ironhack_Final_Project/password.env')\n",
    "    sql_password = os.getenv('sql_password')\n",
    "    \n",
    "    # Set SQL configurations\n",
    "    user = \"root\"\n",
    "    password = sql_password\n",
    "    url_banco = \"localhost\"\n",
    "    nome_db = \"stocks_project\"\n",
    "    conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\"  \n",
    "\n",
    "    # Create engine object\n",
    "    engine = db.create_engine(conn_str)\n",
    "    logger.info('Connection to SQL - Successful')\n",
    "\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_to_date(date, days):\n",
    "    \"\"\"Add days to a date and return the date.\n",
    "    \n",
    "    Args: \n",
    "        date (string): Date string in YYYY-MM-DD format. \n",
    "        days (int): Number of days to add to date\n",
    "    \n",
    "    Returns: \n",
    "        date (date): Date in YYYY-MM-DD with X days added. \n",
    "    \"\"\"\n",
    "    \n",
    "    added_date = pd.to_datetime(date) + timedelta(days=days)\n",
    "    added_date = added_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return added_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_update_dataframe(start, end, ticker_list):\n",
    "    \"\"\"Create a DataFrame with last days historical data.\n",
    "        Logging tracks how many entries each ticker got and save on a new .txt for each day the code runs\n",
    "    \n",
    "    Args: \n",
    "        start (string): Date string in YYYY-MM-DD format - One day after the last update \n",
    "        end (string): Date string in YYYY-MM-DD format - Today\n",
    "        ticker_list (iterable): iterable containing yfinance code for the companies and indexes\n",
    "    \n",
    "    Returns: \n",
    "        df (dataframe): DataFrame with last days historical data. \n",
    "    \"\"\"\n",
    "    \n",
    "    #Track number of entries for each ticker\n",
    "    entries_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, '7+':0 } \n",
    "    ticker_dict = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], '7+':[]}\n",
    "\n",
    "    #ticker_list = ticker_list.sort_values()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        aux_df = pd.DataFrame()\n",
    "        aux_df = yf.Ticker(ticker).history(start=start, end=end)\n",
    "\n",
    "        if aux_df.empty:\n",
    "            logging.warning(f'{ticker}: No data found for this range')\n",
    "            entries_dict[0] += 1\n",
    "            ticker_dict[0].append(ticker)\n",
    "\n",
    "        else:\n",
    "            if aux_df.shape[0] == 1:\n",
    "                entries_dict[1] += 1\n",
    "                ticker_dict[1].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 2:\n",
    "                entries_dict[2] += 1\n",
    "                ticker_dict[2].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 3:\n",
    "                entries_dict[3] += 1\n",
    "                ticker_dict[3].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 4:\n",
    "                entries_dict[4] += 1\n",
    "                ticker_dict[4].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 5:\n",
    "                entries_dict[5] += 1\n",
    "                ticker_dict[5].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 6:\n",
    "                entries_dict[6] += 1\n",
    "                ticker_dict[6].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 7:\n",
    "                entries_dict[7] += 1\n",
    "                ticker_dict[7].append(ticker)\n",
    "\n",
    "            else:\n",
    "                entries_dict['7+'] += 1\n",
    "                ticker_dict['7+'].append(ticker)\n",
    "\n",
    "            aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "        df = pd.concat([df, aux_df], axis=0)\n",
    "\n",
    "    for key, value in entries_dict.items():\n",
    "        if value == 0:\n",
    "            logger.info(f'No tickers with {key} entries')\n",
    "        else: \n",
    "            logger.info(f'Number of tickers with {key} entries: {value}')\n",
    "            logger.info(f'Tickers: {ticker_dict[key]}')\n",
    "\n",
    "    logger.info(f'Create update DataFrame - Successful: Rows in DF: {df.shape[0]}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_update_dataframe(dataframe):\n",
    "    \"\"\"Transform index to da columns with dates and round Open, High, Low, Close and Dividends columns to 3 decimal places\n",
    "    \n",
    "    Args: \n",
    "        dataframe (DataFrame): DataFrame containing last days historical data. \n",
    "    \n",
    "    Returns: \n",
    "        df (DataFrame): Formated Dataframe. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Transform the Index into Date Column\n",
    "    dataframe.reset_index(inplace= True)\n",
    "\n",
    "    # Transform 'Date' to datetime\n",
    "    dataframe['Date'] = dataframe['Date'].astype(str)\n",
    "    dataframe['Date'] = dataframe['Date'].str.extract(r'([0-9]{4}-[0-9]{2}-[0-9]{2})')\n",
    "    dataframe['Date'] = pd.to_datetime(dataframe['Date'], format='%Y-%m-%d')\n",
    "\n",
    "    dataframe = dataframe.loc[:,['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'cod_yfinance']]\n",
    "\n",
    "    # Transform datetime to YYYY-MM-DD\n",
    "    #dataframe['Date'] = dataframe['Date'].dt.date\n",
    "\n",
    "    # Round Columns\n",
    "    dataframe['Open'] = dataframe['Open'].round(3)\n",
    "    dataframe['High'] = dataframe['High'].round(3)\n",
    "    dataframe['Low'] = dataframe['Low'].round(3)\n",
    "    dataframe['Close'] = dataframe['Close'].round(3)\n",
    "    dataframe['Dividends'] = dataframe['Dividends'].round(3)\n",
    "\n",
    "    logger.info('Format update DataFrame - Successful')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_update_dataframe(dataframe, table):\n",
    "    \"\"\"Append update DataFrame to SQL dataset\n",
    "    Verify if SQL got all the rows in the DF\n",
    "\n",
    "    Args: \n",
    "        dataframe (DataFrame): DataFrame, already formated, containing last days historical data. \n",
    "    \"\"\"\n",
    "\n",
    "    rows_df = dataframe.shape[0]\n",
    "    rows_SQL = dataframe.to_sql(name=table, con=engine, if_exists='append', index=False)\n",
    "    \n",
    "    if rows_df == rows_SQL:\n",
    "        logger.info(f'SQL update successfull. All {rows_df} rows where appended to the database')\n",
    "\n",
    "    else:\n",
    "        logger.warning(f'ERROR in SQL update. Only {rows_SQL} out of {rows_df} where appended to the database')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_date(engine, table):\n",
    "    \"\"\"Get the start date to be used in 'create_update_dataframe' function\n",
    "\n",
    "    Args: \n",
    "        engine (sqlalchemy.engine): engine that connects to the stocks_project dataset on MySQL Server \n",
    "    \n",
    "    Returns: \n",
    "        start (str): date to be used in 'create_update_dataframe' function\n",
    "    \"\"\"\n",
    "\n",
    "    last_update = pd.read_sql(sql = f\"SELECT MAX(Date) FROM {table}\", con=engine)\n",
    "    start = last_update.iloc[0,0]\n",
    "    start= add_days_to_date(start, 1)\n",
    "\n",
    "    logger.info(f'Get start date - Successfull - Start date: {start}')\n",
    "\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_date():\n",
    "    \"\"\"Get yesterdays's date to be used as end date in 'create_update_dataframe' function \n",
    "\n",
    "    Returns: \n",
    "        yesterday (str): Date string in YYYY-MM-DD format - Today\n",
    "    \"\"\"\n",
    "    today = datetime.datetime.now()\n",
    "    yesterday = today - datetime.timedelta(days = 1)\n",
    "    yesterday = yesterday.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    logger.info(f'Get end date - Successful - End date: {yesterday}')\n",
    "\n",
    "    return yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_list(engine):\n",
    "    \"\"\"Get the ticker list to be used in 'create_update_dataframe' function\n",
    "\n",
    "    Args: \n",
    "        engine (sqlalchemy.engine): engine that connects to the stocks_project dataset on MySQL Server \n",
    "    \n",
    "    Returns: \n",
    "        ticker_list (iterable): iterable containing yfinance code for the companies and indexes\n",
    "    \"\"\"\n",
    "\n",
    "    ticker_list = pd.read_sql(sql='SELECT cod_yfinance FROM companies', con=engine)['cod_yfinance']\n",
    "\n",
    "    if ticker_list.shape[0] == 735:\n",
    "        logger.info(f'Get ticker list - Successful - Number of tickers: {ticker_list.shape[0]}')\n",
    "    \n",
    "    else:\n",
    "        logger.warning(f'Get ticker list - ERROR - Number of tickers expected: 735 -- Number of ticker found: {ticker_list.shape[0]}')\n",
    "\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(mysql+pymysql://root:***@localhost/stocks_project)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine()\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-12'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = get_start_date(engine, 'historical_data')\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-22'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = get_end_date()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           IPG\n",
       "1           OMC\n",
       "2      TASA4.SA\n",
       "3      EMBR3.SA\n",
       "4            BA\n",
       "         ...   \n",
       "730       ^GSPC\n",
       "731        GC=F\n",
       "732     BTC-USD\n",
       "733     ETH-USD\n",
       "734       BRL=X\n",
       "Name: cod_yfinance, Length: 735, dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_list = get_ticker_list(engine)\n",
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cod_yfinance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-12 00:00:00-05:00</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.869999</td>\n",
       "      <td>31.850000</td>\n",
       "      <td>32.860001</td>\n",
       "      <td>2766200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-13 00:00:00-05:00</th>\n",
       "      <td>33.669998</td>\n",
       "      <td>33.880001</td>\n",
       "      <td>33.099998</td>\n",
       "      <td>33.480000</td>\n",
       "      <td>4635300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-14 00:00:00-05:00</th>\n",
       "      <td>33.480000</td>\n",
       "      <td>34.080002</td>\n",
       "      <td>33.209999</td>\n",
       "      <td>33.450001</td>\n",
       "      <td>4172000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-15 00:00:00-05:00</th>\n",
       "      <td>32.790001</td>\n",
       "      <td>33.049999</td>\n",
       "      <td>32.419998</td>\n",
       "      <td>32.619999</td>\n",
       "      <td>4472300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-16 00:00:00-05:00</th>\n",
       "      <td>32.130001</td>\n",
       "      <td>32.610001</td>\n",
       "      <td>32.060001</td>\n",
       "      <td>32.459999</td>\n",
       "      <td>6686900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 00:00:00+00:00</th>\n",
       "      <td>5.080700</td>\n",
       "      <td>5.128100</td>\n",
       "      <td>5.088800</td>\n",
       "      <td>5.080700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-17 00:00:00+00:00</th>\n",
       "      <td>5.146000</td>\n",
       "      <td>5.153700</td>\n",
       "      <td>5.094900</td>\n",
       "      <td>5.146000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 00:00:00+00:00</th>\n",
       "      <td>5.099600</td>\n",
       "      <td>5.133800</td>\n",
       "      <td>5.064700</td>\n",
       "      <td>5.099600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-19 00:00:00+00:00</th>\n",
       "      <td>5.185300</td>\n",
       "      <td>5.249171</td>\n",
       "      <td>5.182400</td>\n",
       "      <td>5.185300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-20 00:00:00+00:00</th>\n",
       "      <td>5.173000</td>\n",
       "      <td>5.236600</td>\n",
       "      <td>5.164900</td>\n",
       "      <td>5.173000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20228 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2022-12-12 00:00:00-05:00  32.000000  32.869999  31.850000  32.860001   \n",
       "2022-12-13 00:00:00-05:00  33.669998  33.880001  33.099998  33.480000   \n",
       "2022-12-14 00:00:00-05:00  33.480000  34.080002  33.209999  33.450001   \n",
       "2022-12-15 00:00:00-05:00  32.790001  33.049999  32.419998  32.619999   \n",
       "2022-12-16 00:00:00-05:00  32.130001  32.610001  32.060001  32.459999   \n",
       "...                              ...        ...        ...        ...   \n",
       "2023-01-16 00:00:00+00:00   5.080700   5.128100   5.088800   5.080700   \n",
       "2023-01-17 00:00:00+00:00   5.146000   5.153700   5.094900   5.146000   \n",
       "2023-01-18 00:00:00+00:00   5.099600   5.133800   5.064700   5.099600   \n",
       "2023-01-19 00:00:00+00:00   5.185300   5.249171   5.182400   5.185300   \n",
       "2023-01-20 00:00:00+00:00   5.173000   5.236600   5.164900   5.173000   \n",
       "\n",
       "                            Volume  Dividends  Stock Splits cod_yfinance  \n",
       "Date                                                                      \n",
       "2022-12-12 00:00:00-05:00  2766200        0.0           0.0          IPG  \n",
       "2022-12-13 00:00:00-05:00  4635300        0.0           0.0          IPG  \n",
       "2022-12-14 00:00:00-05:00  4172000        0.0           0.0          IPG  \n",
       "2022-12-15 00:00:00-05:00  4472300        0.0           0.0          IPG  \n",
       "2022-12-16 00:00:00-05:00  6686900        0.0           0.0          IPG  \n",
       "...                            ...        ...           ...          ...  \n",
       "2023-01-16 00:00:00+00:00        0        0.0           0.0        BRL=X  \n",
       "2023-01-17 00:00:00+00:00        0        0.0           0.0        BRL=X  \n",
       "2023-01-18 00:00:00+00:00        0        0.0           0.0        BRL=X  \n",
       "2023-01-19 00:00:00+00:00        0        0.0           0.0        BRL=X  \n",
       "2023-01-20 00:00:00+00:00        0        0.0           0.0        BRL=X  \n",
       "\n",
       "[20228 rows x 8 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_update_dataframe(start, end, ticker_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20228 entries, 2022-12-12 00:00:00-05:00 to 2023-01-20 00:00:00+00:00\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Open          20228 non-null  float64\n",
      " 1   High          20228 non-null  float64\n",
      " 2   Low           20228 non-null  float64\n",
      " 3   Close         20228 non-null  float64\n",
      " 4   Volume        20228 non-null  int64  \n",
      " 5   Dividends     20228 non-null  float64\n",
      " 6   Stock Splits  20228 non-null  float64\n",
      " 7   cod_yfinance  20228 non-null  object \n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cod_yfinance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>32.000</td>\n",
       "      <td>32.870</td>\n",
       "      <td>31.850</td>\n",
       "      <td>32.860</td>\n",
       "      <td>2766200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>33.670</td>\n",
       "      <td>33.880</td>\n",
       "      <td>33.100</td>\n",
       "      <td>33.480</td>\n",
       "      <td>4635300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>33.480</td>\n",
       "      <td>34.080</td>\n",
       "      <td>33.210</td>\n",
       "      <td>33.450</td>\n",
       "      <td>4172000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>32.790</td>\n",
       "      <td>33.050</td>\n",
       "      <td>32.420</td>\n",
       "      <td>32.620</td>\n",
       "      <td>4472300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>32.130</td>\n",
       "      <td>32.610</td>\n",
       "      <td>32.060</td>\n",
       "      <td>32.460</td>\n",
       "      <td>6686900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20223</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>5.081</td>\n",
       "      <td>5.128</td>\n",
       "      <td>5.089</td>\n",
       "      <td>5.081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20224</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>5.146</td>\n",
       "      <td>5.154</td>\n",
       "      <td>5.095</td>\n",
       "      <td>5.146</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20225</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>5.100</td>\n",
       "      <td>5.134</td>\n",
       "      <td>5.065</td>\n",
       "      <td>5.100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20226</th>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>5.185</td>\n",
       "      <td>5.249</td>\n",
       "      <td>5.182</td>\n",
       "      <td>5.185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20227</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>5.173</td>\n",
       "      <td>5.237</td>\n",
       "      <td>5.165</td>\n",
       "      <td>5.173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20228 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close   Volume  Dividends  \\\n",
       "0     2022-12-12  32.000  32.870  31.850  32.860  2766200        0.0   \n",
       "1     2022-12-13  33.670  33.880  33.100  33.480  4635300        0.0   \n",
       "2     2022-12-14  33.480  34.080  33.210  33.450  4172000        0.0   \n",
       "3     2022-12-15  32.790  33.050  32.420  32.620  4472300        0.0   \n",
       "4     2022-12-16  32.130  32.610  32.060  32.460  6686900        0.0   \n",
       "...          ...     ...     ...     ...     ...      ...        ...   \n",
       "20223 2023-01-16   5.081   5.128   5.089   5.081        0        0.0   \n",
       "20224 2023-01-17   5.146   5.154   5.095   5.146        0        0.0   \n",
       "20225 2023-01-18   5.100   5.134   5.065   5.100        0        0.0   \n",
       "20226 2023-01-19   5.185   5.249   5.182   5.185        0        0.0   \n",
       "20227 2023-01-20   5.173   5.237   5.165   5.173        0        0.0   \n",
       "\n",
       "       Stock Splits cod_yfinance  \n",
       "0               0.0          IPG  \n",
       "1               0.0          IPG  \n",
       "2               0.0          IPG  \n",
       "3               0.0          IPG  \n",
       "4               0.0          IPG  \n",
       "...             ...          ...  \n",
       "20223           0.0        BRL=X  \n",
       "20224           0.0        BRL=X  \n",
       "20225           0.0        BRL=X  \n",
       "20226           0.0        BRL=X  \n",
       "20227           0.0        BRL=X  \n",
       "\n",
       "[20228 rows x 9 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = format_update_dataframe(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20228 entries, 0 to 20227\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          20228 non-null  datetime64[ns]\n",
      " 1   Open          20228 non-null  float64       \n",
      " 2   High          20228 non-null  float64       \n",
      " 3   Low           20228 non-null  float64       \n",
      " 4   Close         20228 non-null  float64       \n",
      " 5   Volume        20228 non-null  int64         \n",
      " 6   Dividends     20228 non-null  float64       \n",
      " 7   Stock Splits  20228 non-null  float64       \n",
      " 8   cod_yfinance  20228 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(6), int64(1), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_update_dataframe(df, 'historical_data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_and_indexes_rev2.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete_rev5.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks\n",
    "country_br = all_companies['country'] == 'Brazil'\n",
    "country_usa = all_companies['country'] == 'USA'\n",
    "\n",
    "type_company = all_companies['type'] == 'Company'\n",
    "type_index = all_companies['type'] == 'Index'\n",
    "type_gold = all_companies['type'] == 'Gold'\n",
    "type_crypto = all_companies['type'] == 'Crypto'\n",
    "type_currency = all_companies['type'] == 'Currency'\n",
    "\n",
    "perennial = all_companies['perennial'] == 'Yes'\n",
    "\n",
    "subsector_uti_elec = all_companies['perennial_subsector'] == 'Utilities - Electricity'\n",
    "subsector_uti_gas = all_companies['perennial_subsector'] == 'Utilities - Gas'\n",
    "subsector_sanit = all_companies['perennial_subsector'] == 'Sanitation'\n",
    "subsector_banks = all_companies['perennial_subsector'] == 'Banks'\n",
    "subsector_insurance = all_companies['perennial_subsector'] == 'Insurance'\n",
    "subsector_healh_ins = all_companies['perennial_subsector'] == 'Health Insurance'\n",
    "subsector_telecom = all_companies['perennial_subsector'] == 'Telecom'\n",
    "subsector_oil = all_companies['perennial_subsector'] == 'Oil & Gas'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified DataFrame\n",
    "all_companies.to_csv(f'{stock_path}all_companies_and_indexes_rev3.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_and_indexes_rev3.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified DataFrame\n",
    "historical_data.to_csv(f'{stock_path}historical_data_complete_rev8.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete_rev8.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks\n",
    "country_br = all_companies['country'] == 'Brazil'\n",
    "country_usa = all_companies['country'] == 'USA'\n",
    "\n",
    "type_company = all_companies['type'] == 'Company'\n",
    "type_index = all_companies['type'] == 'Index'\n",
    "type_gold = all_companies['type'] == 'Gold'\n",
    "type_crypto = all_companies['type'] == 'Crypto'\n",
    "type_currency = all_companies['type'] == 'Currency'\n",
    "\n",
    "perennial = all_companies['perennial'] == 'Yes'\n",
    "\n",
    "subsector_uti_elec = all_companies['perennial_subsector'] == 'Utilities - Electricity'\n",
    "subsector_uti_gas = all_companies['perennial_subsector'] == 'Utilities - Gas'\n",
    "subsector_sanit = all_companies['perennial_subsector'] == 'Sanitation'\n",
    "subsector_banks = all_companies['perennial_subsector'] == 'Banks'\n",
    "subsector_insurance = all_companies['perennial_subsector'] == 'Insurance'\n",
    "subsector_healh_ins = all_companies['perennial_subsector'] == 'Health Insurance'\n",
    "subsector_telecom = all_companies['perennial_subsector'] == 'Telecom'\n",
    "subsector_oil = all_companies['perennial_subsector'] == 'Oil & Gas'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisys on Companies DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_barsi = [\n",
    "'AESB3'\n",
    ",'BBDC3'\n",
    ",'BBSE3'\n",
    ",'BRAP3'\n",
    ",'BRKM5'\n",
    ",'BRSR6'\n",
    ",'CSMG3'\n",
    ",'ENAT3'\n",
    ",'GRND3'\n",
    ",'ITSA4'\n",
    ",'ITUB3'\n",
    ",'QUAL3'\n",
    ",'PSSA3'\n",
    ",'SANB11'\n",
    ",'SAPR11'\n",
    ",'TAEE11'\n",
    ",'TRPL4'\n",
    ",'VIVT3'\n",
    ",'WIZS3'\n",
    ",'VBBR3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks\n",
    "country_br = all_companies['country'] == 'Brazil'\n",
    "country_usa = all_companies['country'] == 'USA'\n",
    "\n",
    "type_company = all_companies['type'] == 'Company'\n",
    "type_index = all_companies['type'] == 'Index'\n",
    "type_gold = all_companies['type'] == 'Gold'\n",
    "type_crypto = all_companies['type'] == 'Crypto'\n",
    "type_currency = all_companies['type'] == 'Currency'\n",
    "\n",
    "perennial = all_companies['perennial'] == 'Yes'\n",
    "\n",
    "subsector_uti_elec = all_companies['perennial_subsector'] == 'Utilities - Electricity'\n",
    "subsector_uti_gas = all_companies['perennial_subsector'] == 'Utilities - Gas'\n",
    "subsector_sanit = all_companies['perennial_subsector'] == 'Sanitation'\n",
    "subsector_banks = all_companies['perennial_subsector'] == 'Banks'\n",
    "subsector_insurance = all_companies['perennial_subsector'] == 'Insurance'\n",
    "subsector_healh_ins = all_companies['perennial_subsector'] == 'Health Insurance'\n",
    "subsector_telecom = all_companies['perennial_subsector'] == 'Telecom'\n",
    "subsector_oil = all_companies['perennial_subsector'] == 'Oil & Gas'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_usa & type_company, 'sector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_usa & type_company & (all_companies['sector'] == 'Real Estate' )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[country_br & type_company & all_companies['ticker'].str.contains('SAP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_br & type_company & (all_companies['perennial_subsector']=='Health Insurance')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_br & type_company & all_companies['ticker'].isin(top_20_barsi), 'perennial_subsector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data[(historical_data['Date'] == '2008-01-02') & (historical_data['cod_yfinance'].isin(all_companies.loc[country_br & type_company & all_companies['ticker'].isin(top_20_barsi), 'cod_yfinance']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Date'] == '2008-01-02') & (historical_data['cod_yfinance'].isin(all_companies.loc[country_br & type_company, 'cod_yfinance']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_subsector_pbi = {\n",
    "'Utilities - Diversified' : 'Electricity'\n",
    ",'Utilities - Independent Power Producers' : 'Electricity'\n",
    ",'Utilities - Regulated Electric' : 'Electricity'\n",
    ",'Utilities - Regulated Gas' :\t'Utilities - Gas'\n",
    ",'Utilities - Regulated Water' : 'Sanitation'\n",
    ",'Utilities - Renewable' : 'Electricity'\n",
    ",'Banks - Diversified' : 'Banks'\n",
    ",'Banks - Regional' : 'Banks'\n",
    ",'Insurance - Diversified': 'Insurance'\n",
    ",'Insurance - Life' : 'Insurance'\n",
    ",'Insurance - Property & Casualty' : 'Insurance'\n",
    ",'Insurance - Reinsurance' : 'Insurance'\n",
    ",'Insurance - Specialty' : 'Insurance'\n",
    ",'Insurance Brokers' : 'Insurance'\n",
    ",'Healthcare Plans' : 'Health Insurance'\n",
    ",'Telecom Services' : 'Telecom'\n",
    ",'Waste Management' : 'Sanitation'\n",
    ",'Oil & Gas E&P' : 'Oil & Gas'\n",
    ",'Oil & Gas Equipment & Services' : 'Oil & Gas'\n",
    ",'Oil & Gas Integrated' : 'Oil & Gas'\n",
    ",'Oil & Gas Midstream' : 'Oil & Gas'\n",
    ",'Oil & Gas Refining & Marketing' : 'Oil & Gas'\n",
    ",'Real Estate - Development' : 'Construction'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_br & type_company & perennial, 'pbi_sector_analysis'] = all_companies['industry'].map(dict_subsector_pbi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "148dec39413d40c2e0b225421a61564057689d91bfcabc655e2b03b1997f7cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
