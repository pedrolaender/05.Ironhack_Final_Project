{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flask-sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install html5lib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#from unidecode import unidecode\n",
    "import re\n",
    "import os\n",
    "import yfinance as yf\n",
    "from time import sleep\n",
    "import glob\n",
    "import regex as re\n",
    "import datetime\n",
    "import sqlalchemy as db\n",
    "from dotenv import load_dotenv\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining file's path\n",
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\Ironhack_Final_Project\\data/'\n",
    "# Historical dataset is to big to upload to GitHub\n",
    "stock_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets/'\n",
    "# Logging path\n",
    "logging_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets\\Logging/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - Brazilian Companies\n",
    "\n",
    "### List of brazilian companies and composition of indexes - Ibovespa, IBrX100, IBrX50, IBrA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium\n",
    "\n",
    "Used to get list of companies in brazilian's index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurating WebDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurating download file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromeOptions = webdriver.ChromeOptions()\n",
    "download_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project\\data'\n",
    "prefs = {\"download.default_directory\" : download_path}\n",
    "chromeOptions.add_experimental_option(\"prefs\",prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the webdriver\n",
    "driver = webdriver.Chrome(options=chromeOptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Index File (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_stocks(index, wait=6):\n",
    "    '''\n",
    "        Receives the Index name, download a file that contains the index tickers, and return the name of the downloaded file\n",
    "    '''\n",
    "\n",
    "    # Chrome WebDriver opens the index webside\n",
    "    url = f'https://sistemaswebb3-listados.b3.com.br/indexPage/day/{index.upper()}?language=pt-br'\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(wait)\n",
    "\n",
    "    driver.find_element(By.ID, 'segment').send_keys(\"Setor de Atuação\")\n",
    "    driver.implicitly_wait(wait)\n",
    "    driver.find_element(By.LINK_TEXT, 'Download').click()\n",
    "    driver.implicitly_wait(wait)\n",
    "\n",
    "    # Set the directory\n",
    "    os.chdir(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project\\data')\n",
    "    sleep(wait)\n",
    "\n",
    "    # Get the .csv files from the selectec directory and sort them ascending by modification date \n",
    "    files = list(glob.glob('*csv'))\n",
    "    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "\n",
    "    # Returns the name of the most recent file\n",
    "    return files[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Index DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(file):\n",
    "    '''\n",
    "        This function receives the name of the Stock Exchange index and returns a DataFrame with all companies and their respective sectors\n",
    "    '''\n",
    "\n",
    "    # Creating DataFrame\n",
    "    DataFrame = pd.read_csv(file, \n",
    "                                encoding='ISO-8859-1',\n",
    "                                header=1,                   # Uses line 1 as header\n",
    "                                sep=';',                    \n",
    "                                decimal=',',\n",
    "                                thousands='.',\n",
    "                                skipfooter=2,               # Removes last 2 lines\n",
    "                                engine='python',\n",
    "                                index_col=False)            # Does not make first column as index\n",
    "    \n",
    "    # Normalizing columns\n",
    "    DataFrame.columns = [re.sub('[\\.()]', '', re.sub(' ', '_', unidecode(columns.lower()))) for columns in DataFrame.columns]\n",
    "\n",
    "    return DataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Index's DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining file's path\n",
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project\\data/'\n",
    "# Historical dataset is to big to upload to GitHub\n",
    "stock_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining DataFrames' columns names\n",
    "col_names = [\n",
    "    'sector',\n",
    "    'ticker',\n",
    "    'name',\n",
    "    'type',\n",
    "    'amount',\n",
    "    'percentage',\n",
    "    'percentage_acum'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ibovespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov = create_df(get_index_stocks('ibov'))\n",
    "len(ibov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibov.to_csv(f'{path}IBOV.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov = pd.read_csv(f'{path}IBOV.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBrX100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx = create_df(get_index_stocks('ibxx'))\n",
    "len(ibrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibrx.to_csv(f'{path}IBRX100.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBrX50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx50 = create_df(get_index_stocks('ibxl'))\n",
    "len(ibrx50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx50.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibrx50.to_csv(f'{path}IBRX50.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBrA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = create_df(get_index_stocks('ibra'))\n",
    "len(ibra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibra.to_csv(f'{path}IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking companies that differ in the two indexes - Obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ibrx = ibrx['codigo']\n",
    "set_ibrx = set(emp_ibrx)\n",
    "len(set_ibrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ibov = ibov['codigo']\n",
    "set_ibov = set(emp_ibov)\n",
    "len(set_ibov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ibra = ibra['codigo']\n",
    "set_ibra = set(emp_ibra)\n",
    "len(set_ibra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set_ibra.difference(set_ibrx)))\n",
    "print(set_ibra.difference(set_ibrx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set_ibov.difference(set_ibrx)))\n",
    "print(set_ibov.difference(set_ibrx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set_ibrx.difference(set_ibov)))\n",
    "print(set_ibrx.difference(set_ibov))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - Brazilian Companies Historical Dataset - Obsolete (All data gathered from Yfinance)\n",
    "\n",
    "### Create dataset concatenating historical datasets downloaded from B3 website with data from the companies listed in IBRA Index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list with main companies ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using companies in IBRA Index\n",
    "codigo = list(set_ibra)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\data_visualization\\data/'\n",
    "\n",
    "i = 1986\n",
    "\n",
    "while i < 2000:\n",
    "    with zipfile.ZipFile(f'{path}COTAHIST_A{i}.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "    i +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2000\n",
    "\n",
    "while i < 2022:\n",
    "    os.rename(f'COTAHIST_A{i}.TXT', f'COTAHIST_A{i}.txt')\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting configurations to read B3 historical files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.max_columns=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\B3\\txt/'\n",
    "\n",
    "year = 2022\n",
    "\n",
    "widths = [2,8,2,12,3,12,10,3,4,13,13,13,13,13,13,13,5,18,18,13,1,8,7,13,12,3]\n",
    "\n",
    "col_names = [\n",
    "\"tipo_registro\",\n",
    "\"data_pregao\",\n",
    "\"cod_bdi\",\n",
    "\"cod_negociacao\",\n",
    "\"tipo_mercado\",\n",
    "\"nome_empresa\",\n",
    "\"especificacao_papel\",\n",
    "\"prazo_dias_merc_termo\",\n",
    "\"moeda_referencia\",\n",
    "\"preco_abertura\",\n",
    "\"preco_maximo\",\n",
    "\"preco_minimo\",\n",
    "\"preco_medio\",\n",
    "\"preco_ultimo_negocio\",\n",
    "\"preco_melhor_oferta_compra\",\n",
    "\"preco_melhor_oferta_venda\",\n",
    "\"numero_negocios\",\n",
    "\"quantidade_papeis_negociados\",\n",
    "\"volume_total_negociado\",\n",
    "\"preco_exercicio\",\n",
    "\"ìndicador_correcao_precos\",\n",
    "\"data_vencimento\" ,\n",
    "\"fator_cotacao\",\n",
    "\"preco_exercicio_pontos\",\n",
    "\"codigo_isin\",\n",
    "\"num_distribuicao_papel\"]\n",
    "\n",
    "decimal_config=[\n",
    "\"preco_abertura\",\n",
    "\"preco_maximo\",\n",
    "\"preco_minimo\",\n",
    "\"preco_medio\",\n",
    "\"preco_ultimo_negocio\",\n",
    "\"preco_melhor_oferta_compra\",\n",
    "\"preco_melhor_oferta_venda\",\n",
    "\"volume_total_negociado\",\n",
    "\"preco_exercicio\",\n",
    "\"preco_exercicio_pontos\"\n",
    "]\n",
    "\n",
    "\n",
    "remains = [\n",
    "\"data_pregao\",\n",
    "\"cod_negociacao\",\n",
    "\"tipo_mercado\",\n",
    "\"nome_empresa\",\n",
    "\"preco_abertura\",\n",
    "\"preco_maximo\",\n",
    "\"preco_minimo\",\n",
    "\"preco_medio\",\n",
    "\"preco_ultimo_negocio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     Concatenate DataFrames\n",
    "year = 2022\n",
    "while year > 1985:\n",
    "    df = pd.read_fwf(f'{path}COTAHIST_A{year}.TXT',\n",
    "                                    encoding='ISO-8859-1',\n",
    "                                    header=0,\n",
    "                                    widths=widths,\n",
    "                                    skipfooter=1,\n",
    "                                    engine='python',\n",
    "                                    parse_dates=[1],\n",
    "                                    infer_datetime_format=True,\n",
    "                                    index_col=False)\n",
    "    year -= 1\n",
    "\n",
    "    #Definindo nomes das colunas\n",
    "    df.columns = col_names\n",
    "\n",
    "    #Corrigindo casas decimais\n",
    "    for col in decimal_config:\n",
    "        df[col]=df[col]/100\n",
    "\n",
    "    #Selecionando colunas\n",
    "    df = df[remains]\n",
    "    \n",
    "    #Mascara de empresas desejadas\n",
    "    mask_empresas = df.cod_negociacao.isin(codigo)\n",
    "\n",
    "    df = df[mask_empresas]\n",
    "\n",
    "    dataset = pd.concat([dataset, df], ignore_index=True)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export DF - Historical Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(f'{path}dataset_IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f'{path}dataset_IBRA.csv',\n",
    "                encoding='ISO-8859-1',\n",
    "                sep=';',\n",
    "                decimal='.',\n",
    "                index_col=False\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data From Yahoo Finance\n",
    "\n",
    "### Get historical series of brazilian and american indexes\n",
    "### Get historical series of Gold, Bitcoin and Ethererum\n",
    "### Get historical series of american companies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set YFinance setting\n",
    "\n",
    "symbol_list_br = ['^BVSP','^IBX50']\n",
    "symbol_list_eua = ['^DJI','^IXIC','^GSPC','GC=F']\n",
    "symbol_list_crypto = ['BTC-USD', 'ETH-USD']\n",
    "\n",
    "name_dict={\n",
    "    '^BVSP':'Ibovespa',\n",
    "    '^IBX50':'IBrX50',\n",
    "    '^DJI':'Dow Jones',\n",
    "    '^IXIC':'NASDAQ',\n",
    "    '^GSPC':'S&P 500',\n",
    "    'GC=F':'Ouro ($)',\n",
    "    'BTC-USD':'Bitcoin ($)',\n",
    "    'ETH-USD':'Ethereum ($)'\n",
    "}\n",
    "\n",
    "col_names = ['date',\n",
    "\"open\",\n",
    "\"high\",\n",
    "\"low\",\n",
    "\"close\",\n",
    "'cod_yfinance']\n",
    "\n",
    "drop_col = ['Volume','Dividends','Stock Splits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty indexes DataFrames\n",
    "'''\n",
    "df_br = pd.DataFrame()\n",
    "df_eua = pd.DataFrame()\n",
    "df_crypto = pd.DataFrame()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill brazilian indexes historical series dataset\n",
    "'''\n",
    "for ativo in symbol_list_br:\n",
    "        chamada_api = yf.Ticker(ativo).history(period='max')\n",
    "        chamada_api['cod_yfinace'] = ativo\n",
    "        df_br = pd.concat([df_br, chamada_api])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform data from index to column 0\n",
    "'''\n",
    "df_br = df_br.drop(drop_col, axis = 1)\n",
    "df_br.reset_index(inplace=True)\n",
    "df_br['Date'] = df_br['Date'].dt.date\n",
    "df_br.columns = col_names\n",
    "df_br\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put indexes names in the DF\n",
    "df_br['name'] = df_br['cod_yfinance'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reroder columns\n",
    "df_br = df_br[['date','name','open','high','low','close','cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "df_br.to_csv(f'{path}index_br.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame\n",
    "index_br = pd.read_csv(f'{path}index_br.csv',\n",
    "                    sep = ';',\n",
    "                    decimal = '.',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill american indexes and gold historical series dataset\n",
    "'''\n",
    "for ativo in symbol_list_eua:\n",
    "        chamada_api = yf.Ticker(ativo).history(period='max')\n",
    "        chamada_api['cod_yfinance'] = ativo\n",
    "        df_eua = pd.concat([df_eua, chamada_api])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform data from index to column 0\n",
    "'''\n",
    "df_eua = df_eua.drop(drop_col, axis = 1)\n",
    "df_eua.reset_index(inplace=True)\n",
    "df_eua['Date'] = df_eua['Date'].dt.date\n",
    "df_eua.columns = col_names\n",
    "df_eua\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put indexes names in the DF\n",
    "df_eua['name'] = df_eua['cod_yfinance'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_eua = df_eua[['date','name','open','high','low','close','cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "df_eua.to_csv(f'{path}index_eua.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame\n",
    "index_eua = pd.read_csv(f'{path}index_eua.csv',\n",
    "                    sep = ';',\n",
    "                    decimal = '.',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill cripto historical series dataset\n",
    "'''\n",
    "for ativo in symbol_list_crypto:\n",
    "        chamada_api = yf.Ticker(ativo).history(period='max')\n",
    "        chamada_api['cod_yfinace'] = ativo\n",
    "        df_crypto = pd.concat([df_crypto, chamada_api])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform data from index to column 0\n",
    "'''\n",
    "df_crypto = df_crypto.drop(drop_col, axis = 1)\n",
    "df_crypto.reset_index(inplace=True)\n",
    "df_crypto['Date'] = df_crypto['Date'].dt.date\n",
    "df_crypto.columns = col_names\n",
    "df_crypto\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put indexes names in the DF\n",
    "df_crypto['name'] = df_crypto['cod_yfinance'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_crypto = df_crypto[['date','name','open','high','low','close','cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crypto.to_csv(f'{path}crypto.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = pd.read_csv(f'{path}crypto.csv',\n",
    "                    sep = ';',\n",
    "                    decimal = '.',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - American Companies\n",
    "\n",
    "### List of american companies and composition of indexes - S&P500, Dow Jones, Nasdaq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = data[0].iloc[:,[0,1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.columns = ['ticker', 'name', 'sector', 'sub_industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.to_csv(f'{path}SP500.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv(f'{path}SP500.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Nasdaq-100'\n",
    "\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[4]\n",
    "nasdaq = data[4]\n",
    "nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq.columns = ['name','ticker', 'sector', 'sub_industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq.to_csv(f'{path}NASDAQ.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = pd.read_csv(f'{path}NASDAQ.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dow Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average'\n",
    "\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]\n",
    "dow_jones = data[1].iloc[:,[0,2,3]]\n",
    "dow_jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones.columns = ['name','ticker', 'sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones.to_csv(f'{path}DOW_JONES.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones = pd.read_csv(f'{path}DOW_JONES.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame with all companies in american indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_sp500 = sp500['ticker']\n",
    "set_sp500 = set(emp_sp500)\n",
    "len(set_sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_nasdaq = nasdaq['ticker']\n",
    "set_nasdaq = set(emp_nasdaq)\n",
    "len(set_nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Companies in Nasdaq that aren't in sp500\n",
    "print(len(set_nasdaq.difference(set_sp500)))\n",
    "print(set_nasdaq.difference(set_sp500))\n",
    "list_nasdaq = list(set_nasdaq.difference(set_sp500))\n",
    "list_nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF with all companies in both indexes\n",
    "sp500_concat = pd.concat([sp500,nasdaq.loc[nasdaq['ticker'].isin(list_nasdaq)]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF\n",
    "sp500_concat.to_csv(f'{path}eua_all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - Company's Sector and Industry\n",
    "\n",
    "### Get sector and sub-sector of all companies using WebScrapping on Yahoo Finance website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = pd.read_csv(f'{path}IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.')\n",
    "\n",
    "ibra = ibra[['ticker','name','sector']]\n",
    "ibra[['sector','sub_industry']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua = pd.read_csv(f'{path}eua_all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua[eua['ticker'].str.contains(r'[^a-zA-Z0-9]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '.' in S&P500 ticker to '-', in order to get the right ticker for yfinance webscrapping\n",
    "eua['ticker'].replace(r'[^a-zA-Z0-9]', r'-', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the webdriver\n",
    "driver = webdriver.Chrome(options=chromeOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "wait = 8\n",
    "\n",
    "for i in eua['ticker']:\n",
    "    # Get the Yfinance company's url\n",
    "    url = f'https://finance.yahoo.com/quote/{i}/profile?p={i}'\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(wait)\n",
    "\n",
    "    # Get company's sector\n",
    "    try:\n",
    "        sector = driver.find_element(By.XPATH, '//*[@id=\"Col1-0-Profile-Proxy\"]/section/div[1]/div/div/p[2]/span[2]')\n",
    "        driver.implicitly_wait(wait)\n",
    "        eua.loc[index, 'sector'] = sector.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Get company's industry\n",
    "    try:\n",
    "        industry = driver.find_element(By.XPATH, '//*[@id=\"Col1-0-Profile-Proxy\"]/section/div[1]/div/div/p[2]/span[4]')\n",
    "        driver.implicitly_wait(wait)\n",
    "        eua.loc[index, 'sub_industry'] = industry.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Update index\n",
    "    index +=1    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if all companies in IBRA index have sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra[ibra['sector'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra[ibra['sector'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.loc[[149,151,200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.loc[149,('sector','sub_industry')] = ['Healthcare', 'Drug Manufacturers—Specialty & Generic']\n",
    "ibra.loc[151,('sector','sub_industry')] = ['Healthcare', 'Drug Manufacturers—Specialty & Generic']\n",
    "ibra.loc[200,('sector','sub_industry')] = ['Utilities', 'Utilities—Independent Power Producers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.to_csv(f'{path}IBRA_sector.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = ibra.rename({'sub_industry':'industry'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_yfinance = [f'{i}.SA' for i in ibra['ticker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['cod_yfinance'] = cod_yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['country'] = 'Brazil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if all companies in eua DataFrame have sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua['sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataframe\n",
    "eua.to_csv(f'{path}eua_all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua = eua.rename({'sub_industry':'industry'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua['cod_yfinance'] = eua['ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua['country'] = 'USA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating IBRA dataset - Obsoleto - criar novo dataframe com series históricas retiradas do yfinace para todas as empresas\n",
    "\n",
    "### (dataset that contains brazilian companies's historical data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets\n",
    "\n",
    "### Dataset that contains brazilian and american companies's characteristics\n",
    "### Dataset that contains brazilian and american companies's historical data\n",
    "### Dataset that contains brazilian and american indexes, gold, dolar (R$), bitcoin and ethereum  characteristics\n",
    "### Dataset that contains brazilian and american indexes, gold, dolar (R$), bitcoin and ethereum  historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical dataset is to big to upload to GitHub\n",
    "stock_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with all companies's characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.concat([ibra, eua], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.to_csv(f'{stock_path}all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_rev4.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with indexes, gold, dolar (R$), bitcoin and ethereum  characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ticker = [\n",
    "    'IBOV'\n",
    "    ,'IBRX50'\n",
    "    ,'NASDAQ'\n",
    "    ,'DOW JONES'\n",
    "    ,'SP500'\n",
    "    ,'GOLD'\n",
    "    ,'BTC'\n",
    "    ,'ETH'\n",
    "    ,'USD-BRL'\n",
    "]\n",
    "\n",
    "index_name = [\n",
    "    'Ibovespa'\n",
    "    ,'IBrX50'\n",
    "    ,'Nasdaq 100'\n",
    "    ,'Dow Jones Industrial Average'\n",
    "    ,'S&P 500'\n",
    "    ,'Gold (US$)'\n",
    "    ,'Bitcoin (US$)'\n",
    "    ,'Ethereum (US$)'\n",
    "    ,'Dolar (R$)'\n",
    "]\n",
    "\n",
    "index_sector = [\n",
    "    'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Gold'\n",
    "    ,'Crypto'\n",
    "    ,'Crypto'\n",
    "    ,'Currency'\n",
    "]\n",
    "\n",
    "index_industry = [\n",
    "    'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Gold'\n",
    "    ,'Crypto'\n",
    "    ,'Crypto'\n",
    "    ,'Currency'\n",
    "]\n",
    "\n",
    "index_cod = [\n",
    "    '^BVSP'\n",
    "    ,'^IBX50'\n",
    "    ,'NQ=F'\n",
    "    ,'^DJI'\n",
    "    ,'^GSPC'\n",
    "    ,'GC=F'\n",
    "    ,'BTC-USD'\n",
    "    ,'ETH-USD'\n",
    "    ,'BRL=X'\n",
    "]\n",
    "\n",
    "index_country = [\n",
    "    'Brazil'\n",
    "    ,'Brazil'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'Brazil'\n",
    "]\n",
    "\n",
    "index_type = [\n",
    "    'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Gold'\n",
    "    ,'Crypto'\n",
    "    ,'Crypto'\n",
    "    ,'Currency'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = pd.DataFrame()\n",
    "df_index['ticker'] = index_ticker\n",
    "df_index['name'] = index_name\n",
    "df_index['sector'] = index_sector\n",
    "df_index['industry'] = index_industry\n",
    "df_index['cod_yfinance'] = index_cod\n",
    "df_index['country'] = index_country\n",
    "df_index['type'] = index_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index.to_csv(f'{stock_path}all_indexes.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unificating characteristic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_and_index = pd.concat([all_companies, df_index], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_and_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_and_index.to_csv(f'{stock_path}all_companies_and_indexes.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with all companies and indexes historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty DataFrame\n",
    "historical_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with historical data of all companies\n",
    "for ticker in all_companies_and_index['cod_yfinance']:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(period='max')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    historical_data = pd.concat([historical_data, aux_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if got all companies historical data\n",
    "len(historical_data['cod_yfinance'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 2022-12-12\n",
    "historical_data = historical_data.drop(historical_data[historical_data['Date'] == datetime.date(2022,12,12)].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data[historical_data['Date'] == datetime.date(2022,12,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "historical_data.to_csv(f'{stock_path}historical_data_complete_rev5.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete5.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform index to column Date\n",
    "historical_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date to datetime\n",
    "historical_data['Date'] = pd.to_datetime(historical_data['Date'], utc=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform datetime to YYYY-MM-DD\n",
    "historical_data['Date'] = historical_data['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historical_data['cod_yfinance'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data['Open'] = historical_data['Open'].round(3)\n",
    "historical_data['High'] = historical_data['High'].round(3)\n",
    "historical_data['Low'] = historical_data['Low'].round(3)\n",
    "historical_data['Close'] = historical_data['Close'].round(3)\n",
    "historical_data['Dividends'] = historical_data['Dividends'].round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with indexes, gold, dolar (R$), bitcoin and ethereum historical data - Obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty DataFrame\n",
    "indexes_historical_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with historical data of all companies\n",
    "for ticker in df_index['cod_yfinance']:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(start='1927-12-30', end='2022-12-10')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    indexes_historical_data = pd.concat([indexes_historical_data, aux_df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_historical_data.to_csv(f'{stock_path}indexes_historical_data.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on companies sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_and_indexes.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['sector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['industry'] = all_companies['industry'].str.replace(\"—\",\" - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[all_companies['industry'].str.contains('-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agf = ['QUAL3'\n",
    ",'VVBR3'\n",
    ",'AESB3'\n",
    ",'WIZS3'\n",
    ",'BRAP3'\n",
    ",'BRSR6'\n",
    ",'BRKM5'\n",
    ",'BRAP4'\n",
    ",'BRKM3'\n",
    ",'BRSR3'\n",
    ",'CGAS5'\n",
    ",'TRPL4'\n",
    ",'VIVT3'\n",
    ",'TAEE11'\n",
    ",'TAEE4'\n",
    ",'TAEE3'\n",
    ",'CGAS3'\n",
    ",'ITSA4'\n",
    ",'CSMG3'\n",
    ",'ENAT3'\n",
    ",'ITSA3'\n",
    ",'SANB11'\n",
    ",'SANB3'\n",
    ",'SANB4'\n",
    ",'GRND3'\n",
    ",'BRSR5'\n",
    ",'TRPL3'\n",
    ",'SAPR4'\n",
    ",'SAPR3'\n",
    ",'BBSE3'\n",
    ",'CMIG4'\n",
    ",'ALUP11'\n",
    ",'CLSC3'\n",
    ",'CMIG4'\n",
    ",'ELET3'\n",
    ",'BBAS3'\n",
    ",'BBDC4'\n",
    ",'ITUB4'\n",
    ",'AMBP3'\n",
    ",'CSAN3'\n",
    ",'CSAN4'\n",
    ",'OPCT3'\n",
    ",'SBSP3'\n",
    ",'SAPR11'\n",
    ",'VERZ34'\n",
    ",'OIBR4'\n",
    ",'TIMS3'\n",
    ",'VIVT4'\n",
    ",'TELB4'\n",
    ",'TELB3'\n",
    ",'ATTB34'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[all_companies['ticker'].isin(agf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[all_companies['name'].isin(companies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[(all_companies['name'].isin(companies)) | all_companies['ticker'].isin(agf)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perennial Industry\n",
    "perennial=[\n",
    "'Utilities - Diversified'\n",
    ",'Utilities - Independent Power Producers'\n",
    ",'Utilities - Regulated Electric'\n",
    ",'Utilities - Regulated Gas'\n",
    ",'Utilities - Regulated Water'\n",
    ",'Utilities - Renewable'\n",
    ",'Banks - Diversified'\n",
    ",'Banks - Regional'\n",
    ",'Insurance - Diversified'\n",
    ",'Insurance - Life'\n",
    ",'Insurance - Property & Casualty'\n",
    ",'Insurance - Reinsurance'\n",
    ",'Insurance - Specialty'\n",
    ",'Insurance Brokers'\n",
    ",'Healthcare Plans'\n",
    ",'Telecom Services'\n",
    ",'Waste Management'\n",
    ",'Oil & Gas E&P'\n",
    ",'Oil & Gas Equipment & Services'\n",
    ",'Oil & Gas Integrated'\n",
    ",'Oil & Gas Midstream'\n",
    ",'Oil & Gas Refining & Marketing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perennial subsector\n",
    "dict_subsector = {\n",
    "'Utilities - Diversified' : 'Utilities - Electricity'\n",
    ",'Utilities - Independent Power Producers' : 'Utilities - Electricity'\n",
    ",'Utilities - Regulated Electric' : 'Utilities - Electricity'\n",
    ",'Utilities - Regulated Gas' :\t'Utilities - Gas'\n",
    ",'Utilities - Regulated Water' : 'Sanitation'\n",
    ",'Utilities - Renewable' : 'Utilities - Electricity'\n",
    ",'Banks - Diversified' : 'Banks'\n",
    ",'Banks - Regional' : 'Banks'\n",
    ",'Insurance - Diversified': 'Insurance'\n",
    ",'Insurance - Life' : 'Insurance'\n",
    ",'Insurance - Property & Casualty' : 'Insurance'\n",
    ",'Insurance - Reinsurance' : 'Insurance'\n",
    ",'Insurance - Specialty' : 'Insurance'\n",
    ",'Insurance Brokers' : 'Insurance'\n",
    ",'Healthcare Plans' : 'Health Insurance'\n",
    ",'Telecom Services' : 'Telecom'\n",
    ",'Waste Management' : 'Sanitation'\n",
    ",'Oil & Gas E&P' : 'Oil & Gas'\n",
    ",'Oil & Gas Equipment & Services' : 'Oil & Gas'\n",
    ",'Oil & Gas Integrated' : 'Oil & Gas'\n",
    ",'Oil & Gas Midstream' : 'Oil & Gas'\n",
    ",'Oil & Gas Refining & Marketing' : 'Oil & Gas'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_perennial = all_companies['industry'].isin(perennial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indetify if the company is in a perennial sector\n",
    "all_companies.loc[mask_perennial, 'perennial'] = 'Yes'\n",
    "all_companies.loc[~mask_perennial, 'perennial'] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subsector for perennial companies\n",
    "all_companies.loc[mask_perennial, 'perennial_subsector'] =  all_companies.loc[mask_perennial, 'industry'].map(dict_subsector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the company is not perennial, subsector = industry\n",
    "all_companies.loc[~mask_perennial, 'perennial_subsector'] = all_companies.loc[~mask_perennial, 'industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified DataFrame\n",
    "all_companies_rev1.to_csv(f'{stock_path}all_companies_and_indexes_rev2.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_rev2 = pd.read_csv(f'{stock_path}all_companies_and_indexes_rev1.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\05.Ironhack_Final_Project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(mysql+pymysql://root:***@localhost/stocks_project)\n"
     ]
    }
   ],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create companies Dataset in SQL\n",
    "all_companies.to_sql(name='companies', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create historical data dataset in SQL\n",
    "historical_data.to_sql(name='historical_data', con=engine, if_exists='replace', index=False) ##if_exists=append\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate historical data dataset update process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing yfinance historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_engine():\n",
    "    \"\"\"Create engine to connect to MySQL server\n",
    "\n",
    "    Returns: \n",
    "        engine (sqlalchemy.engine): engine that connects to the stocks_project dataset on MySQL Server \n",
    "    \"\"\"\n",
    "    \n",
    "    # Import sql_password\n",
    "    load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\05.Ironhack_Final_Project/password.env')\n",
    "    sql_password = os.getenv('sql_password')\n",
    "    \n",
    "    # Set SQL configurations\n",
    "    user = \"root\"\n",
    "    password = sql_password\n",
    "    url_banco = \"localhost\"\n",
    "    nome_db = \"stocks_project\"\n",
    "    conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\"  \n",
    "\n",
    "    # Create engine object\n",
    "    engine = db.create_engine(conn_str)\n",
    "    logger.info('Connection to SQL - Successful')\n",
    "\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_to_date(date, days):\n",
    "    \"\"\"Add days to a date and return the date.\n",
    "    \n",
    "    Args: \n",
    "        date (string): Date string in YYYY-MM-DD format. \n",
    "        days (int): Number of days to add to date\n",
    "    \n",
    "    Returns: \n",
    "        date (date): Date in YYYY-MM-DD with X days added. \n",
    "    \"\"\"\n",
    "    \n",
    "    added_date = pd.to_datetime(date) + timedelta(days=days)\n",
    "    added_date = added_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return added_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_update_dataframe(start, end, ticker_list):\n",
    "    \"\"\"Create a DataFrame with last days historical data.\n",
    "        Logging tracks how many entries each ticker got and save on a new .txt for each day the code runs\n",
    "    \n",
    "    Args: \n",
    "        start (string): Date string in YYYY-MM-DD format - One day after the last update \n",
    "        end (string): Date string in YYYY-MM-DD format - Today\n",
    "        ticker_list (iterable): iterable containing yfinance code for the companies and indexes\n",
    "    \n",
    "    Returns: \n",
    "        df (dataframe): DataFrame with last days historical data. \n",
    "    \"\"\"\n",
    "    \n",
    "    #Track number of entries for each ticker\n",
    "    entries_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, '7+':0 } \n",
    "    ticker_dict = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], '7+':[]}\n",
    "\n",
    "    ticker_list = ticker_list.sort_values()\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        aux_df = pd.DataFrame()\n",
    "        aux_df = yf.Ticker(ticker).history(start=start, end=end)\n",
    "\n",
    "        if aux_df.empty:\n",
    "            logging.warning(f'{ticker}: No data found for this range')\n",
    "            entries_dict[0] += 1\n",
    "            ticker_dict[0].append(ticker)\n",
    "\n",
    "        else:\n",
    "            if aux_df.shape[0] == 1:\n",
    "                entries_dict[1] += 1\n",
    "                ticker_dict[1].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 2:\n",
    "                entries_dict[2] += 1\n",
    "                ticker_dict[2].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 3:\n",
    "                entries_dict[3] += 1\n",
    "                ticker_dict[3].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 4:\n",
    "                entries_dict[4] += 1\n",
    "                ticker_dict[4].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 5:\n",
    "                entries_dict[5] += 1\n",
    "                ticker_dict[5].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 6:\n",
    "                entries_dict[6] += 1\n",
    "                ticker_dict[6].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 7:\n",
    "                entries_dict[7] += 1\n",
    "                ticker_dict[7].append(ticker)\n",
    "\n",
    "            else:\n",
    "                entries_dict['7+'] += 1\n",
    "                ticker_dict['7+'].append(ticker)\n",
    "\n",
    "            aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "        df = pd.concat([df, aux_df], axis=0)\n",
    "\n",
    "    for key, value in entries_dict.items():\n",
    "        if value == 0:\n",
    "            logger.info(f'No tickers with {key} entries')\n",
    "        else: \n",
    "            logger.info(f'Number of tickers with {key} entries: {value}')\n",
    "            logger.info(f'Tickers: {ticker_dict[key]}')\n",
    "\n",
    "    logger.info(f'Create update DataFrame - Successful: Rows in DF: {df.shape[0]}')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_update_dataframe(dataframe):\n",
    "    \"\"\"Transform index to da columns with dates and round Open, High, Low, Close and Dividends columns to 3 decimal places\n",
    "    \n",
    "    Args: \n",
    "        dataframe (DataFrame): DataFrame containing last days historical data. \n",
    "    \n",
    "    Returns: \n",
    "        df (DataFrame): Formated Dataframe. \n",
    "    \"\"\"\n",
    "    \n",
    "    dataframe.reset_index(inplace= True)\n",
    "\n",
    "    # Transform 'Date' to datetime\n",
    "    dataframe['Date'] = pd.to_datetime(dataframe['Date'], format='%Y-%m-%d', utc=True)\n",
    "\n",
    "    dataframe = dataframe.loc[:,['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'cod_yfinance']]\n",
    "\n",
    "    # Transform datetime to YYYY-MM-DD\n",
    "    #dataframe['Date'] = dataframe['Date'].dt.date\n",
    "\n",
    "    # Round Columns\n",
    "    dataframe['Open'] = dataframe['Open'].round(3)\n",
    "    dataframe['High'] = dataframe['High'].round(3)\n",
    "    dataframe['Low'] = dataframe['Low'].round(3)\n",
    "    dataframe['Close'] = dataframe['Close'].round(3)\n",
    "    dataframe['Dividends'] = dataframe['Dividends'].round(3)\n",
    "\n",
    "    logger.info('Format update DataFrame - Successful')\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_update_dataframe(dataframe):\n",
    "    \"\"\"Append update DataFrame to SQL dataset\n",
    "    Verify if SQL got all the rows in the DF\n",
    "\n",
    "    Args: \n",
    "        dataframe (DataFrame): DataFrame, already formated, containing last days historical data. \n",
    "    \"\"\"\n",
    "\n",
    "    dataframe.to_sql(name='historical_data', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    rows_df = dataframe.shape[0]\n",
    "    rows_SQL = dataframe.to_sql(name='historical_data', con=engine, if_exists='replace', index=False)\n",
    "    \n",
    "    if rows_df == rows_SQL:\n",
    "        logger.info(f'SQL update successfull. All {rows_df} rows where appended to the database')\n",
    "\n",
    "    else:\n",
    "        logger.warning(f'ERROR in SQL update. Only {rows_SQL} out of {rows_df} where appended to the database')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_date(engine):\n",
    "    \"\"\"Get the start date to be used in 'create_update_dataframe' function\n",
    "\n",
    "    Args: \n",
    "        engine (sqlalchemy.engine): engine that connects to the stocks_project dataset on MySQL Server \n",
    "    \n",
    "    Returns: \n",
    "        start (str): date to be used in 'create_update_dataframe' function\n",
    "    \"\"\"\n",
    "\n",
    "    last_update = pd.read_sql(sql = \"SELECT MAX(Date) FROM historical_data\", con=engine)\n",
    "    start = last_update.iloc[0,0]\n",
    "    start= add_days_to_date(start, 1)\n",
    "\n",
    "    logger.info(f'Get start date - Successfull - Start date: {start}')\n",
    "\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_date():\n",
    "    \"\"\"Get yesterdays's date to be used as end date in 'create_update_dataframe' function \n",
    "\n",
    "    Returns: \n",
    "        yesterday (str): Date string in YYYY-MM-DD format - Today\n",
    "    \"\"\"\n",
    "    today = datetime.datetime.now()\n",
    "    yesterday = today - datetime.timedelta(days = 1)\n",
    "    yesterday = yesterday.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    logger.info(f'Get end date - Successful - End date: {yesterday}')\n",
    "\n",
    "    return yesterday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_list(engine):\n",
    "    \"\"\"Get the ticker list to be used in 'create_update_dataframe' function\n",
    "\n",
    "    Args: \n",
    "        engine (sqlalchemy.engine): engine that connects to the stocks_project dataset on MySQL Server \n",
    "    \n",
    "    Returns: \n",
    "        ticker_list (iterable): iterable containing yfinance code for the companies and indexes\n",
    "    \"\"\"\n",
    "\n",
    "    ticker_list = pd.read_sql(sql='SELECT cod_yfinance FROM companies', con=engine)['cod_yfinance']\n",
    "\n",
    "    if ticker_list.shape[0] == 735:\n",
    "        logger.info(f'Get ticker list - Successful - Number of tickers: {ticker_list.shape[0]}')\n",
    "    \n",
    "    else:\n",
    "        logger.warning(f'Get ticker list - ERROR - Number of tickers expected: 735 -- Number of ticker found: {ticker_list.shape[0]}')\n",
    "\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(mysql+pymysql://root:***@localhost/stocks_project)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine()\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-12'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = get_start_date(engine)\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-19'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = get_end_date()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           IPG\n",
       "1           OMC\n",
       "2      TASA4.SA\n",
       "3      EMBR3.SA\n",
       "4            BA\n",
       "         ...   \n",
       "730       ^GSPC\n",
       "731        GC=F\n",
       "732     BTC-USD\n",
       "733     ETH-USD\n",
       "734       BRL=X\n",
       "Name: cod_yfinance, Length: 735, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_list = get_ticker_list(engine)\n",
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAH: No data found for this date range, symbol may be delisted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cod_yfinance</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-12 00:00:00-05:00</th>\n",
       "      <td>153.780652</td>\n",
       "      <td>155.747720</td>\n",
       "      <td>153.201514</td>\n",
       "      <td>155.098694</td>\n",
       "      <td>1071400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-13 00:00:00-05:00</th>\n",
       "      <td>158.962917</td>\n",
       "      <td>160.021336</td>\n",
       "      <td>156.526548</td>\n",
       "      <td>157.425217</td>\n",
       "      <td>1534200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-14 00:00:00-05:00</th>\n",
       "      <td>157.025816</td>\n",
       "      <td>158.204067</td>\n",
       "      <td>153.930442</td>\n",
       "      <td>154.579468</td>\n",
       "      <td>1344400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-15 00:00:00-05:00</th>\n",
       "      <td>152.582439</td>\n",
       "      <td>152.812092</td>\n",
       "      <td>150.016274</td>\n",
       "      <td>150.635345</td>\n",
       "      <td>1483900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-16 00:00:00-05:00</th>\n",
       "      <td>149.387203</td>\n",
       "      <td>149.726693</td>\n",
       "      <td>147.689738</td>\n",
       "      <td>149.077667</td>\n",
       "      <td>2436700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-12 00:00:00-03:00</th>\n",
       "      <td>18982.679688</td>\n",
       "      <td>19072.609375</td>\n",
       "      <td>18732.980469</td>\n",
       "      <td>18882.599609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-13 00:00:00-03:00</th>\n",
       "      <td>18877.019531</td>\n",
       "      <td>18877.019531</td>\n",
       "      <td>18656.580078</td>\n",
       "      <td>18768.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-16 00:00:00-03:00</th>\n",
       "      <td>18744.199219</td>\n",
       "      <td>18744.199219</td>\n",
       "      <td>18355.539062</td>\n",
       "      <td>18442.410156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-17 00:00:00-03:00</th>\n",
       "      <td>18442.609375</td>\n",
       "      <td>18815.119141</td>\n",
       "      <td>18442.609375</td>\n",
       "      <td>18808.240234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 00:00:00-03:00</th>\n",
       "      <td>18816.580078</td>\n",
       "      <td>19120.669922</td>\n",
       "      <td>18816.580078</td>\n",
       "      <td>18978.429688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18739 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Open          High           Low  \\\n",
       "Date                                                                  \n",
       "2022-12-12 00:00:00-05:00    153.780652    155.747720    153.201514   \n",
       "2022-12-13 00:00:00-05:00    158.962917    160.021336    156.526548   \n",
       "2022-12-14 00:00:00-05:00    157.025816    158.204067    153.930442   \n",
       "2022-12-15 00:00:00-05:00    152.582439    152.812092    150.016274   \n",
       "2022-12-16 00:00:00-05:00    149.387203    149.726693    147.689738   \n",
       "...                                 ...           ...           ...   \n",
       "2023-01-12 00:00:00-03:00  18982.679688  19072.609375  18732.980469   \n",
       "2023-01-13 00:00:00-03:00  18877.019531  18877.019531  18656.580078   \n",
       "2023-01-16 00:00:00-03:00  18744.199219  18744.199219  18355.539062   \n",
       "2023-01-17 00:00:00-03:00  18442.609375  18815.119141  18442.609375   \n",
       "2023-01-18 00:00:00-03:00  18816.580078  19120.669922  18816.580078   \n",
       "\n",
       "                                  Close     Volume  Dividends  Stock Splits  \\\n",
       "Date                                                                          \n",
       "2022-12-12 00:00:00-05:00    155.098694  1071400.0        0.0           0.0   \n",
       "2022-12-13 00:00:00-05:00    157.425217  1534200.0        0.0           0.0   \n",
       "2022-12-14 00:00:00-05:00    154.579468  1344400.0        0.0           0.0   \n",
       "2022-12-15 00:00:00-05:00    150.635345  1483900.0        0.0           0.0   \n",
       "2022-12-16 00:00:00-05:00    149.077667  2436700.0        0.0           0.0   \n",
       "...                                 ...        ...        ...           ...   \n",
       "2023-01-12 00:00:00-03:00  18882.599609        0.0        0.0           0.0   \n",
       "2023-01-13 00:00:00-03:00  18768.000000        0.0        0.0           0.0   \n",
       "2023-01-16 00:00:00-03:00  18442.410156        0.0        0.0           0.0   \n",
       "2023-01-17 00:00:00-03:00  18808.240234        0.0        0.0           0.0   \n",
       "2023-01-18 00:00:00-03:00  18978.429688        0.0        0.0           0.0   \n",
       "\n",
       "                          cod_yfinance  Adj Close  \n",
       "Date                                               \n",
       "2022-12-12 00:00:00-05:00            A        NaN  \n",
       "2022-12-13 00:00:00-05:00            A        NaN  \n",
       "2022-12-14 00:00:00-05:00            A        NaN  \n",
       "2022-12-15 00:00:00-05:00            A        NaN  \n",
       "2022-12-16 00:00:00-05:00            A        NaN  \n",
       "...                                ...        ...  \n",
       "2023-01-12 00:00:00-03:00       ^IBX50        NaN  \n",
       "2023-01-13 00:00:00-03:00       ^IBX50        NaN  \n",
       "2023-01-16 00:00:00-03:00       ^IBX50        NaN  \n",
       "2023-01-17 00:00:00-03:00       ^IBX50        NaN  \n",
       "2023-01-18 00:00:00-03:00       ^IBX50        NaN  \n",
       "\n",
       "[18739 rows x 9 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_update_dataframe(start, end, ticker_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 18739 entries, 2022-12-12 00:00:00-05:00 to 2023-01-18 00:00:00-03:00\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Open          18739 non-null  float64\n",
      " 1   High          18739 non-null  float64\n",
      " 2   Low           18739 non-null  float64\n",
      " 3   Close         18739 non-null  float64\n",
      " 4   Volume        18739 non-null  float64\n",
      " 5   Dividends     18739 non-null  float64\n",
      " 6   Stock Splits  18739 non-null  float64\n",
      " 7   cod_yfinance  18739 non-null  object \n",
      " 8   Adj Close     0 non-null      float64\n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\AppData\\Local\\Temp\\ipykernel_17748\\2607806064.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['Date'] = pd.to_datetime(dataframe['Date'], format='%Y-%m-%d', utc=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cod_yfinance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-12 05:00:00+00:00</td>\n",
       "      <td>153.781</td>\n",
       "      <td>155.748</td>\n",
       "      <td>153.202</td>\n",
       "      <td>155.099</td>\n",
       "      <td>1071400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-13 05:00:00+00:00</td>\n",
       "      <td>158.963</td>\n",
       "      <td>160.021</td>\n",
       "      <td>156.527</td>\n",
       "      <td>157.425</td>\n",
       "      <td>1534200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-14 05:00:00+00:00</td>\n",
       "      <td>157.026</td>\n",
       "      <td>158.204</td>\n",
       "      <td>153.930</td>\n",
       "      <td>154.579</td>\n",
       "      <td>1344400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-15 05:00:00+00:00</td>\n",
       "      <td>152.582</td>\n",
       "      <td>152.812</td>\n",
       "      <td>150.016</td>\n",
       "      <td>150.635</td>\n",
       "      <td>1483900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-16 05:00:00+00:00</td>\n",
       "      <td>149.387</td>\n",
       "      <td>149.727</td>\n",
       "      <td>147.690</td>\n",
       "      <td>149.078</td>\n",
       "      <td>2436700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18734</th>\n",
       "      <td>2023-01-12 03:00:00+00:00</td>\n",
       "      <td>18982.680</td>\n",
       "      <td>19072.609</td>\n",
       "      <td>18732.980</td>\n",
       "      <td>18882.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18735</th>\n",
       "      <td>2023-01-13 03:00:00+00:00</td>\n",
       "      <td>18877.020</td>\n",
       "      <td>18877.020</td>\n",
       "      <td>18656.580</td>\n",
       "      <td>18768.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18736</th>\n",
       "      <td>2023-01-16 03:00:00+00:00</td>\n",
       "      <td>18744.199</td>\n",
       "      <td>18744.199</td>\n",
       "      <td>18355.539</td>\n",
       "      <td>18442.410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18737</th>\n",
       "      <td>2023-01-17 03:00:00+00:00</td>\n",
       "      <td>18442.609</td>\n",
       "      <td>18815.119</td>\n",
       "      <td>18442.609</td>\n",
       "      <td>18808.240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18738</th>\n",
       "      <td>2023-01-18 03:00:00+00:00</td>\n",
       "      <td>18816.580</td>\n",
       "      <td>19120.670</td>\n",
       "      <td>18816.580</td>\n",
       "      <td>18978.430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^IBX50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18739 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date       Open       High        Low      Close  \\\n",
       "0     2022-12-12 05:00:00+00:00    153.781    155.748    153.202    155.099   \n",
       "1     2022-12-13 05:00:00+00:00    158.963    160.021    156.527    157.425   \n",
       "2     2022-12-14 05:00:00+00:00    157.026    158.204    153.930    154.579   \n",
       "3     2022-12-15 05:00:00+00:00    152.582    152.812    150.016    150.635   \n",
       "4     2022-12-16 05:00:00+00:00    149.387    149.727    147.690    149.078   \n",
       "...                         ...        ...        ...        ...        ...   \n",
       "18734 2023-01-12 03:00:00+00:00  18982.680  19072.609  18732.980  18882.600   \n",
       "18735 2023-01-13 03:00:00+00:00  18877.020  18877.020  18656.580  18768.000   \n",
       "18736 2023-01-16 03:00:00+00:00  18744.199  18744.199  18355.539  18442.410   \n",
       "18737 2023-01-17 03:00:00+00:00  18442.609  18815.119  18442.609  18808.240   \n",
       "18738 2023-01-18 03:00:00+00:00  18816.580  19120.670  18816.580  18978.430   \n",
       "\n",
       "          Volume  Dividends  Stock Splits cod_yfinance  \n",
       "0      1071400.0        0.0           0.0            A  \n",
       "1      1534200.0        0.0           0.0            A  \n",
       "2      1344400.0        0.0           0.0            A  \n",
       "3      1483900.0        0.0           0.0            A  \n",
       "4      2436700.0        0.0           0.0            A  \n",
       "...          ...        ...           ...          ...  \n",
       "18734        0.0        0.0           0.0       ^IBX50  \n",
       "18735        0.0        0.0           0.0       ^IBX50  \n",
       "18736        0.0        0.0           0.0       ^IBX50  \n",
       "18737        0.0        0.0           0.0       ^IBX50  \n",
       "18738        0.0        0.0           0.0       ^IBX50  \n",
       "\n",
       "[18739 rows x 9 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = format_update_dataframe(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18739 entries, 0 to 18738\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   Date          18739 non-null  datetime64[ns, UTC]\n",
      " 1   Open          18739 non-null  float64            \n",
      " 2   High          18739 non-null  float64            \n",
      " 3   Low           18739 non-null  float64            \n",
      " 4   Close         18739 non-null  float64            \n",
      " 5   Volume        18739 non-null  float64            \n",
      " 6   Dividends     18739 non-null  float64            \n",
      " 7   Stock Splits  18739 non-null  float64            \n",
      " 8   cod_yfinance  18739 non-null  object             \n",
      " 9   Adj Close     0 non-null      float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(8), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_update_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update = pd.read_sql(sql = \"SELECT MAX(Date) FROM historical_data\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = last_update.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = add_days_to_date(start, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = pd.read_sql(sql='SELECT cod_yfinance FROM companies', con=engine)['cod_yfinance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list.iloc[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list.iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing yfinance historical data\n",
    "test_df = pd.DataFrame()\n",
    "for ticker in ticker_list.iloc[:5]:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(start='2022-12-08', end='2022-12-12')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    test_df = pd.concat([test_df, aux_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date to datetime\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'], utc=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform datetime to YYYY-MM-DD\n",
    "test_df['Date'] = test_df['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Open'] = test_df['Open'].round(3)\n",
    "test_df['High'] = test_df['High'].round(3)\n",
    "test_df['Low'] = test_df['Low'].round(3)\n",
    "test_df['Close'] = test_df['Close'].round(3)\n",
    "test_df['Dividends'] = test_df['Dividends'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_sql(name='test_dataset', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.to_sql(name='companies', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing yfinance historical data\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "for ticker in ticker_list.loc[0:5]:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(start='2022-12-09', end='2022-12-10')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    test_df = pd.concat([test_df, aux_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date to datetime\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'], utc=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform datetime to YYYY-MM-DD\n",
    "test_df['Date'] = test_df['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Open'] = test_df['Open'].round(3)\n",
    "test_df['High'] = test_df['High'].round(3)\n",
    "test_df['Low'] = test_df['Low'].round(3)\n",
    "test_df['Close'] = test_df['Close'].round(3)\n",
    "test_df['Dividends'] = test_df['Dividends'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_sql(name='test_dataset', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_and_indexes_rev2.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete_rev5.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks\n",
    "country_br = all_companies['country'] == 'Brazil'\n",
    "country_usa = all_companies['country'] == 'USA'\n",
    "\n",
    "type_company = all_companies['type'] == 'Company'\n",
    "type_index = all_companies['type'] == 'Index'\n",
    "type_gold = all_companies['type'] == 'Gold'\n",
    "type_crypto = all_companies['type'] == 'Crypto'\n",
    "type_currency = all_companies['type'] == 'Currency'\n",
    "\n",
    "perennial = all_companies['perennial'] == 'Yes'\n",
    "\n",
    "subsector_uti_elec = all_companies['perennial_subsector'] == 'Utilities - Electricity'\n",
    "subsector_uti_gas = all_companies['perennial_subsector'] == 'Utilities - Gas'\n",
    "subsector_sanit = all_companies['perennial_subsector'] == 'Sanitation'\n",
    "subsector_banks = all_companies['perennial_subsector'] == 'Banks'\n",
    "subsector_insurance = all_companies['perennial_subsector'] == 'Insurance'\n",
    "subsector_healh_ins = all_companies['perennial_subsector'] == 'Health Insurance'\n",
    "subsector_telecom = all_companies['perennial_subsector'] == 'Telecom'\n",
    "subsector_oil = all_companies['perennial_subsector'] == 'Oil & Gas'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[historical_data['Date'] == '2012-02-22'].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_aux = historical_data_aux.drop([467086,470795,4794649,482460,1354271])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_aux.loc[(historical_data_aux['Date'] == '2021-05-02') & (historical_data_aux['cod_yfinance'].isin(all_companies.loc[country_br, 'cod_yfinance']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Date'] == '2012-01-02') & (historical_data['cod_yfinance'].isin(all_companies.loc[country_br, 'cod_yfinance']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.dropna(axis = 0, subset=['Close']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_aux_1 = historical_data.dropna(axis = 0, subset=['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_aux_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data[\"Date\"] == '2018-07-30') & historical_data['cod_yfinance'].isin(all_companies.loc[type_company & country_br & subsector_banks, 'cod_yfinance']), 'Close'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[type_company & country_br & subsector_banks, 'cod_yfinance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[subsector_oil]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[perennial & country_br, 'perennial_subsector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_br = all_companies[country_br & type_company]\n",
    "df_company_usa = all_companies[country_usa & type_company]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_usa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[historical_data['cod_yfinance'].isin(['^GSPC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_br_pivot = pd.pivot_table(historical_data[historical_data['cod_yfinance'].isin(df_company_br[\"cod_yfinance\"].unique())], index='Date', columns='cod_yfinance', values='Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_br_pivot.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_br_pivot.loc['2018-01-03',df_br_pivot.loc['2018-01-03'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[[729], 'name'] = 'Dow Jones'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = all_companies.drop('Ticker', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified DataFrame\n",
    "all_companies.to_csv(f'{stock_path}all_companies_and_indexes_rev3.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_and_indexes_rev2.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete_rev8.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified DataFrame\n",
    "historical_data_aux_1.to_csv(f'{stock_path}historical_data_complete_rev6.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_aux_1.to_sql(name='historical_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks\n",
    "country_br = all_companies['country'] == 'Brazil'\n",
    "country_usa = all_companies['country'] == 'USA'\n",
    "\n",
    "type_company = all_companies['type'] == 'Company'\n",
    "type_index = all_companies['type'] == 'Index'\n",
    "type_gold = all_companies['type'] == 'Gold'\n",
    "type_crypto = all_companies['type'] == 'Crypto'\n",
    "type_currency = all_companies['type'] == 'Currency'\n",
    "\n",
    "perennial = all_companies['perennial'] == 'Yes'\n",
    "\n",
    "subsector_uti_elec = all_companies['perennial_subsector'] == 'Utilities - Electricity'\n",
    "subsector_uti_gas = all_companies['perennial_subsector'] == 'Utilities - Gas'\n",
    "subsector_sanit = all_companies['perennial_subsector'] == 'Sanitation'\n",
    "subsector_banks = all_companies['perennial_subsector'] == 'Banks'\n",
    "subsector_insurance = all_companies['perennial_subsector'] == 'Insurance'\n",
    "subsector_healh_ins = all_companies['perennial_subsector'] == 'Health Insurance'\n",
    "subsector_telecom = all_companies['perennial_subsector'] == 'Telecom'\n",
    "subsector_oil = all_companies['perennial_subsector'] == 'Oil & Gas'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Date'] == '2017-06-15') & (historical_data['cod_yfinance'].isin(['^BVSP']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_update_dataframe('2003-07-09','2003-07-10',['^BVSP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_update_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tasa4 = historical_data['cod_yfinance'] == 'TASA4.SA'\n",
    "mask_ibov = historical_data['cod_yfinance'] == '^BVSP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[mask_tasa4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[mask_ibov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = historical_data.drop(historical_data.loc[(historical_data['Close'] > 70) & (historical_data['cod_yfinance'].isin(['LREN3.SA']))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Close'] > 300) & (historical_data['cod_yfinance'].isin(all_companies.loc[type_company & country_br, 'cod_yfinance'])) & (historical_data['cod_yfinance'] != 'GFSA3.SA')].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Close'] > 100) & (historical_data['cod_yfinance'].isin(['GGBR4.SA']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Close'] > 100) & (historical_data['cod_yfinance'].isin(all_companies.loc[type_company & country_br, 'cod_yfinance'])) & (historical_data['cod_yfinance'] != 'GFSA3.SA'), 'cod_yfinance'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[all_companies['type'] != 'Company']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Close'] > 1000) & historical_data['cod_yfinance'].isin(all_companies.loc[type_company, 'cod_yfinance']), 'cod_yfinance'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibra = pd.read_csv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\B3\\txt/dataset-IBRA.csv',\n",
    "                        encoding='ISO-8859-1',\n",
    "                        sep=';',\n",
    "                        decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibra.loc[dataset_ibra['cod_negociacao'] == 'BRKM5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibra.loc[(dataset_ibra['data_pregao'] == '2002-09-04') & (dataset_ibra['cod_negociacao'] == 'BRKM5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibra.loc[(dataset_ibra['preco_ultimo_negocio'] > 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibra.loc[(dataset_ibra['cod_negociacao'] == 'CMIG4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibra[dataset_ibra['cod_negociacao'] == 'TUPY3'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[historical_data['cod_yfinance'].isin(['AGRO3.SA']), 'Close'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[all_companies['cod_yfinance'] == 'VULC3.SA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Close'] > 100000) & historical_data['cod_yfinance'].isin(['VULC3.SA'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[historical_data['cod_yfinance'].isin(['VULC3.SA'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified = historical_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(historical_data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified['Date'] = pd.to_datetime(historical_data_modified['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_before = pd.to_datetime('2022-01-01')\n",
    "date_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_date_prev_2022 = historical_data_modified['Date'] < date_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_modify = ['BRKM5.SA', 'LREN3.SA', 'VULC3.SA', 'UGPA3.SA', 'RCSL3.SA', 'CMIG4.SA', 'TRPL4.SA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_companies_modify = historical_data_modified['cod_yfinance'].isin(list_modify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified.loc[mask_date_prev_2022 & mask_companies_modify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4913040 - 37735"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified = historical_data_modified.drop(historical_data_modified.loc[mask_date_prev_2022 & mask_companies_modify].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibra['data_pregao'] = pd.to_datetime(dataset_ibra['data_pregao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_date_prev_2022_ibra = dataset_ibra['data_pregao'] < date_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_modify_ibra = ['BRKM5', 'LREN3', 'VULC3', 'UGPA3', 'RCSL3', 'CMIG4', 'TRPL4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_companies_modify_ibra = dataset_ibra['cod_negociacao'].isin(list_modify_ibra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ibra.loc[(dataset_ibra['data_pregao'] > pd.to_datetime('2021-01-01')) & (dataset_ibra['data_pregao'] < pd.to_datetime('2021-01-03'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete = dataset_ibra.loc[mask_date_prev_2022_ibra  & mask_companies_modify_ibra].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete = append_to_complete[['data_pregao', 'preco_abertura', 'preco_maximo', 'preco_minimo', 'preco_ultimo_negocio', 'Volume', 'Dividends', 'Stock Splits', 'cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_yfinance = [f'{i}.SA'for i in append_to_complete['cod_negociacao']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete['Dividends'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete['Volume'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete['cod_yfinance'] = cod_yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete = append_to_complete.drop('cod_negociacao', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'cod_yfinance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4875305 + 27834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COncatenar DataFrame yfinance concatenado com B3 para resolver outliers\n",
    "historical_data_modified_to_save = pd.concat([historical_data_modified, append_to_complete], axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified_to_save.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified_to_save.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified_to_save = historical_data_modified_to_save.drop(historical_data_modified_to_save.loc[(historical_data_modified_to_save['Close'] > 100) & historical_data_modified_to_save['cod_yfinance'].isin(['TUPY3.SA'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified DataFrame\n",
    "historical_data_modified_to_save.to_csv(f'{stock_path}historical_data_complete_rev7.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_modified_to_save.to_sql(name='historical_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = historical_data_modified_to_save.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data[(historical_data['Date'] > '2012-02-10') & ((historical_data['Date'] < '2012-02-21')) & (historical_data['cod_yfinance'].str.contains(r'\\.SA'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete_rev6.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Close'] > 5000) & historical_data['cod_yfinance'].isin(all_companies.loc[type_company, 'cod_yfinance'])].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = historical_data.drop(historical_data.loc[(historical_data['Close'] < 0) & historical_data['cod_yfinance'].isin(all_companies.loc[type_company, 'cod_yfinance'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Close'] < 0) & historical_data['cod_yfinance'].isin(all_companies.loc[type_company, 'cod_yfinance'])].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Date'] == '2001-09-12') & (historical_data['cod_yfinance'].isin(all_companies.loc[type_company, 'cod_yfinance']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified DataFrame\n",
    "historical_data.to_csv(f'{stock_path}historical_data_complete_rev8.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.to_sql(name='historical_data', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisys on Companies DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_barsi = [\n",
    "'AESB3'\n",
    ",'BBDC3'\n",
    ",'BBSE3'\n",
    ",'BRAP3'\n",
    ",'BRKM5'\n",
    ",'BRSR6'\n",
    ",'CSMG3'\n",
    ",'ENAT3'\n",
    ",'GRND3'\n",
    ",'ITSA4'\n",
    ",'ITUB3'\n",
    ",'QUAL3'\n",
    ",'PSSA3'\n",
    ",'SANB11'\n",
    ",'SAPR11'\n",
    ",'TAEE11'\n",
    ",'TRPL4'\n",
    ",'VIVT3'\n",
    ",'WIZS3'\n",
    ",'VBBR3'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks\n",
    "country_br = all_companies['country'] == 'Brazil'\n",
    "country_usa = all_companies['country'] == 'USA'\n",
    "\n",
    "type_company = all_companies['type'] == 'Company'\n",
    "type_index = all_companies['type'] == 'Index'\n",
    "type_gold = all_companies['type'] == 'Gold'\n",
    "type_crypto = all_companies['type'] == 'Crypto'\n",
    "type_currency = all_companies['type'] == 'Currency'\n",
    "\n",
    "perennial = all_companies['perennial'] == 'Yes'\n",
    "\n",
    "subsector_uti_elec = all_companies['perennial_subsector'] == 'Utilities - Electricity'\n",
    "subsector_uti_gas = all_companies['perennial_subsector'] == 'Utilities - Gas'\n",
    "subsector_sanit = all_companies['perennial_subsector'] == 'Sanitation'\n",
    "subsector_banks = all_companies['perennial_subsector'] == 'Banks'\n",
    "subsector_insurance = all_companies['perennial_subsector'] == 'Insurance'\n",
    "subsector_healh_ins = all_companies['perennial_subsector'] == 'Health Insurance'\n",
    "subsector_telecom = all_companies['perennial_subsector'] == 'Telecom'\n",
    "subsector_oil = all_companies['perennial_subsector'] == 'Oil & Gas'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_usa & type_company, 'sector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_usa & type_company & (all_companies['sector'] == 'Real Estate' )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[country_br & type_company & all_companies['ticker'].str.contains('SAP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_br & type_company & (all_companies['perennial_subsector']=='Health Insurance')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_br & type_company & all_companies['ticker'].isin(top_20_barsi), 'perennial_subsector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data[(historical_data['Date'] == '2008-01-02') & (historical_data['cod_yfinance'].isin(all_companies.loc[country_br & type_company & all_companies['ticker'].isin(top_20_barsi), 'cod_yfinance']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.loc[(historical_data['Date'] == '2008-01-02') & (historical_data['cod_yfinance'].isin(all_companies.loc[country_br & type_company, 'cod_yfinance']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_subsector_pbi = {\n",
    "'Utilities - Diversified' : 'Electricity'\n",
    ",'Utilities - Independent Power Producers' : 'Electricity'\n",
    ",'Utilities - Regulated Electric' : 'Electricity'\n",
    ",'Utilities - Regulated Gas' :\t'Utilities - Gas'\n",
    ",'Utilities - Regulated Water' : 'Sanitation'\n",
    ",'Utilities - Renewable' : 'Electricity'\n",
    ",'Banks - Diversified' : 'Banks'\n",
    ",'Banks - Regional' : 'Banks'\n",
    ",'Insurance - Diversified': 'Insurance'\n",
    ",'Insurance - Life' : 'Insurance'\n",
    ",'Insurance - Property & Casualty' : 'Insurance'\n",
    ",'Insurance - Reinsurance' : 'Insurance'\n",
    ",'Insurance - Specialty' : 'Insurance'\n",
    ",'Insurance Brokers' : 'Insurance'\n",
    ",'Healthcare Plans' : 'Health Insurance'\n",
    ",'Telecom Services' : 'Telecom'\n",
    ",'Waste Management' : 'Sanitation'\n",
    ",'Oil & Gas E&P' : 'Oil & Gas'\n",
    ",'Oil & Gas Equipment & Services' : 'Oil & Gas'\n",
    ",'Oil & Gas Integrated' : 'Oil & Gas'\n",
    ",'Oil & Gas Midstream' : 'Oil & Gas'\n",
    ",'Oil & Gas Refining & Marketing' : 'Oil & Gas'\n",
    ",'Real Estate - Development' : 'Construction'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_br & type_company & perennial, 'pbi_sector_analysis'] = all_companies['industry'].map(dict_subsector_pbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[all_companies['pbi_sector_analysis'].isnull(), 'pbi_sector_analysis'] = all_companies['sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[country_usa & type_company & (all_companies['sector'] == 'Technology')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.to_sql(name='companies', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_rev1 = all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[['cod_yfinance', 'ticker', 'name', 'sector', 'industry']].sort_values('name').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.sort_values('name').head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_outlier = pd.read_csv(f'{stock_path}historical_data_complete_rev5.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_outlier[(historical_data_outlier['Close'] > 100000) & (historical_data_outlier['cod_yfinance'].str.contains('SA'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_and_indexes_rev3.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete_rev8.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cod_yfinance</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>perennial_subsector</th>\n",
       "      <th>perennial</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>pbi_sector_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>AALR3.SA</td>\n",
       "      <td>AALR3</td>\n",
       "      <td>ALLIAR</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>No</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Company</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ABCB4.SA</td>\n",
       "      <td>ABCB4</td>\n",
       "      <td>ABC BRASIL</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Banks - Regional</td>\n",
       "      <td>Banks</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Company</td>\n",
       "      <td>Banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ABEV3.SA</td>\n",
       "      <td>ABEV3</td>\n",
       "      <td>AMBEV S/A</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>Beverages - Brewers</td>\n",
       "      <td>Beverages - Brewers</td>\n",
       "      <td>No</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Company</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>AERI3.SA</td>\n",
       "      <td>AERI3</td>\n",
       "      <td>AERIS</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "      <td>Specialty Industrial Machinery</td>\n",
       "      <td>No</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Company</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>AESB3.SA</td>\n",
       "      <td>AESB3</td>\n",
       "      <td>AES BRASIL</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Utilities - Renewable</td>\n",
       "      <td>Utilities - Electricity</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Company</td>\n",
       "      <td>Electricity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>^BVSP</td>\n",
       "      <td>IBOV</td>\n",
       "      <td>Ibovespa</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>No</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>^IBX50</td>\n",
       "      <td>IBRX50</td>\n",
       "      <td>IBrX50</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>No</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>^DJI</td>\n",
       "      <td>DOW JONES</td>\n",
       "      <td>Dow Jones</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>NQ=F</td>\n",
       "      <td>NASDAQ100</td>\n",
       "      <td>Nasdaq 100</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>SP500</td>\n",
       "      <td>S&amp;P 500</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cod_yfinance     ticker        name              sector  \\\n",
       "155     AALR3.SA      AALR3      ALLIAR          Healthcare   \n",
       "63      ABCB4.SA      ABCB4  ABC BRASIL  Financial Services   \n",
       "88      ABEV3.SA      ABEV3   AMBEV S/A  Consumer Defensive   \n",
       "597     AERI3.SA      AERI3       AERIS         Industrials   \n",
       "713     AESB3.SA      AESB3  AES BRASIL           Utilities   \n",
       "..           ...        ...         ...                 ...   \n",
       "726        ^BVSP       IBOV    Ibovespa               Index   \n",
       "727       ^IBX50     IBRX50      IBrX50               Index   \n",
       "729         ^DJI  DOW JONES   Dow Jones               Index   \n",
       "728         NQ=F  NASDAQ100  Nasdaq 100               Index   \n",
       "730        ^GSPC      SP500     S&P 500               Index   \n",
       "\n",
       "                           industry             perennial_subsector perennial  \\\n",
       "155          Diagnostics & Research          Diagnostics & Research        No   \n",
       "63                 Banks - Regional                           Banks       Yes   \n",
       "88              Beverages - Brewers             Beverages - Brewers        No   \n",
       "597  Specialty Industrial Machinery  Specialty Industrial Machinery        No   \n",
       "713           Utilities - Renewable         Utilities - Electricity       Yes   \n",
       "..                              ...                             ...       ...   \n",
       "726                           Index                           Index        No   \n",
       "727                           Index                           Index        No   \n",
       "729                           Index                           Index        No   \n",
       "728                           Index                           Index        No   \n",
       "730                           Index                           Index        No   \n",
       "\n",
       "    country     type pbi_sector_analysis  \n",
       "155  Brazil  Company          Healthcare  \n",
       "63   Brazil  Company               Banks  \n",
       "88   Brazil  Company  Consumer Defensive  \n",
       "597  Brazil  Company         Industrials  \n",
       "713  Brazil  Company         Electricity  \n",
       "..      ...      ...                 ...  \n",
       "726  Brazil    Index               Index  \n",
       "727  Brazil    Index               Index  \n",
       "729     USA    Index               Index  \n",
       "728     USA    Index               Index  \n",
       "730     USA    Index               Index  \n",
       "\n",
       "[735 rows x 10 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_companies.sort_values(['type', 'country', 'ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cod_yfinance</th>\n",
       "      <th>ticker</th>\n",
       "      <th>name</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>perennial_subsector</th>\n",
       "      <th>perennial</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>pbi_sector_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AAL</td>\n",
       "      <td>AAL</td>\n",
       "      <td>American Airlines Group</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>AALR3.SA</td>\n",
       "      <td>AALR3</td>\n",
       "      <td>ALLIAR</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>Diagnostics &amp; Research</td>\n",
       "      <td>No</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Company</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>AAP</td>\n",
       "      <td>AAP</td>\n",
       "      <td>Advance Auto Parts</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>Specialty Retail</td>\n",
       "      <td>Specialty Retail</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Consumer Electronics</td>\n",
       "      <td>Consumer Electronics</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>Drug Manufacturers - Specialty &amp; Generic</td>\n",
       "      <td>Drug Manufacturers - Specialty &amp; Generic</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Company</td>\n",
       "      <td>Healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>^BVSP</td>\n",
       "      <td>IBOV</td>\n",
       "      <td>Ibovespa</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>No</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>^DJI</td>\n",
       "      <td>DOW JONES</td>\n",
       "      <td>Dow Jones</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>^GSPC</td>\n",
       "      <td>SP500</td>\n",
       "      <td>S&amp;P 500</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>No</td>\n",
       "      <td>USA</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>^IBX50</td>\n",
       "      <td>IBRX50</td>\n",
       "      <td>IBrX50</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>No</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>735 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cod_yfinance     ticker                     name             sector  \\\n",
       "159            A          A     Agilent Technologies         Healthcare   \n",
       "23           AAL        AAL  American Airlines Group        Industrials   \n",
       "155     AALR3.SA      AALR3                   ALLIAR         Healthcare   \n",
       "625          AAP        AAP       Advance Auto Parts  Consumer Cyclical   \n",
       "142         AAPL       AAPL               Apple Inc.         Technology   \n",
       "..           ...        ...                      ...                ...   \n",
       "191          ZTS        ZTS                   Zoetis         Healthcare   \n",
       "726        ^BVSP       IBOV                 Ibovespa              Index   \n",
       "729         ^DJI  DOW JONES                Dow Jones              Index   \n",
       "730        ^GSPC      SP500                  S&P 500              Index   \n",
       "727       ^IBX50     IBRX50                   IBrX50              Index   \n",
       "\n",
       "                                     industry  \\\n",
       "159                    Diagnostics & Research   \n",
       "23                                   Airlines   \n",
       "155                    Diagnostics & Research   \n",
       "625                          Specialty Retail   \n",
       "142                      Consumer Electronics   \n",
       "..                                        ...   \n",
       "191  Drug Manufacturers - Specialty & Generic   \n",
       "726                                     Index   \n",
       "729                                     Index   \n",
       "730                                     Index   \n",
       "727                                     Index   \n",
       "\n",
       "                          perennial_subsector perennial country     type  \\\n",
       "159                    Diagnostics & Research        No     USA  Company   \n",
       "23                                   Airlines        No     USA  Company   \n",
       "155                    Diagnostics & Research        No  Brazil  Company   \n",
       "625                          Specialty Retail        No     USA  Company   \n",
       "142                      Consumer Electronics        No     USA  Company   \n",
       "..                                        ...       ...     ...      ...   \n",
       "191  Drug Manufacturers - Specialty & Generic        No     USA  Company   \n",
       "726                                     Index        No  Brazil    Index   \n",
       "729                                     Index        No     USA    Index   \n",
       "730                                     Index        No     USA    Index   \n",
       "727                                     Index        No  Brazil    Index   \n",
       "\n",
       "    pbi_sector_analysis  \n",
       "159          Healthcare  \n",
       "23          Industrials  \n",
       "155          Healthcare  \n",
       "625   Consumer Cyclical  \n",
       "142          Technology  \n",
       "..                  ...  \n",
       "191          Healthcare  \n",
       "726               Index  \n",
       "729               Index  \n",
       "730               Index  \n",
       "727               Index  \n",
       "\n",
       "[735 rows x 10 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_companies.sort_values('cod_yfinance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cod_yfinance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-03-17 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-03-18 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.417</td>\n",
       "      <td>327600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-03-19 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.417</td>\n",
       "      <td>115200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-03-20 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-03-21 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>554400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899920</th>\n",
       "      <td>2022-12-05 00:00:00+00:00</td>\n",
       "      <td>5.218</td>\n",
       "      <td>5.264</td>\n",
       "      <td>5.214</td>\n",
       "      <td>5.218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899921</th>\n",
       "      <td>2022-12-06 00:00:00+00:00</td>\n",
       "      <td>5.280</td>\n",
       "      <td>5.281</td>\n",
       "      <td>5.220</td>\n",
       "      <td>5.280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899922</th>\n",
       "      <td>2022-12-07 00:00:00+00:00</td>\n",
       "      <td>5.234</td>\n",
       "      <td>5.270</td>\n",
       "      <td>5.210</td>\n",
       "      <td>5.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899923</th>\n",
       "      <td>2022-12-08 00:00:00+00:00</td>\n",
       "      <td>5.204</td>\n",
       "      <td>5.248</td>\n",
       "      <td>5.194</td>\n",
       "      <td>5.204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899924</th>\n",
       "      <td>2022-12-09 00:00:00+00:00</td>\n",
       "      <td>5.224</td>\n",
       "      <td>5.280</td>\n",
       "      <td>5.215</td>\n",
       "      <td>5.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4899925 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date   Open   High    Low  Close    Volume  \\\n",
       "0       1980-03-17 00:00:00+00:00  0.000  0.426  0.420  0.420   43200.0   \n",
       "1       1980-03-18 00:00:00+00:00  0.000  0.417  0.417  0.417  327600.0   \n",
       "2       1980-03-19 00:00:00+00:00  0.000  0.417  0.417  0.417  115200.0   \n",
       "3       1980-03-20 00:00:00+00:00  0.000  0.420  0.420  0.420   28800.0   \n",
       "4       1980-03-21 00:00:00+00:00  0.000  0.420  0.420  0.420  554400.0   \n",
       "...                           ...    ...    ...    ...    ...       ...   \n",
       "4899920 2022-12-05 00:00:00+00:00  5.218  5.264  5.214  5.218       0.0   \n",
       "4899921 2022-12-06 00:00:00+00:00  5.280  5.281  5.220  5.280       0.0   \n",
       "4899922 2022-12-07 00:00:00+00:00  5.234  5.270  5.210  5.234       0.0   \n",
       "4899923 2022-12-08 00:00:00+00:00  5.204  5.248  5.194  5.204       0.0   \n",
       "4899924 2022-12-09 00:00:00+00:00  5.224  5.280  5.215  5.224       0.0   \n",
       "\n",
       "         Dividends  Stock Splits cod_yfinance  \n",
       "0              0.0           0.0          IPG  \n",
       "1              0.0           0.0          IPG  \n",
       "2              0.0           0.0          IPG  \n",
       "3              0.0           0.0          IPG  \n",
       "4              0.0           0.0          IPG  \n",
       "...            ...           ...          ...  \n",
       "4899920        0.0           0.0        BRL=X  \n",
       "4899921        0.0           0.0        BRL=X  \n",
       "4899922        0.0           0.0        BRL=X  \n",
       "4899923        0.0           0.0        BRL=X  \n",
       "4899924        0.0           0.0        BRL=X  \n",
       "\n",
       "[4899925 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data['Date'] = pd.to_datetime(historical_data['Date'], format='%Y-%m-%d', utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4899925 entries, 0 to 4899924\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Dtype              \n",
      "---  ------        -----              \n",
      " 0   Date          datetime64[ns, UTC]\n",
      " 1   Open          float64            \n",
      " 2   High          float64            \n",
      " 3   Low           float64            \n",
      " 4   Close         float64            \n",
      " 5   Volume        float64            \n",
      " 6   Dividends     float64            \n",
      " 7   Stock Splits  float64            \n",
      " 8   cod_yfinance  object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(7), object(1)\n",
      "memory usage: 336.5+ MB\n"
     ]
    }
   ],
   "source": [
    "historical_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cod_yfinance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-03-17 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>43200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-03-18 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.417</td>\n",
       "      <td>327600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-03-19 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.417</td>\n",
       "      <td>115200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-03-20 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-03-21 00:00:00+00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.420</td>\n",
       "      <td>554400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899920</th>\n",
       "      <td>2022-12-05 00:00:00+00:00</td>\n",
       "      <td>5.218</td>\n",
       "      <td>5.264</td>\n",
       "      <td>5.214</td>\n",
       "      <td>5.218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899921</th>\n",
       "      <td>2022-12-06 00:00:00+00:00</td>\n",
       "      <td>5.280</td>\n",
       "      <td>5.281</td>\n",
       "      <td>5.220</td>\n",
       "      <td>5.280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899922</th>\n",
       "      <td>2022-12-07 00:00:00+00:00</td>\n",
       "      <td>5.234</td>\n",
       "      <td>5.270</td>\n",
       "      <td>5.210</td>\n",
       "      <td>5.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899923</th>\n",
       "      <td>2022-12-08 00:00:00+00:00</td>\n",
       "      <td>5.204</td>\n",
       "      <td>5.248</td>\n",
       "      <td>5.194</td>\n",
       "      <td>5.204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899924</th>\n",
       "      <td>2022-12-09 00:00:00+00:00</td>\n",
       "      <td>5.224</td>\n",
       "      <td>5.280</td>\n",
       "      <td>5.215</td>\n",
       "      <td>5.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4899925 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date   Open   High    Low  Close    Volume  \\\n",
       "0       1980-03-17 00:00:00+00:00  0.000  0.426  0.420  0.420   43200.0   \n",
       "1       1980-03-18 00:00:00+00:00  0.000  0.417  0.417  0.417  327600.0   \n",
       "2       1980-03-19 00:00:00+00:00  0.000  0.417  0.417  0.417  115200.0   \n",
       "3       1980-03-20 00:00:00+00:00  0.000  0.420  0.420  0.420   28800.0   \n",
       "4       1980-03-21 00:00:00+00:00  0.000  0.420  0.420  0.420  554400.0   \n",
       "...                           ...    ...    ...    ...    ...       ...   \n",
       "4899920 2022-12-05 00:00:00+00:00  5.218  5.264  5.214  5.218       0.0   \n",
       "4899921 2022-12-06 00:00:00+00:00  5.280  5.281  5.220  5.280       0.0   \n",
       "4899922 2022-12-07 00:00:00+00:00  5.234  5.270  5.210  5.234       0.0   \n",
       "4899923 2022-12-08 00:00:00+00:00  5.204  5.248  5.194  5.204       0.0   \n",
       "4899924 2022-12-09 00:00:00+00:00  5.224  5.280  5.215  5.224       0.0   \n",
       "\n",
       "         Dividends  Stock Splits cod_yfinance  \n",
       "0              0.0           0.0          IPG  \n",
       "1              0.0           0.0          IPG  \n",
       "2              0.0           0.0          IPG  \n",
       "3              0.0           0.0          IPG  \n",
       "4              0.0           0.0          IPG  \n",
       "...            ...           ...          ...  \n",
       "4899920        0.0           0.0        BRL=X  \n",
       "4899921        0.0           0.0        BRL=X  \n",
       "4899922        0.0           0.0        BRL=X  \n",
       "4899923        0.0           0.0        BRL=X  \n",
       "4899924        0.0           0.0        BRL=X  \n",
       "\n",
       "[4899925 rows x 9 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_test = historical_data.iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 4899915 to 4899924\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   Date          10 non-null     datetime64[ns, UTC]\n",
      " 1   Open          10 non-null     float64            \n",
      " 2   High          10 non-null     float64            \n",
      " 3   Low           10 non-null     float64            \n",
      " 4   Close         10 non-null     float64            \n",
      " 5   Volume        10 non-null     float64            \n",
      " 6   Dividends     10 non-null     float64            \n",
      " 7   Stock Splits  10 non-null     float64            \n",
      " 8   cod_yfinance  10 non-null     object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(7), object(1)\n",
      "memory usage: 852.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "date_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cod_yfinance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4899915</th>\n",
       "      <td>2022-11-28 00:00:00+00:00</td>\n",
       "      <td>5.409</td>\n",
       "      <td>5.424</td>\n",
       "      <td>5.365</td>\n",
       "      <td>5.409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899916</th>\n",
       "      <td>2022-11-29 00:00:00+00:00</td>\n",
       "      <td>5.365</td>\n",
       "      <td>5.365</td>\n",
       "      <td>5.278</td>\n",
       "      <td>5.365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899917</th>\n",
       "      <td>2022-11-30 00:00:00+00:00</td>\n",
       "      <td>5.268</td>\n",
       "      <td>5.316</td>\n",
       "      <td>5.244</td>\n",
       "      <td>5.268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899918</th>\n",
       "      <td>2022-12-01 00:00:00+00:00</td>\n",
       "      <td>5.182</td>\n",
       "      <td>5.214</td>\n",
       "      <td>5.163</td>\n",
       "      <td>5.182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899919</th>\n",
       "      <td>2022-12-02 00:00:00+00:00</td>\n",
       "      <td>5.184</td>\n",
       "      <td>5.236</td>\n",
       "      <td>5.164</td>\n",
       "      <td>5.184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899920</th>\n",
       "      <td>2022-12-05 00:00:00+00:00</td>\n",
       "      <td>5.218</td>\n",
       "      <td>5.264</td>\n",
       "      <td>5.214</td>\n",
       "      <td>5.218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899921</th>\n",
       "      <td>2022-12-06 00:00:00+00:00</td>\n",
       "      <td>5.280</td>\n",
       "      <td>5.281</td>\n",
       "      <td>5.220</td>\n",
       "      <td>5.280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899922</th>\n",
       "      <td>2022-12-07 00:00:00+00:00</td>\n",
       "      <td>5.234</td>\n",
       "      <td>5.270</td>\n",
       "      <td>5.210</td>\n",
       "      <td>5.234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899923</th>\n",
       "      <td>2022-12-08 00:00:00+00:00</td>\n",
       "      <td>5.204</td>\n",
       "      <td>5.248</td>\n",
       "      <td>5.194</td>\n",
       "      <td>5.204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899924</th>\n",
       "      <td>2022-12-09 00:00:00+00:00</td>\n",
       "      <td>5.224</td>\n",
       "      <td>5.280</td>\n",
       "      <td>5.215</td>\n",
       "      <td>5.224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BRL=X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date   Open   High    Low  Close  Volume  \\\n",
       "4899915 2022-11-28 00:00:00+00:00  5.409  5.424  5.365  5.409     0.0   \n",
       "4899916 2022-11-29 00:00:00+00:00  5.365  5.365  5.278  5.365     0.0   \n",
       "4899917 2022-11-30 00:00:00+00:00  5.268  5.316  5.244  5.268     0.0   \n",
       "4899918 2022-12-01 00:00:00+00:00  5.182  5.214  5.163  5.182     0.0   \n",
       "4899919 2022-12-02 00:00:00+00:00  5.184  5.236  5.164  5.184     0.0   \n",
       "4899920 2022-12-05 00:00:00+00:00  5.218  5.264  5.214  5.218     0.0   \n",
       "4899921 2022-12-06 00:00:00+00:00  5.280  5.281  5.220  5.280     0.0   \n",
       "4899922 2022-12-07 00:00:00+00:00  5.234  5.270  5.210  5.234     0.0   \n",
       "4899923 2022-12-08 00:00:00+00:00  5.204  5.248  5.194  5.204     0.0   \n",
       "4899924 2022-12-09 00:00:00+00:00  5.224  5.280  5.215  5.224     0.0   \n",
       "\n",
       "         Dividends  Stock Splits cod_yfinance  \n",
       "4899915        0.0           0.0        BRL=X  \n",
       "4899916        0.0           0.0        BRL=X  \n",
       "4899917        0.0           0.0        BRL=X  \n",
       "4899918        0.0           0.0        BRL=X  \n",
       "4899919        0.0           0.0        BRL=X  \n",
       "4899920        0.0           0.0        BRL=X  \n",
       "4899921        0.0           0.0        BRL=X  \n",
       "4899922        0.0           0.0        BRL=X  \n",
       "4899923        0.0           0.0        BRL=X  \n",
       "4899924        0.0           0.0        BRL=X  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_test.to_sql(name='date_test_03', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_update_dataframe(dataframe):\n",
    "    \"\"\"Append update DataFrame to SQL dataset\n",
    "\n",
    "    Args: \n",
    "        dataframe (DataFrame): DataFrame, already formated, containing last days historical data. \n",
    "    \n",
    "    Returns**: \n",
    "        Append update DataFrame to SQL dataset \n",
    "    \"\"\"\n",
    "\n",
    "    dataframe.to_sql(name='historical_data_backup_2022-12-09', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_update_dataframe(historical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\AppData\\Local\\Temp\\ipykernel_5688\\382160274.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  date_test['Date'] = pd.to_datetime(date_test['Date'])\n"
     ]
    }
   ],
   "source": [
    "date_test['Date'] = pd.to_datetime(date_test['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_update_dataframe(date_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'date_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m date_test\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mstock_path\u001b[39m}\u001b[39;00m\u001b[39mdate_test.csv\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                     encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUTF-8\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                     sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m;\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m                     decimal\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                     index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'date_test' is not defined"
     ]
    }
   ],
   "source": [
    "date_test.to_csv(f'{stock_path}date_test.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_test_csv = pd.read_csv(f'{stock_path}date_test.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Date          10 non-null     object \n",
      " 1   Open          10 non-null     float64\n",
      " 2   High          10 non-null     float64\n",
      " 3   Low           10 non-null     float64\n",
      " 4   Close         10 non-null     float64\n",
      " 5   Volume        10 non-null     float64\n",
      " 6   Dividends     10 non-null     float64\n",
      " 7   Stock Splits  10 non-null     float64\n",
      " 8   cod_yfinance  10 non-null     object \n",
      "dtypes: float64(7), object(2)\n",
      "memory usage: 848.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "date_test_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_test_csv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update = pd.read_sql(sql = \"SELECT MAX(Date) FROM date_test_01\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABMD: No data found for this date range, symbol may be delisted\n",
      "SULA11.SA: No data found for this date range, symbol may be delisted\n",
      "BRML3.SA: No data found for this date range, symbol may be delisted\n",
      "DMMO3.SA: No data found for this date range, symbol may be delisted\n"
     ]
    }
   ],
   "source": [
    "teste_df = create_update_dataframe('2023-01-08', '2023-01-15', ['ABMD', 'SULA11.SA', 'BRML3.SA', 'DMMO3.SA', '^GSPC', 'ABEV3.SA', 'MSFT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>cod_yfinance</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-09 00:00:00-05:00</th>\n",
       "      <td>3910.820068</td>\n",
       "      <td>3950.570068</td>\n",
       "      <td>3890.419922</td>\n",
       "      <td>3892.090088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.311770e+09</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 00:00:00-05:00</th>\n",
       "      <td>3888.570068</td>\n",
       "      <td>3919.830078</td>\n",
       "      <td>3877.290039</td>\n",
       "      <td>3919.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.851030e+09</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11 00:00:00-05:00</th>\n",
       "      <td>3932.350098</td>\n",
       "      <td>3970.070068</td>\n",
       "      <td>3928.540039</td>\n",
       "      <td>3969.610107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.303360e+09</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-12 00:00:00-05:00</th>\n",
       "      <td>3977.570068</td>\n",
       "      <td>3997.760010</td>\n",
       "      <td>3937.560059</td>\n",
       "      <td>3983.169922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.440260e+09</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-13 00:00:00-05:00</th>\n",
       "      <td>3960.600098</td>\n",
       "      <td>4003.949951</td>\n",
       "      <td>3947.669922</td>\n",
       "      <td>3999.090088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.939700e+09</td>\n",
       "      <td>^GSPC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09 00:00:00-03:00</th>\n",
       "      <td>14.290000</td>\n",
       "      <td>14.470000</td>\n",
       "      <td>14.270000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.444860e+07</td>\n",
       "      <td>ABEV3.SA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 00:00:00-03:00</th>\n",
       "      <td>14.260000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>14.540000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.553500e+07</td>\n",
       "      <td>ABEV3.SA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11 00:00:00-03:00</th>\n",
       "      <td>14.510000</td>\n",
       "      <td>14.790000</td>\n",
       "      <td>13.950000</td>\n",
       "      <td>14.290000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.441960e+07</td>\n",
       "      <td>ABEV3.SA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-12 00:00:00-03:00</th>\n",
       "      <td>13.800000</td>\n",
       "      <td>14.170000</td>\n",
       "      <td>13.660000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.995950e+07</td>\n",
       "      <td>ABEV3.SA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-13 00:00:00-03:00</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.050000</td>\n",
       "      <td>13.770000</td>\n",
       "      <td>13.880000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.429130e+07</td>\n",
       "      <td>ABEV3.SA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-09 00:00:00-05:00</th>\n",
       "      <td>226.449997</td>\n",
       "      <td>231.240005</td>\n",
       "      <td>226.410004</td>\n",
       "      <td>227.119995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.736980e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 00:00:00-05:00</th>\n",
       "      <td>227.759995</td>\n",
       "      <td>231.309998</td>\n",
       "      <td>227.330002</td>\n",
       "      <td>228.850006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.703390e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11 00:00:00-05:00</th>\n",
       "      <td>231.289993</td>\n",
       "      <td>235.949997</td>\n",
       "      <td>231.110001</td>\n",
       "      <td>235.770004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.866930e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-12 00:00:00-05:00</th>\n",
       "      <td>235.259995</td>\n",
       "      <td>239.899994</td>\n",
       "      <td>233.559998</td>\n",
       "      <td>238.509995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.726950e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-13 00:00:00-05:00</th>\n",
       "      <td>237.000000</td>\n",
       "      <td>239.369995</td>\n",
       "      <td>234.919998</td>\n",
       "      <td>239.229996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.131770e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "2023-01-09 00:00:00-05:00  3910.820068  3950.570068  3890.419922  3892.090088   \n",
       "2023-01-10 00:00:00-05:00  3888.570068  3919.830078  3877.290039  3919.250000   \n",
       "2023-01-11 00:00:00-05:00  3932.350098  3970.070068  3928.540039  3969.610107   \n",
       "2023-01-12 00:00:00-05:00  3977.570068  3997.760010  3937.560059  3983.169922   \n",
       "2023-01-13 00:00:00-05:00  3960.600098  4003.949951  3947.669922  3999.090088   \n",
       "2023-01-09 00:00:00-03:00    14.290000    14.470000    14.270000    14.400000   \n",
       "2023-01-10 00:00:00-03:00    14.260000    14.600000    14.250000    14.540000   \n",
       "2023-01-11 00:00:00-03:00    14.510000    14.790000    13.950000    14.290000   \n",
       "2023-01-12 00:00:00-03:00    13.800000    14.170000    13.660000    14.100000   \n",
       "2023-01-13 00:00:00-03:00    14.000000    14.050000    13.770000    13.880000   \n",
       "2023-01-09 00:00:00-05:00   226.449997   231.240005   226.410004   227.119995   \n",
       "2023-01-10 00:00:00-05:00   227.759995   231.309998   227.330002   228.850006   \n",
       "2023-01-11 00:00:00-05:00   231.289993   235.949997   231.110001   235.770004   \n",
       "2023-01-12 00:00:00-05:00   235.259995   239.899994   233.559998   238.509995   \n",
       "2023-01-13 00:00:00-05:00   237.000000   239.369995   234.919998   239.229996   \n",
       "\n",
       "                           Adj Close        Volume cod_yfinance  Dividends  \\\n",
       "Date                                                                         \n",
       "2023-01-09 00:00:00-05:00        NaN  4.311770e+09        ^GSPC        0.0   \n",
       "2023-01-10 00:00:00-05:00        NaN  3.851030e+09        ^GSPC        0.0   \n",
       "2023-01-11 00:00:00-05:00        NaN  4.303360e+09        ^GSPC        0.0   \n",
       "2023-01-12 00:00:00-05:00        NaN  4.440260e+09        ^GSPC        0.0   \n",
       "2023-01-13 00:00:00-05:00        NaN  3.939700e+09        ^GSPC        0.0   \n",
       "2023-01-09 00:00:00-03:00        NaN  2.444860e+07     ABEV3.SA        0.0   \n",
       "2023-01-10 00:00:00-03:00        NaN  3.553500e+07     ABEV3.SA        0.0   \n",
       "2023-01-11 00:00:00-03:00        NaN  7.441960e+07     ABEV3.SA        0.0   \n",
       "2023-01-12 00:00:00-03:00        NaN  6.995950e+07     ABEV3.SA        0.0   \n",
       "2023-01-13 00:00:00-03:00        NaN  4.429130e+07     ABEV3.SA        0.0   \n",
       "2023-01-09 00:00:00-05:00        NaN  2.736980e+07         MSFT        0.0   \n",
       "2023-01-10 00:00:00-05:00        NaN  2.703390e+07         MSFT        0.0   \n",
       "2023-01-11 00:00:00-05:00        NaN  2.866930e+07         MSFT        0.0   \n",
       "2023-01-12 00:00:00-05:00        NaN  2.726950e+07         MSFT        0.0   \n",
       "2023-01-13 00:00:00-05:00        NaN  2.131770e+07         MSFT        0.0   \n",
       "\n",
       "                           Stock Splits  \n",
       "Date                                     \n",
       "2023-01-09 00:00:00-05:00           0.0  \n",
       "2023-01-10 00:00:00-05:00           0.0  \n",
       "2023-01-11 00:00:00-05:00           0.0  \n",
       "2023-01-12 00:00:00-05:00           0.0  \n",
       "2023-01-13 00:00:00-05:00           0.0  \n",
       "2023-01-09 00:00:00-03:00           0.0  \n",
       "2023-01-10 00:00:00-03:00           0.0  \n",
       "2023-01-11 00:00:00-03:00           0.0  \n",
       "2023-01-12 00:00:00-03:00           0.0  \n",
       "2023-01-13 00:00:00-03:00           0.0  \n",
       "2023-01-09 00:00:00-05:00           0.0  \n",
       "2023-01-10 00:00:00-05:00           0.0  \n",
       "2023-01-11 00:00:00-05:00           0.0  \n",
       "2023-01-12 00:00:00-05:00           0.0  \n",
       "2023-01-13 00:00:00-05:00           0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_update_dataframe(start, end, ticker_list):\n",
    "    \"\"\"Create a DataFrame with last days historical data.\n",
    "    \n",
    "    Args: \n",
    "        start (string): Date string in YYYY-MM-DD format - One day after the last update \n",
    "        end (string): Date string in YYYY-MM-DD format - Today\n",
    "        ticker_list (iterable): iterable containing yfinance code for the companies and indexes\n",
    "    \n",
    "    Returns: \n",
    "        df (dataframe): DataFrame with last days historical data. \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        aux_df = pd.DataFrame()\n",
    "        aux_df = yf.Ticker(ticker).history(start=start, end=end)\n",
    "        aux_df['cod_yfinance'] = ticker\n",
    "        \n",
    "        df = pd.concat([df, aux_df], axis=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_update_dataframe(start, end, ticker_list):\n",
    "    \"\"\"Create a DataFrame with last days historical data.\n",
    "        Logging tracks how many entries each ticker got and save on a new .txt for each day the code runs\n",
    "    \n",
    "    Args: \n",
    "        start (string): Date string in YYYY-MM-DD format - One day after the last update \n",
    "        end (string): Date string in YYYY-MM-DD format - Today\n",
    "        ticker_list (iterable): iterable containing yfinance code for the companies and indexes\n",
    "    \n",
    "    Returns: \n",
    "        df (dataframe): DataFrame with last days historical data. \n",
    "    \"\"\"\n",
    "    \n",
    "    #Track number of entries for each ticker\n",
    "    entries_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, '7+':0 } \n",
    "    ticker_dict = {0:[], 1:[], 2:[], 3:[], 4:[], 5:[], 6:[], 7:[], '7+':[]}\n",
    "\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for ticker in ['ABMD', 'SULA11.SA', 'BRML3.SA', 'DMMO3.SA', '^GSPC', 'ABEV3.SA', 'MSFT']:\n",
    "        aux_df = pd.DataFrame()\n",
    "        aux_df = yf.Ticker(ticker).history(start='2023-01-08', end='2023-01-19')\n",
    "\n",
    "        if aux_df.empty:\n",
    "            logging.warning(f'{ticker}: No data found for this range')\n",
    "            entries_dict[0] += 1\n",
    "            ticker_dict[0].append(ticker)\n",
    "\n",
    "        else:\n",
    "            if aux_df.shape[0] == 1:\n",
    "                entries_dict[1] += 1\n",
    "                ticker_dict[1].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 2:\n",
    "                entries_dict[2] += 1\n",
    "                ticker_dict[2].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 3:\n",
    "                entries_dict[3] += 1\n",
    "                ticker_dict[3].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 4:\n",
    "                entries_dict[4] += 1\n",
    "                ticker_dict[4].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 5:\n",
    "                entries_dict[5] += 1\n",
    "                ticker_dict[5].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 6:\n",
    "                entries_dict[6] += 1\n",
    "                ticker_dict[6].append(ticker)\n",
    "\n",
    "            elif aux_df.shape[0] == 7:\n",
    "                entries_dict[7] += 1\n",
    "                ticker_dict[7].append(ticker)\n",
    "\n",
    "            else:\n",
    "                entries_dict['7+'] += 1\n",
    "                ticker_dict['7+'].append(ticker)\n",
    "\n",
    "            aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "        df = pd.concat([df, aux_df], axis=0)\n",
    "\n",
    "    for key, value in entries_dict.items():\n",
    "        if value == 0:\n",
    "            logger.info(f'No tickers with {key} entries')\n",
    "        else: \n",
    "            logger.info(f'Number of tickers with {key} entries: {value}')\n",
    "            logger.info(f'Tickers: {ticker_dict[key]}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 9)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_sql(name='date_test_02', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_update_dataframe(dataframe):\n",
    "    \"\"\"Append update DataFrame to SQL dataset       ********revisar se está correto a maneira de verificar o append de linhas********\n",
    "\n",
    "    Args: \n",
    "        dataframe (DataFrame): DataFrame, already formated, containing last days historical data. \n",
    "    \n",
    "    Returns**: \n",
    "        Append update DataFrame to SQL dataset \n",
    "    \"\"\"\n",
    "\n",
    "    dataframe.to_sql(name='date_test_03', con=engine, if_exists='replace', index=False)\n",
    "    \n",
    "    return dataframe.to_sql(name='date_test_03', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_rows_sql(row_df, row_SQL):\n",
    "    \"\"\"Verify if SQL got all the rows in the DF\n",
    "\n",
    "    Args:\n",
    "        row_df (int): number of rows in the DataFrame to be appended \n",
    "        row_SQL (int): number of rows appended in the SQL database\n",
    "    \n",
    "    Return:\n",
    "        Loggging tracking if everything occurred as expected\n",
    "    \"\"\"\n",
    "\n",
    "    if row_df == row_SQL:\n",
    "        logger.info(f'SQL update successfull. All {row_df} where appended to the database')\n",
    "\n",
    "    else:\n",
    "        logger.warning(f'ERROR in SQL update. Only {row_SQL} out of {row_df} where appended to the database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_update_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 4, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 2, '7+': 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['ABMD', 'SULA11.SA', 'BRML3.SA', 'DMMO3.SA'],\n",
       " 1: [],\n",
       " 2: [],\n",
       " 3: [],\n",
       " 4: [],\n",
       " 5: [],\n",
       " 6: [],\n",
       " 7: ['^GSPC', 'MSFT'],\n",
       " '7+': ['ABEV3.SA']}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste_df.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_df = yf.Ticker('MSFT').history(start='2023-01-08', end='2023-01-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-09 00:00:00-05:00</th>\n",
       "      <td>226.449997</td>\n",
       "      <td>231.240005</td>\n",
       "      <td>226.410004</td>\n",
       "      <td>227.119995</td>\n",
       "      <td>27369800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-10 00:00:00-05:00</th>\n",
       "      <td>227.759995</td>\n",
       "      <td>231.309998</td>\n",
       "      <td>227.330002</td>\n",
       "      <td>228.850006</td>\n",
       "      <td>27033900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-11 00:00:00-05:00</th>\n",
       "      <td>231.289993</td>\n",
       "      <td>235.949997</td>\n",
       "      <td>231.110001</td>\n",
       "      <td>235.770004</td>\n",
       "      <td>28669300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-12 00:00:00-05:00</th>\n",
       "      <td>235.259995</td>\n",
       "      <td>239.899994</td>\n",
       "      <td>233.559998</td>\n",
       "      <td>238.509995</td>\n",
       "      <td>27269500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-13 00:00:00-05:00</th>\n",
       "      <td>237.000000</td>\n",
       "      <td>239.369995</td>\n",
       "      <td>234.919998</td>\n",
       "      <td>239.229996</td>\n",
       "      <td>21317700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-17 00:00:00-05:00</th>\n",
       "      <td>237.970001</td>\n",
       "      <td>240.910004</td>\n",
       "      <td>237.089996</td>\n",
       "      <td>240.350006</td>\n",
       "      <td>29831300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-18 00:00:00-05:00</th>\n",
       "      <td>241.570007</td>\n",
       "      <td>242.380005</td>\n",
       "      <td>235.520004</td>\n",
       "      <td>235.809998</td>\n",
       "      <td>30004400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2023-01-09 00:00:00-05:00  226.449997  231.240005  226.410004  227.119995   \n",
       "2023-01-10 00:00:00-05:00  227.759995  231.309998  227.330002  228.850006   \n",
       "2023-01-11 00:00:00-05:00  231.289993  235.949997  231.110001  235.770004   \n",
       "2023-01-12 00:00:00-05:00  235.259995  239.899994  233.559998  238.509995   \n",
       "2023-01-13 00:00:00-05:00  237.000000  239.369995  234.919998  239.229996   \n",
       "2023-01-17 00:00:00-05:00  237.970001  240.910004  237.089996  240.350006   \n",
       "2023-01-18 00:00:00-05:00  241.570007  242.380005  235.520004  235.809998   \n",
       "\n",
       "                             Volume  Dividends  Stock Splits  \n",
       "Date                                                          \n",
       "2023-01-09 00:00:00-05:00  27369800        0.0           0.0  \n",
       "2023-01-10 00:00:00-05:00  27033900        0.0           0.0  \n",
       "2023-01-11 00:00:00-05:00  28669300        0.0           0.0  \n",
       "2023-01-12 00:00:00-05:00  27269500        0.0           0.0  \n",
       "2023-01-13 00:00:00-05:00  21317700        0.0           0.0  \n",
       "2023-01-17 00:00:00-05:00  29831300        0.0           0.0  \n",
       "2023-01-18 00:00:00-05:00  30004400        0.0           0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.Ticker('MSFT').history(start='2023-01-08', end='2023-01-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_update_dataframe('2023-01-08', '2023-01-18', ['ABMD', 'SULA11.SA', 'BRML3.SA', 'DMMO3.SA', '^GSPC', 'ABEV3.SA', 'MSFT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.today()\n",
    "today = today.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-20'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    filename=f'{logging_path}{today}.log',\n",
    "                    format='%(asctime)s.%(msecs)03d %(levelname)s - %(funcName)s: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.info(f'7 entries: {entries_dict[7]}')\n",
    "#logging.warning(f'0 entries: {entries_dict[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('Logging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logger = logging.getLogger('name')\n",
    "def func_test_log():\n",
    "    logger.critical(f'Testing simple log.')\n",
    "func_test_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = pd.read_sql(sql='SELECT cod_yfinance FROM companies', con=engine)['cod_yfinance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159           A\n",
       "23          AAL\n",
       "155    AALR3.SA\n",
       "625         AAP\n",
       "142        AAPL\n",
       "         ...   \n",
       "191         ZTS\n",
       "726       ^BVSP\n",
       "729        ^DJI\n",
       "730       ^GSPC\n",
       "727      ^IBX50\n",
       "Name: cod_yfinance, Length: 735, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_list.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_sql(name='historical_data_backup_2022-12-09', con=engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "148dec39413d40c2e0b225421a61564057689d91bfcabc655e2b03b1997f7cfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
