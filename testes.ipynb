{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas_datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yfinance --upgrade --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install html5lib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import os\n",
    "import yfinance as yf\n",
    "from time import sleep\n",
    "import glob\n",
    "import regex as re\n",
    "import datetime\n",
    "import sqlalchemy as db\n",
    "from dotenv import load_dotenv\n",
    "from datetime import timedelta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - Brazilian Companies\n",
    "\n",
    "### List of brazilian companies and composition of indexes - Ibovespa, IBrX100, IBrX50, IBrA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium\n",
    "\n",
    "Used to get list of companies in brazilian's index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurating WebDriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurating download file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromeOptions = webdriver.ChromeOptions()\n",
    "download_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project\\data'\n",
    "prefs = {\"download.default_directory\" : download_path}\n",
    "chromeOptions.add_experimental_option(\"prefs\",prefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the webdriver\n",
    "driver = webdriver.Chrome(options=chromeOptions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Index File (.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_stocks(index, wait=6):\n",
    "    '''\n",
    "        Receives the Index name, download a file that contains the index tickers, and return the name of the downloaded file\n",
    "    '''\n",
    "\n",
    "    # Chrome WebDriver opens the index webside\n",
    "    url = f'https://sistemaswebb3-listados.b3.com.br/indexPage/day/{index.upper()}?language=pt-br'\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(wait)\n",
    "\n",
    "    driver.find_element(By.ID, 'segment').send_keys(\"Setor de Atuação\")\n",
    "    driver.implicitly_wait(wait)\n",
    "    driver.find_element(By.LINK_TEXT, 'Download').click()\n",
    "    driver.implicitly_wait(wait)\n",
    "\n",
    "    # Set the directory\n",
    "    os.chdir(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project\\data')\n",
    "    sleep(wait)\n",
    "\n",
    "    # Get the .csv files from the selectec directory and sort them ascending by modification date \n",
    "    files = list(glob.glob('*csv'))\n",
    "    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)\n",
    "\n",
    "    # Returns the name of the most recent file\n",
    "    return files[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Index DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(file):\n",
    "    '''\n",
    "        This function receives the name of the Stock Exchange index and returns a DataFrame with all companies and their respective sectors\n",
    "    '''\n",
    "\n",
    "    # Creating DataFrame\n",
    "    DataFrame = pd.read_csv(file, \n",
    "                                encoding='ISO-8859-1',\n",
    "                                header=1,                   # Uses line 1 as header\n",
    "                                sep=';',                    \n",
    "                                decimal=',',\n",
    "                                thousands='.',\n",
    "                                skipfooter=2,               # Removes last 2 lines\n",
    "                                engine='python',\n",
    "                                index_col=False)            # Does not make first column as index\n",
    "    \n",
    "    # Normalizing columns\n",
    "    DataFrame.columns = [re.sub('[\\.()]', '', re.sub(' ', '_', unidecode(columns.lower()))) for columns in DataFrame.columns]\n",
    "\n",
    "    return DataFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Index's DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining file's path\n",
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project\\data/'\n",
    "# Historical dataset is to big to upload to GitHub\n",
    "stock_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining DataFrames' columns names\n",
    "col_names = [\n",
    "    'sector',\n",
    "    'ticker',\n",
    "    'name',\n",
    "    'type',\n",
    "    'amount',\n",
    "    'percentage',\n",
    "    'percentage_acum'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ibovespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov = create_df(get_index_stocks('ibov'))\n",
    "len(ibov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibov.to_csv(f'{path}IBOV.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBrX100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx = create_df(get_index_stocks('ibxx'))\n",
    "len(ibrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibrx.to_csv(f'{path}IBRX100.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBrX50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx50 = create_df(get_index_stocks('ibxl'))\n",
    "len(ibrx50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibrx50.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibrx50.to_csv(f'{path}IBRX50.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBrA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = create_df(get_index_stocks('ibra'))\n",
    "len(ibra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save index file\n",
    "ibra.to_csv(f'{path}IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Sector - Obsoleto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = pd.read_csv(f'{path}IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ibra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra[['sector_aux', 'sub_sector_aux']] = ibra['sector'].str.split('/',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['sector_aux'] = ibra['sector_aux'].str.strip()\n",
    "ibra['sub_sector_aux'] = ibra['sub_sector_aux'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ibra['sector_aux'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ibra['sub_sector_aux'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando empresas que divergem nos dois índices - Obsoleto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ibrx = ibrx['codigo']\n",
    "set_ibrx = set(emp_ibrx)\n",
    "len(set_ibrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ibov = ibov['codigo']\n",
    "set_ibov = set(emp_ibov)\n",
    "len(set_ibov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ibra = ibra['codigo']\n",
    "set_ibra = set(emp_ibra)\n",
    "len(set_ibra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set_ibra.difference(set_ibrx)))\n",
    "print(set_ibra.difference(set_ibrx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set_ibov.difference(set_ibrx)))\n",
    "print(set_ibov.difference(set_ibrx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set_ibrx.difference(set_ibov)))\n",
    "print(set_ibrx.difference(set_ibov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando qual empresa da lista completa não exista em 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_codigo = set(lista_codigo)\n",
    "set_empresas_2021 = set(empresas_2021)\n",
    "\n",
    "print(len(set_codigo.difference(set_empresas_2021)))\n",
    "print(set_codigo.difference(set_empresas_2021))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando DataFrame unindo os dois índices - Obsoleto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empresas = pd.concat([ibrx, ibov]).drop_duplicates(subset='codigo', ignore_index=True).drop(['qtde_teorica',r'part_%',r'part_%acum'], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - Brazilian Companies Historical Dataset\n",
    "\n",
    "### Create data set concatenating historical datasets downloaded from B3 website with data from the companies listed in IBRA Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando lista com o código dos pricipais ativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utilizar lista do IBRA\n",
    "codigo = list(set_ibra)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\data_visualization\\data/'\n",
    "\n",
    "i = 1986\n",
    "\n",
    "while i < 2000:\n",
    "    with zipfile.ZipFile(f'{path}COTAHIST_A{i}.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "    i +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2000\n",
    "\n",
    "while i < 2022:\n",
    "    os.rename(f'COTAHIST_A{i}.TXT', f'COTAHIST_A{i}.txt')\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting configurations to read B3 historical files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.options.display.max_columns=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\B3\\txt/'\n",
    "\n",
    "year = 2022\n",
    "\n",
    "widths = [2,8,2,12,3,12,10,3,4,13,13,13,13,13,13,13,5,18,18,13,1,8,7,13,12,3]\n",
    "\n",
    "col_names = [\n",
    "\"tipo_registro\",\n",
    "\"data_pregao\",\n",
    "\"cod_bdi\",\n",
    "\"cod_negociacao\",\n",
    "\"tipo_mercado\",\n",
    "\"nome_empresa\",\n",
    "\"especificacao_papel\",\n",
    "\"prazo_dias_merc_termo\",\n",
    "\"moeda_referencia\",\n",
    "\"preco_abertura\",\n",
    "\"preco_maximo\",\n",
    "\"preco_minimo\",\n",
    "\"preco_medio\",\n",
    "\"preco_ultimo_negocio\",\n",
    "\"preco_melhor_oferta_compra\",\n",
    "\"preco_melhor_oferta_venda\",\n",
    "\"numero_negocios\",\n",
    "\"quantidade_papeis_negociados\",\n",
    "\"volume_total_negociado\",\n",
    "\"preco_exercicio\",\n",
    "\"ìndicador_correcao_precos\",\n",
    "\"data_vencimento\" ,\n",
    "\"fator_cotacao\",\n",
    "\"preco_exercicio_pontos\",\n",
    "\"codigo_isin\",\n",
    "\"num_distribuicao_papel\"]\n",
    "\n",
    "decimal_config=[\n",
    "\"preco_abertura\",\n",
    "\"preco_maximo\",\n",
    "\"preco_minimo\",\n",
    "\"preco_medio\",\n",
    "\"preco_ultimo_negocio\",\n",
    "\"preco_melhor_oferta_compra\",\n",
    "\"preco_melhor_oferta_venda\",\n",
    "\"volume_total_negociado\",\n",
    "\"preco_exercicio\",\n",
    "\"preco_exercicio_pontos\"\n",
    "]\n",
    "\n",
    "\n",
    "remains = [\n",
    "\"data_pregao\",\n",
    "\"cod_negociacao\",\n",
    "\"tipo_mercado\",\n",
    "\"nome_empresa\",\n",
    "\"preco_abertura\",\n",
    "\"preco_maximo\",\n",
    "\"preco_minimo\",\n",
    "\"preco_medio\",\n",
    "\"preco_ultimo_negocio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''     Concatenate DataFrames\n",
    "year = 2022\n",
    "while year > 1985:\n",
    "    df = pd.read_fwf(f'{path}COTAHIST_A{year}.TXT',\n",
    "                                    encoding='ISO-8859-1',\n",
    "                                    header=0,\n",
    "                                    widths=widths,\n",
    "                                    skipfooter=1,\n",
    "                                    engine='python',\n",
    "                                    parse_dates=[1],\n",
    "                                    infer_datetime_format=True,\n",
    "                                    index_col=False)\n",
    "    year -= 1\n",
    "\n",
    "    #Definindo nomes das colunas\n",
    "    df.columns = col_names\n",
    "\n",
    "    #Corrigindo casas decimais\n",
    "    for col in decimal_config:\n",
    "        df[col]=df[col]/100\n",
    "\n",
    "    #Selecionando colunas\n",
    "    df = df[remains]\n",
    "    \n",
    "    #Mascara de empresas desejadas\n",
    "    mask_empresas = df.cod_negociacao.isin(codigo)\n",
    "\n",
    "    df = df[mask_empresas]\n",
    "\n",
    "    dataset = pd.concat([dataset, df], ignore_index=True)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export DF - Historical Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(f'{path}dataset_IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f'{path}dataset_IBRA.csv',\n",
    "                encoding='ISO-8859-1',\n",
    "                sep=';',\n",
    "                decimal='.',\n",
    "                index_col=False\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data From Yahoo Finance\n",
    "\n",
    "### Get historical series of brazilian and american indexes\n",
    "### Get historical series of Gold, Bitcoin and Ethererum\n",
    "### Get historical series of american companies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set YFinance setting\n",
    "\n",
    "symbol_list_br = ['^BVSP','^IBX50']\n",
    "symbol_list_eua = ['^DJI','^IXIC','^GSPC','GC=F']\n",
    "symbol_list_crypto = ['BTC-USD', 'ETH-USD']\n",
    "\n",
    "name_dict={\n",
    "    '^BVSP':'Ibovespa',\n",
    "    '^IBX50':'IBrX50',\n",
    "    '^DJI':'Dow Jones',\n",
    "    '^IXIC':'NASDAQ',\n",
    "    '^GSPC':'S&P 500',\n",
    "    'GC=F':'Ouro ($)',\n",
    "    'BTC-USD':'Bitcoin ($)',\n",
    "    'ETH-USD':'Ethereum ($)'\n",
    "}\n",
    "\n",
    "col_names = ['date',\n",
    "\"open\",\n",
    "\"high\",\n",
    "\"low\",\n",
    "\"close\",\n",
    "'cod_yfinance']\n",
    "\n",
    "drop_col = ['Volume','Dividends','Stock Splits']\n",
    "\n",
    "start = '2000-01-01'\n",
    "start_br ='2004-11-03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty indexes DataFrames\n",
    "'''\n",
    "df_br = pd.DataFrame()\n",
    "df_eua = pd.DataFrame()\n",
    "df_crypto = pd.DataFrame()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill brazilian indexes historical series dataset\n",
    "'''\n",
    "for ativo in symbol_list_br:\n",
    "        chamada_api = yf.Ticker(ativo).history(period='max')\n",
    "        chamada_api['cod_yfinace'] = ativo\n",
    "        df_br = pd.concat([df_br, chamada_api])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform data from index to column 0\n",
    "'''\n",
    "df_br = df_br.drop(drop_col, axis = 1)\n",
    "df_br.reset_index(inplace=True)\n",
    "df_br['Date'] = df_br['Date'].dt.date\n",
    "df_br.columns = col_names\n",
    "df_br\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put indexes names in the DF\n",
    "df_br['name'] = df_br['cod_yfinance'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reroder columns\n",
    "df_br = df_br[['date','name','open','high','low','close','cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "df_br.to_csv(f'{path}index_br.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame\n",
    "index_br = pd.read_csv(f'{path}index_br.csv',\n",
    "                    sep = ';',\n",
    "                    decimal = '.',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_br"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill american indexes and gold historical series dataset\n",
    "'''\n",
    "for ativo in symbol_list_eua:\n",
    "        chamada_api = yf.Ticker(ativo).history(period='max')\n",
    "        chamada_api['cod_yfinance'] = ativo\n",
    "        df_eua = pd.concat([df_eua, chamada_api])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform data from index to column 0\n",
    "'''\n",
    "df_eua = df_eua.drop(drop_col, axis = 1)\n",
    "df_eua.reset_index(inplace=True)\n",
    "df_eua['Date'] = df_eua['Date'].dt.date\n",
    "df_eua.columns = col_names\n",
    "df_eua\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put indexes names in the DF\n",
    "df_eua['name'] = df_eua['cod_yfinance'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_eua = df_eua[['date','name','open','high','low','close','cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "df_eua.to_csv(f'{path}index_eua.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read DataFrame\n",
    "index_eua = pd.read_csv(f'{path}index_eua.csv',\n",
    "                    sep = ';',\n",
    "                    decimal = '.',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill cripto historical series dataset\n",
    "'''\n",
    "for ativo in symbol_list_crypto:\n",
    "        chamada_api = yf.Ticker(ativo).history(period='max')\n",
    "        chamada_api['cod_yfinace'] = ativo\n",
    "        df_crypto = pd.concat([df_crypto, chamada_api])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform data from index to column 0\n",
    "'''\n",
    "df_crypto = df_crypto.drop(drop_col, axis = 1)\n",
    "df_crypto.reset_index(inplace=True)\n",
    "df_crypto['Date'] = df_crypto['Date'].dt.date\n",
    "df_crypto.columns = col_names\n",
    "df_crypto\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put indexes names in the DF\n",
    "df_crypto['name'] = df_crypto['cod_yfinance'].map(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_crypto = df_crypto[['date','name','open','high','low','close','cod_yfinance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crypto.to_csv(f'{path}crypto.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = pd.read_csv(f'{path}crypto.csv',\n",
    "                    sep = ';',\n",
    "                    decimal = '.',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    index_col=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - American Companies\n",
    "\n",
    "### List of american companies and composition of indexes - S&P500, Dow Jones, Nasdaq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = data[0].iloc[:,[0,1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.columns = ['ticker', 'name', 'sector', 'sub_industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.to_csv(f'{path}SP500.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f'{path}SP500.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Nasdaq-100'\n",
    "\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[4]\n",
    "nasdaq = data[4]\n",
    "nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq.columns = ['name','ticker', 'sector', 'sub_industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq.to_csv(f'{path}NASDAQ.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = pd.read_csv(f'{path}NASDAQ.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dow Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average'\n",
    "\n",
    "data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]\n",
    "dow_jones = data[1].iloc[:,[0,2,3]]\n",
    "dow_jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones.columns = ['name','ticker', 'sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones.to_csv(f'{path}DOW_JONES.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_jones = pd.read_csv(f'{path}DOW_JONES.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame with all companies in american indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_sp500 = sp500['ticker']\n",
    "set_sp500 = set(emp_sp500)\n",
    "len(set_sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_nasdaq = nasdaq['ticker']\n",
    "set_nasdaq = set(emp_nasdaq)\n",
    "len(set_nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Companies in Nasdaq that aren't in sp500\n",
    "print(len(set_nasdaq.difference(set_sp500)))\n",
    "print(set_nasdaq.difference(set_sp500))\n",
    "list_nasdaq = list(set_nasdaq.difference(set_sp500))\n",
    "list_nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF with all companies in both indexes\n",
    "sp500_concat = pd.concat([sp500,nasdaq.loc[nasdaq['ticker'].isin(list_nasdaq)]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DF\n",
    "sp500_concat.to_csv(f'{path}eua_all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data - Company's Sector and Industry\n",
    "\n",
    "### Get sector and sub-sector of all companies using WebScrapping on Yahoo Finance website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = pd.read_csv(f'{path}IBRA.csv',\n",
    "                    encoding='ISO-8859-1',\n",
    "                    sep=';',\n",
    "                    decimal='.')\n",
    "\n",
    "ibra = ibra[['ticker','name','sector']]\n",
    "ibra[['sector','sub_industry']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua = pd.read_csv(f'{path}eua_all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua[eua['ticker'].str.contains(r'[^a-zA-Z0-9]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '.' in S&P500 ticker to '-', in order to get the right ticker for yfinance webscrapping\n",
    "eua['ticker'].replace(r'[^a-zA-Z0-9]', r'-', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the webdriver\n",
    "driver = webdriver.Chrome(options=chromeOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "wait = 8\n",
    "\n",
    "for i in eua['ticker']:\n",
    "    # Get the Yfinance company's url\n",
    "    url = f'https://finance.yahoo.com/quote/{i}/profile?p={i}'\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(wait)\n",
    "\n",
    "    # Get company's sector\n",
    "    try:\n",
    "        sector = driver.find_element(By.XPATH, '//*[@id=\"Col1-0-Profile-Proxy\"]/section/div[1]/div/div/p[2]/span[2]')\n",
    "        driver.implicitly_wait(wait)\n",
    "        eua.loc[index, 'sector'] = sector.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Get company's industry\n",
    "    try:\n",
    "        industry = driver.find_element(By.XPATH, '//*[@id=\"Col1-0-Profile-Proxy\"]/section/div[1]/div/div/p[2]/span[4]')\n",
    "        driver.implicitly_wait(wait)\n",
    "        eua.loc[index, 'sub_industry'] = industry.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Update index\n",
    "    index +=1    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if all companies in IBRA index have sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra[ibra['sector'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra[ibra['sector'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.loc[[149,151,200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.loc[149,('sector','sub_industry')] = ['Healthcare', 'Drug Manufacturers—Specialty & Generic']\n",
    "ibra.loc[151,('sector','sub_industry')] = ['Healthcare', 'Drug Manufacturers—Specialty & Generic']\n",
    "ibra.loc[200,('sector','sub_industry')] = ['Utilities', 'Utilities—Independent Power Producers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.to_csv(f'{path}IBRA_sector.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra = ibra.rename({'sub_industry':'industry'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_yfinance = [f'{i}.SA' for i in ibra['ticker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['cod_yfinance'] = cod_yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra['country'] = 'Brazil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if all companies in eua DataFrame have sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua['sector'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataframe\n",
    "eua.to_csv(f'{path}eua_all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua = eua.rename({'sub_industry':'industry'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua['cod_yfinance'] = eua['ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua['country'] = 'USA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating IBRA dataset - Obsoleto - criar novo dataframe com series históricas retiradas do yfinace para todas as empresas\n",
    "\n",
    "### (dataset that contains brazilian companies's historical data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets\n",
    "\n",
    "### Dataset that contains brazilian and american companies's characteristics\n",
    "### Dataset that contains brazilian and american companies's historical data\n",
    "### Dataset that contains brazilian and american indexes, gold, dolar (R$), bitcoin and ethereum  characteristics\n",
    "### Dataset that contains brazilian and american indexes, gold, dolar (R$), bitcoin and ethereum  historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical dataset is to big to upload to GitHub\n",
    "stock_path = r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\05. Dados\\stock_project_datasets/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with all companies's characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eua.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.concat([ibra, eua], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.to_csv(f'{stock_path}all_companies.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_rev4.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with indexes, gold, dolar (R$), bitcoin and ethereum  characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ticker = [\n",
    "    'IBOV'\n",
    "    ,'IBRX50'\n",
    "    ,'NASDAQ'\n",
    "    ,'DOW JONES'\n",
    "    ,'SP500'\n",
    "    ,'GOLD'\n",
    "    ,'BTC'\n",
    "    ,'ETH'\n",
    "    ,'USD-BRL'\n",
    "]\n",
    "\n",
    "index_name = [\n",
    "    'Ibovespa'\n",
    "    ,'IBrX50'\n",
    "    ,'Nasdaq 100'\n",
    "    ,'Dow Jones Industrial Average'\n",
    "    ,'S&P 500'\n",
    "    ,'Gold (US$)'\n",
    "    ,'Bitcoin (US$)'\n",
    "    ,'Ethereum (US$)'\n",
    "    ,'Dolar (R$)'\n",
    "]\n",
    "\n",
    "index_sector = [\n",
    "    'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Gold'\n",
    "    ,'Crypto'\n",
    "    ,'Crypto'\n",
    "    ,'Currency'\n",
    "]\n",
    "\n",
    "index_industry = [\n",
    "    'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Gold'\n",
    "    ,'Crypto'\n",
    "    ,'Crypto'\n",
    "    ,'Currency'\n",
    "]\n",
    "\n",
    "index_cod = [\n",
    "    '^BVSP'\n",
    "    ,'^IBX50'\n",
    "    ,'^DJI'\n",
    "    ,'NQ=F'\n",
    "    ,'^GSPC'\n",
    "    ,'GC=F'\n",
    "    ,'BTC-USD'\n",
    "    ,'ETH-USD'\n",
    "    ,'BRL=X'\n",
    "]\n",
    "\n",
    "index_country = [\n",
    "    'Brazil'\n",
    "    ,'Brazil'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'USA'\n",
    "    ,'Brazil'\n",
    "]\n",
    "\n",
    "index_type = [\n",
    "    'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Index'\n",
    "    ,'Gold'\n",
    "    ,'Crypto'\n",
    "    ,'Crypto'\n",
    "    ,'Currency'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index = pd.DataFrame()\n",
    "df_index['ticker'] = index_ticker\n",
    "df_index['name'] = index_name\n",
    "df_index['sector'] = index_sector\n",
    "df_index['industry'] = index_industry\n",
    "df_index['cod_yfinance'] = index_cod\n",
    "df_index['country'] = index_country\n",
    "df_index['type'] = index_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index.to_csv(f'{stock_path}all_indexes.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unificating characteristic datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_and_index = pd.concat([all_companies, df_index], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_and_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_and_index.to_csv(f'{stock_path}all_companies_and_indexes.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with all companies and indexes historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty DataFrame\n",
    "historical_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with historical data of all companies\n",
    "for ticker in all_companies_and_index['cod_yfinance']:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(period='max')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    historical_data = pd.concat([historical_data, aux_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if got all companies historical data\n",
    "len(historical_data['cod_yfinance'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 2022-12-12\n",
    "historical_data = historical_data.drop(historical_data[historical_data['Date'] == datetime.date(2022,12,12)].index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data[historical_data['Date'] == datetime.date(2022,12,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame\n",
    "historical_data.to_csv(f'{stock_path}historical_data_complete_rev5.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform index to column Date\n",
    "historical_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date to datetime\n",
    "historical_data['Date'] = pd.to_datetime(historical_data['Date'], utc=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform datetime to YYYY-MM-DD\n",
    "historical_data['Date'] = historical_data['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historical_data['cod_yfinance'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rounding values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data['Open'] = historical_data['Open'].round(3)\n",
    "historical_data['High'] = historical_data['High'].round(3)\n",
    "historical_data['Low'] = historical_data['Low'].round(3)\n",
    "historical_data['Close'] = historical_data['Close'].round(3)\n",
    "historical_data['Dividends'] = historical_data['Dividends'].round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset with indexes, gold, dolar (R$), bitcoin and ethereum historical data - Obsolete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty DataFrame\n",
    "indexes_historical_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with historical data of all companies\n",
    "for ticker in df_index['cod_yfinance']:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(start='1927-12-30', end='2022-12-10')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    indexes_historical_data = pd.concat([indexes_historical_data, aux_df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_historical_data.to_csv(f'{stock_path}indexes_historical_data.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on companies sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_and_indexes.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['sector'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies['industry'] = all_companies['industry'].str.replace(\"—\",\" - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[all_companies['industry'].str.contains('-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agf = ['QUAL3'\n",
    ",'VVBR3'\n",
    ",'AESB3'\n",
    ",'WIZS3'\n",
    ",'BRAP3'\n",
    ",'BRSR6'\n",
    ",'BRKM5'\n",
    ",'BRAP4'\n",
    ",'BRKM3'\n",
    ",'BRSR3'\n",
    ",'CGAS5'\n",
    ",'TRPL4'\n",
    ",'VIVT3'\n",
    ",'TAEE11'\n",
    ",'TAEE4'\n",
    ",'TAEE3'\n",
    ",'CGAS3'\n",
    ",'ITSA4'\n",
    ",'CSMG3'\n",
    ",'ENAT3'\n",
    ",'ITSA3'\n",
    ",'SANB11'\n",
    ",'SANB3'\n",
    ",'SANB4'\n",
    ",'GRND3'\n",
    ",'BRSR5'\n",
    ",'TRPL3'\n",
    ",'SAPR4'\n",
    ",'SAPR3'\n",
    ",'BBSE3'\n",
    ",'CMIG4'\n",
    ",'ALUP11'\n",
    ",'CLSC3'\n",
    ",'CMIG4'\n",
    ",'ELET3'\n",
    ",'BBAS3'\n",
    ",'BBDC4'\n",
    ",'ITUB4'\n",
    ",'AMBP3'\n",
    ",'CSAN3'\n",
    ",'CSAN4'\n",
    ",'OPCT3'\n",
    ",'SBSP3'\n",
    ",'SAPR11'\n",
    ",'VERZ34'\n",
    ",'OIBR4'\n",
    ",'TIMS3'\n",
    ",'VIVT4'\n",
    ",'TELB4'\n",
    ",'TELB3'\n",
    ",'ATTB34'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies[all_companies['ticker'].isin(agf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[all_companies['name'].isin(companies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.loc[(all_companies['name'].isin(companies)) | all_companies['ticker'].isin(agf)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perennial Industry\n",
    "perennial=[\n",
    "'Utilities - Diversified'\n",
    ",'Utilities - Independent Power Producers'\n",
    ",'Utilities - Regulated Electric'\n",
    ",'Utilities - Regulated Gas'\n",
    ",'Utilities - Regulated Water'\n",
    ",'Utilities - Renewable'\n",
    ",'Banks - Diversified'\n",
    ",'Banks - Regional'\n",
    ",'Insurance - Diversified'\n",
    ",'Insurance - Life'\n",
    ",'Insurance - Property & Casualty'\n",
    ",'Insurance - Reinsurance'\n",
    ",'Insurance - Specialty'\n",
    ",'Insurance Brokers'\n",
    ",'Healthcare Plans'\n",
    ",'Telecom Services'\n",
    ",'Waste Management'\n",
    ",'Oil & Gas E&P'\n",
    ",'Oil & Gas Equipment & Services'\n",
    ",'Oil & Gas Integrated'\n",
    ",'Oil & Gas Midstream'\n",
    ",'Oil & Gas Refining & Marketing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perennial subsector\n",
    "dict_subsector = {\n",
    "'Utilities - Diversified' : 'Utilities - Electricity'\n",
    ",'Utilities - Independent Power Producers' : 'Utilities - Electricity'\n",
    ",'Utilities - Regulated Electric' : 'Utilities - Electricity'\n",
    ",'Utilities - Regulated Gas' :\t'Utilities - Gas'\n",
    ",'Utilities - Regulated Water' : 'Sanitation'\n",
    ",'Utilities - Renewable' : 'Utilities - Electricity'\n",
    ",'Banks - Diversified' : 'Banks'\n",
    ",'Banks - Regional' : 'Banks'\n",
    ",'Insurance - Diversified': 'Insurance'\n",
    ",'Insurance - Life' : 'Insurance'\n",
    ",'Insurance - Property & Casualty' : 'Insurance'\n",
    ",'Insurance - Reinsurance' : 'Insurance'\n",
    ",'Insurance - Specialty' : 'Insurance'\n",
    ",'Insurance Brokers' : 'Insurance'\n",
    ",'Healthcare Plans' : 'Health Insurance'\n",
    ",'Telecom Services' : 'Telecom'\n",
    ",'Waste Management' : 'Sanitation'\n",
    ",'Oil & Gas E&P' : 'Oil & Gas'\n",
    ",'Oil & Gas Equipment & Services' : 'Oil & Gas'\n",
    ",'Oil & Gas Integrated' : 'Oil & Gas'\n",
    ",'Oil & Gas Midstream' : 'Oil & Gas'\n",
    ",'Oil & Gas Refining & Marketing' : 'Oil & Gas'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_perennial = all_companies['industry'].isin(perennial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indetify if the company is in a perennial sector\n",
    "all_companies.loc[mask_perennial, 'perennial'] = 'Yes'\n",
    "all_companies.loc[~mask_perennial, 'perennial'] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subsector for perennial companies\n",
    "all_companies.loc[mask_perennial, 'perennial_subsector'] =  all_companies.loc[mask_perennial, 'industry'].map(dict_subsector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the company is not perennial, subsector = industry\n",
    "all_companies.loc[~mask_perennial, 'perennial_subsector'] = all_companies.loc[~mask_perennial, 'industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save modified DataFrame\n",
    "all_companies_rev1.to_csv(f'{stock_path}all_companies_and_indexes_rev2.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_rev2 = pd.read_csv(f'{stock_path}all_companies_and_indexes_rev1.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_rev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_rev1 = all_companies_rev1[['cod_yfinance', 'ticker', 'name', 'sector', 'industry', 'perennial_subsector', 'perennial', 'country', 'type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies_rev1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get companies in AGF ranking using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the webdriver\n",
    "driver = webdriver.Chrome(options=chromeOptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.implicitly_wait(wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = driver.find_elements(By.CSS_SELECTOR, '.text-secondary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [i.text for i in company_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AGF companies ticker - not working\n",
    "br_ticker = driver.find_elements(By.XPATH, '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"text-muted\", \" \" ))]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies.to_csv(f'{stock_path}all_companies_rev2.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.',\n",
    "                    index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = pd.read_csv(f'{stock_path}all_companies_and_indexes_rev2.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = pd.read_csv(f'{stock_path}historical_data_complete_rev5.csv',\n",
    "                    encoding='UTF-8',\n",
    "                    sep=';',\n",
    "                    decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(\"USE stocks_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create companies Dataset in SQL\n",
    "all_companies.to_sql(name='companies', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create historical data dataset in SQL\n",
    "historical_data.to_sql(name='historical_data', con=engine, if_exists='replace', index=False) ##if_exists=append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate historical data dataset update process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing yfinance historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql_password\n",
    "load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project/password.env')\n",
    "sql_password = os.getenv('sql_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SQL configurations\n",
    "user = \"root\"\n",
    "password = sql_password\n",
    "url_banco = \"localhost\"\n",
    "nome_db = \"stocks_project\"\n",
    "conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine object\n",
    "engine = db.create_engine(conn_str)\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_engine():\n",
    "    \"\"\"Create engine to connect to MySQL server\n",
    "\n",
    "    Returns: \n",
    "        engine (sqlalchemy.engine): engine that connects to the stocks_project dataset on MySQL Server \n",
    "    \"\"\"\n",
    "    \n",
    "    # Import sql_password\n",
    "    load_dotenv(r'C:\\Users\\Pedro\\OneDrive\\Desktop\\Ironhack\\04. GitHub\\stocks_project/password.env')\n",
    "    sql_password = os.getenv('sql_password')\n",
    "\n",
    "    # Set SQL configurations\n",
    "    user = \"root\"\n",
    "    password = sql_password\n",
    "    url_banco = \"localhost\"\n",
    "    nome_db = \"stocks_project\"\n",
    "    conn_str = f\"mysql+pymysql://{user}:{password}@{url_banco}/{nome_db}\"\n",
    "\n",
    "    # Create engine object\n",
    "    engine = db.create_engine(conn_str)\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_to_date(date, days):\n",
    "    \"\"\"Add days to a date and return the date.\n",
    "    \n",
    "    Args: \n",
    "        date (string): Date string in YYYY-MM-DD format. \n",
    "        days (int): Number of days to add to date\n",
    "    \n",
    "    Returns: \n",
    "        date (date): Date in YYYY-MM-DD with X days added. \n",
    "    \"\"\"\n",
    "    \n",
    "    added_date = pd.to_datetime(date) + timedelta(days=days)\n",
    "    added_date = added_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return added_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_update_dataframe(start, end, ticker_list):\n",
    "    \"\"\"Create a DataFrame with last days historical data.\n",
    "    \n",
    "    Args: \n",
    "        start (string): Date string in YYYY-MM-DD format - One day after the last update \n",
    "        end (string): Date string in YYYY-MM-DD format - Today\n",
    "        ticker_list (iterable): iterable containing yfinance code for the companies and indexes\n",
    "    \n",
    "    Returns: \n",
    "        df (dataframe): DataFrame with last days historical data. \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for ticker in ticker_list.loc[0:5]:\n",
    "        aux_df = pd.DataFrame()\n",
    "        aux_df = yf.Ticker(ticker).history(start=start, end=end)\n",
    "        aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "        df = pd.concat([df, aux_df], axis=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_update_dataframe(dataframe):\n",
    "    \"\"\"Transform index to da columns with dates and round Open, High, Low, Close and Dividends columns to 3 decimal places\n",
    "    \n",
    "    Args: \n",
    "        dataframe (DataFrame): DataFrame containing last days historical data. \n",
    "    \n",
    "    Returns: \n",
    "        df (DataFrame): Formated Dataframe. \n",
    "    \"\"\"\n",
    "\n",
    "    dataframe.reset_index(inplace=True)\n",
    "    \n",
    "    # Transform date to datetime\n",
    "    dataframe['Date'] = pd.to_datetime(dataframe['Date'], utc=True) \n",
    "\n",
    "    # Transform datetime to YYYY-MM-DD\n",
    "    dataframe['Date'] = dataframe['Date'].dt.date\n",
    "\n",
    "    # Round Columns\n",
    "    dataframe['Open'] = dataframe['Open'].round(3)\n",
    "    dataframe['High'] = dataframe['High'].round(3)\n",
    "    dataframe['Low'] = dataframe['Low'].round(3)\n",
    "    dataframe['Close'] = dataframe['Close'].round(3)\n",
    "    dataframe['Dividends'] = dataframe['Dividends'].round(3)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_update_dataframe(dataframe):\n",
    "    \"\"\"Append update DataFrame to SQL dataset\n",
    "\n",
    "    Args: \n",
    "        dataframe (DataFrame): DataFrame, already formated, containing last days historical data. \n",
    "    \n",
    "    Returns**: \n",
    "        Append update DataFrame to SQL dataset \n",
    "    \"\"\"\n",
    "\n",
    "    dataframe.to_sql(name='test_dataset', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_date(engine):\n",
    "    \"\"\"Get the start date to be used in 'create_update_dataframe' function\n",
    "\n",
    "    Args: \n",
    "        engine (sqlalchemy.engine): engine that connects to the stocks_project dataset on MySQL Server \n",
    "    \n",
    "    Returns: \n",
    "        start (str): date to be used in 'create_update_dataframe' function\n",
    "    \"\"\"\n",
    "\n",
    "    last_update = pd.read_sql(sql = \"SELECT MAX(Date) FROM test_dataset\", con=engine)\n",
    "    start = last_update.iloc[0,0]\n",
    "    start= add_days_to_date(start, 1)\n",
    "\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_end_date():\n",
    "    \"\"\"Get today's date to be used as end date in 'create_update_dataframe' function \n",
    "\n",
    "    Returns: \n",
    "        today (str): Date string in YYYY-MM-DD format - Today\n",
    "    \"\"\"\n",
    "    today = datetime.datetime.now()\n",
    "    today = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_list(engine):\n",
    "    \"\"\"Get the ticker list to be used in 'create_update_dataframe' function\n",
    "\n",
    "    Args: \n",
    "        engine (sqlalchemy.engine): engine that connects to the stocks_project dataset on MySQL Server \n",
    "    \n",
    "    Returns: \n",
    "        ticker_list (iterable): iterable containing yfinance code for the companies and indexes\n",
    "    \"\"\"\n",
    "\n",
    "    ticker_list = pd.read_sql(sql='SELECT cod_yfinance FROM companies', con=engine)['cod_yfinance']\n",
    "\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(mysql+pymysql://root:***@localhost/stocks_project)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine()\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-09'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = get_start_date(engine)\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-12-12'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = get_end_date()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           IPG\n",
       "1           OMC\n",
       "2      TASA4.SA\n",
       "3      EMBR3.SA\n",
       "4            BA\n",
       "         ...   \n",
       "730       ^GSPC\n",
       "731        GC=F\n",
       "732     BTC-USD\n",
       "733     ETH-USD\n",
       "734       BRL=X\n",
       "Name: cod_yfinance, Length: 735, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ticker_list = get_ticker_list(engine)\n",
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cod_yfinance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-09 00:00:00-05:00</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.419998</td>\n",
       "      <td>31.840000</td>\n",
       "      <td>32.070000</td>\n",
       "      <td>1766400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 00:00:00-05:00</th>\n",
       "      <td>75.519997</td>\n",
       "      <td>76.410004</td>\n",
       "      <td>75.099998</td>\n",
       "      <td>75.650002</td>\n",
       "      <td>1160300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 00:00:00-03:00</th>\n",
       "      <td>13.900000</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>13.490000</td>\n",
       "      <td>13.590000</td>\n",
       "      <td>368300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TASA4.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 00:00:00-03:00</th>\n",
       "      <td>13.310000</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>13.090000</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>4267300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EMBR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 00:00:00-05:00</th>\n",
       "      <td>180.750000</td>\n",
       "      <td>183.889999</td>\n",
       "      <td>179.250000</td>\n",
       "      <td>179.539993</td>\n",
       "      <td>6348800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-09 00:00:00-05:00</th>\n",
       "      <td>247.270004</td>\n",
       "      <td>249.389999</td>\n",
       "      <td>246.500000</td>\n",
       "      <td>247.039993</td>\n",
       "      <td>748200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2022-12-09 00:00:00-05:00   32.000000   32.419998   31.840000   32.070000   \n",
       "2022-12-09 00:00:00-05:00   75.519997   76.410004   75.099998   75.650002   \n",
       "2022-12-09 00:00:00-03:00   13.900000   13.900000   13.490000   13.590000   \n",
       "2022-12-09 00:00:00-03:00   13.310000   13.410000   13.090000   13.110000   \n",
       "2022-12-09 00:00:00-05:00  180.750000  183.889999  179.250000  179.539993   \n",
       "2022-12-09 00:00:00-05:00  247.270004  249.389999  246.500000  247.039993   \n",
       "\n",
       "                            Volume  Dividends  Stock Splits cod_yfinance  \n",
       "Date                                                                      \n",
       "2022-12-09 00:00:00-05:00  1766400          0             0          IPG  \n",
       "2022-12-09 00:00:00-05:00  1160300          0             0          OMC  \n",
       "2022-12-09 00:00:00-03:00   368300          0             0     TASA4.SA  \n",
       "2022-12-09 00:00:00-03:00  4267300          0             0     EMBR3.SA  \n",
       "2022-12-09 00:00:00-05:00  6348800          0             0           BA  \n",
       "2022-12-09 00:00:00-05:00   748200          0             0           GD  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_update_dataframe(start, end, ticker_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>cod_yfinance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.42</td>\n",
       "      <td>31.84</td>\n",
       "      <td>32.07</td>\n",
       "      <td>1766400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>75.52</td>\n",
       "      <td>76.41</td>\n",
       "      <td>75.10</td>\n",
       "      <td>75.65</td>\n",
       "      <td>1160300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>13.90</td>\n",
       "      <td>13.90</td>\n",
       "      <td>13.49</td>\n",
       "      <td>13.59</td>\n",
       "      <td>368300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TASA4.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.41</td>\n",
       "      <td>13.09</td>\n",
       "      <td>13.11</td>\n",
       "      <td>4267300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EMBR3.SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>180.75</td>\n",
       "      <td>183.89</td>\n",
       "      <td>179.25</td>\n",
       "      <td>179.54</td>\n",
       "      <td>6348800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>247.27</td>\n",
       "      <td>249.39</td>\n",
       "      <td>246.50</td>\n",
       "      <td>247.04</td>\n",
       "      <td>748200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low   Close   Volume  Dividends  \\\n",
       "0  2022-12-09   32.00   32.42   31.84   32.07  1766400          0   \n",
       "1  2022-12-09   75.52   76.41   75.10   75.65  1160300          0   \n",
       "2  2022-12-09   13.90   13.90   13.49   13.59   368300          0   \n",
       "3  2022-12-09   13.31   13.41   13.09   13.11  4267300          0   \n",
       "4  2022-12-09  180.75  183.89  179.25  179.54  6348800          0   \n",
       "5  2022-12-09  247.27  249.39  246.50  247.04   748200          0   \n",
       "\n",
       "   Stock Splits cod_yfinance  \n",
       "0             0          IPG  \n",
       "1             0          OMC  \n",
       "2             0     TASA4.SA  \n",
       "3             0     EMBR3.SA  \n",
       "4             0           BA  \n",
       "5             0           GD  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = format_update_dataframe(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_update_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_update = pd.read_sql(sql = \"SELECT MAX(Date) FROM historical_data\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = last_update.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = add_days_to_date(start, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = pd.read_sql(sql='SELECT cod_yfinance FROM companies', con=engine)['cod_yfinance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing yfinance historical data\n",
    "test_df = pd.DataFrame()\n",
    "for ticker in ticker_list.loc[0:5]:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(start='2022-12-08', end='2022-12-09')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    test_df = pd.concat([test_df, aux_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date to datetime\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'], utc=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform datetime to YYYY-MM-DD\n",
    "test_df['Date'] = test_df['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Open'] = test_df['Open'].round(3)\n",
    "test_df['High'] = test_df['High'].round(3)\n",
    "test_df['Low'] = test_df['Low'].round(3)\n",
    "test_df['Close'] = test_df['Close'].round(3)\n",
    "test_df['Dividends'] = test_df['Dividends'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_sql(name='test_dataset', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing yfinance historical data\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "for ticker in ticker_list.loc[0:5]:\n",
    "    aux_df = pd.DataFrame()\n",
    "    aux_df = yf.Ticker(ticker).history(start='2022-12-09', end='2022-12-10')\n",
    "    aux_df['cod_yfinance'] = ticker\n",
    "\n",
    "    test_df = pd.concat([test_df, aux_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform date to datetime\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'], utc=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform datetime to YYYY-MM-DD\n",
    "test_df['Date'] = test_df['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Open'] = test_df['Open'].round(3)\n",
    "test_df['High'] = test_df['High'].round(3)\n",
    "test_df['Low'] = test_df['Low'].round(3)\n",
    "test_df['Close'] = test_df['Close'].round(3)\n",
    "test_df['Dividends'] = test_df['Dividends'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_sql(name='test_dataset', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d90c038637108ac29aff4d22cdf99e3e2599f922ccc5532827d676edf9e0ab0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
