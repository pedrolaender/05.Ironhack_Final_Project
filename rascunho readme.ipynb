{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"\"/>\n",
    "</p>\n",
    "\n",
    "# Final Project\n",
    "\n",
    "  Project Completed.\n",
    "## Abstract\n",
    "\n",
    "  This is the final project of the Ironhack's Data Analytics Bootcamp - Oct/2022. The objective of this project is to compare the stock prices of companies that belong to perennial sector and those that do not in periods of crises, both in Brazil and United States.\n",
    "## Introduction\n",
    "\n",
    "  <img width=\"10%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/Barsi%20-%20rev1.png?raw=true\">\n",
    "  \n",
    "  Luiz Barsi Filho is the biggest single investor in Brazil with a fortune estimated of R$ 4 billions. His strategy is to build a monthly income portfolio and is based in 4 main fundamentals:\n",
    "  \n",
    "  **<ins>Perennial Sectors:</ins>** Activity sectors essential for the survival of a country. Sectors in which demand is always growing or at least stable in periods of crisis.\n",
    "  - Banks\n",
    "  - Energy\n",
    "  - Insurance\n",
    "  - Sanitation\n",
    "  - Telecommunications\n",
    "  \n",
    "  **<ins>Dividends:</ins>** Dividends are the portion of the company's profit that is distributed to shareholders, it is proportional to the number of shares.\n",
    "\n",
    "  **<ins>Sustainability:</ins>** Companies wich activities are sustainable.\n",
    "\n",
    "  **<ins>Good Projects:</ins>** Companies that presents good projects for the future.\n",
    "\n",
    "\n",
    "\n",
    "### Business Question\n",
    "\n",
    "### Technologies \n",
    "\n",
    "  - Python\n",
    "  - MySQL\n",
    "  - Power BI\n",
    "\n",
    "### Methods\n",
    "\n",
    "  - Filtering\n",
    "  - Grouping\n",
    "  - Visualization\n",
    "  - Functional Programming\n",
    "  - Web Scrapping\n",
    "  - API\n",
    "\n",
    "### Libraries\n",
    "\n",
    "  - Pandas\n",
    "  - BeautifulSoup\n",
    "  - Selenium\n",
    "  - Regex\n",
    "  - Yfinance\n",
    "  - Numpy\n",
    "  - SQLAlchemy\n",
    "  - Dotenv\n",
    "  - Glob\n",
    "  - Time\n",
    "\n",
    "## Project Description\n",
    "\n",
    "### Select the Companies\n",
    "\n",
    "  The first thing to start building the dataset was to choose wich companies would be part of it. For Brazil we selected all companies listed on IBrA (√çndice Brasil Amplo) and Ibovespa totalizing 201 companies. For USA we selected all companies in S&P500 (Standard & Poor's 500), Nasdaq 100 and Dow Jone Industrial Average totalizing 525 companies.\n",
    "\n",
    "  The list of companies belonging to this indexes were gathered by Web Scrapping on B3 website, for brazilian index, and Wikipedia for americans.\n",
    "\n",
    "  Having selected the companies that would be part of the analysis, the need for two different datasets was identified, one containing the characteristics of the companies and the other the historical series of stock prices\n",
    "\n",
    "### Companies Characteristics Dataset\n",
    "\n",
    "  Once the analysis proposed in this project rely on the company's activity sector, it is the most important characteristic to be gathered. To standardize the sectors, we got it from Yahoo Finance website by webscrapping, both for brazilian and american companies. By doing this we got the dataset as shown below.\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img width=\"33%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/01.%20features%20before.png?raw=true\">\n",
    "</p>\n",
    "\n",
    "  Besides the sector, we found important to add some other features, so after checking the integrity of the already gathered data we add some other informations about the companies as if it is Perennial (yes/no), the Country, Type (company/index) and group the sectors to fit in the perennial sectors describe above, because it was to specific. After this cleaning and transforming we got a dataset as shown below.\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img  width=\"40%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/02.%20features%20after.png?raw=true\">\n",
    "</p>\n",
    "\n",
    "### Company's Stock Price Historical Series Dataset\n",
    "\n",
    "  The company's historical series were also gathered from Yahoo Finance, but through the API this time, once this ways makes getting the information easyer and saves a lot o processing time. The raw dataset after getting the data had some nulls and outlier as seen in the image below.\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img width=\"33%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/03%20historical%20before.png?raw=tru\">\n",
    "</p>\n",
    "\n",
    "  After cleaning we ended with a dataset as shown below. It contains near to 5 millions entries.\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img width=\"33%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/04.%20historiacal%20after.png?raw=true\">\n",
    "</p>\n",
    "\n",
    "### Uploading to SQL\n",
    "\n",
    "  Having both datasets ready to work we uploaded it to SQL.\n",
    "\n",
    "  <p align=\"center\" width=\"100%\">\n",
    " <img width=\"20%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/05.%20sql%20tables%20.PNG?raw=true\">\n",
    "  </p>\n",
    "\n",
    "  <p align=\"center\" width=\"100%\">\n",
    " <img width=\"33%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/06.%20sql%20historical.PNG?raw=true\">\n",
    "  </p>\n",
    "\n",
    "  <p align=\"center\" width=\"100%\">\n",
    " <img width=\"50%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/07.%20sql%20companies.PNG?raw=true\">\n",
    "  </p>\n",
    "  \n",
    "### Automating Historical Dataset Update\n",
    "\n",
    "  Now that we have the main dataset, we have to make a way to uptade it automatically. For that we separeted the data gathering, cleaning, tranforming and appending steps in functions to be run automatically every day. The sequence of the process is decribed below:\n",
    "  \n",
    "<img align=\"right\" width=\"25%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/08.%20functions.png?raw=true\">\n",
    "\n",
    "  - Link to database (SQL)\n",
    "  - Search last update date\n",
    "  - Search list of companies\n",
    "  - Search for stock quotes on Yfinance\n",
    "  - Process the data\n",
    "  - Add to main database\n",
    "\n",
    "\n",
    "### Visualization and Analysis\n",
    "\n",
    "  In order to make the analysis we elaborate a Power BI Dashboard.\n",
    "\n",
    "  The first page presents an exploratory analysis of the data in wich we can see that it is unbalanced with regard to the number of companies that belong to perennial sectors and thoose that do not. I was already as expected once we have only 5 sector considered perennial. Another thing importante to be considered is that the number of companies grow through the years.\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img width=\"33%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/09.%20exploratory%20analysis.PNG?raw=true\">\n",
    "</p>\n",
    "\n",
    "  The next pages show a line graphic that contains a reference index and the behavior of the mean price of stocks of two sectors considered perennial and two that are not, both for Brazil and USA. The analysis were made considering two periods of time 2019-2022 and 2012-2022 as shown below.\n",
    "  \n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img width=\"33%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/10.%20brasil%202019.PNG?raw=true\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img width=\"33%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/11.%20brasil%202012.PNG?raw=true\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img width=\"33%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/12.%20eua%202019.PNG?raw=true\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "<img width=\"33%\" src=\"https://github.com/pedrolaender/05.Ironhack_Final_Project/blob/main/Presentation/13.%20eua%202012.PNG?raw=true\">\n",
    "</p>\n",
    "\n",
    "## Conclusion\n",
    "  There are countless possibilities when it comes to improve a predict model. With the approach followed in this project we achieved our goal by getting a RMSE of 845,09 on Rick's Diamond Dataset.\n",
    "  \n",
    "## Contact\n",
    "\n",
    "  Pedro Laender\n",
    "  \n",
    "  Github - (https://github.com/pedrolaender)\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d90c038637108ac29aff4d22cdf99e3e2599f922ccc5532827d676edf9e0ab0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
